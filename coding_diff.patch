diff --git a/consensus/src/marshal/coding/marshaled.rs b/consensus/src/marshal/coding/marshaled.rs
new file mode 100644
index 000000000..4beeb87ab
--- /dev/null
+++ b/consensus/src/marshal/coding/marshaled.rs
@@ -0,0 +1,1018 @@
+//! Wrapper for consensus applications that handles epochs, erasure coding, and block dissemination.
+//!
+//! # Overview
+//!
+//! [`Marshaled`] is an adapter that wraps any [`VerifyingApplication`] implementation to handle
+//! epoch transitions and erasure coded broadcast automatically. It intercepts consensus
+//! operations (propose, verify, certify) and ensures blocks are only produced within valid epoch boundaries.
+//!
+//! # Epoch Boundaries
+//!
+//! An epoch is a fixed number of blocks (the `epoch_length`). When the last block in an epoch
+//! is reached, this wrapper prevents new blocks from being built & proposed until the next epoch begins.
+//! Instead, it re-proposes the boundary block to avoid producing blocks that would be pruned
+//! by the epoch transition.
+//!
+//! # Erasure Coding
+//!
+//! This wrapper integrates with a variant of marshal that supports erasure coded broadcast. When a leader
+//! proposes a new block, it is automatically erasure encoded and its shards are broadcasted to active
+//! participants. When verifying a proposed block (the precondition for notarization), the wrapper
+//! ensures the commitment's context digest matches the consensus context and subscribes to shard validity
+//! for the shard received by the proposer. If the shard is valid, the local shard is relayed to all
+//! other participants to aid in block reconstruction.
+//!
+//! During certification (the phase between notarization and finalization), the wrapper subscribes to
+//! block reconstruction and validates epoch boundaries, parent commitment, height contiguity, and
+//! that the block's embedded context matches the consensus context before allowing the block to be
+//! certified. If certification fails, the voter can still emit a nullify vote to advance the view.
+//!
+//! # Usage
+//!
+//! Wrap your [`VerifyingApplication`] implementation with [`Marshaled::new`] and provide it to your
+//! consensus engine for the [`Automaton`] and [`Relay`]. The wrapper handles all epoch logic transparently.
+//!
+//! ```rust,ignore
+//! let cfg = MarshaledConfig {
+//!     application: my_application,
+//!     marshal: marshal_mailbox,
+//!     shards: shard_mailbox,
+//!     scheme_provider,
+//!     epocher,
+//!     strategy,
+//! };
+//! let application = Marshaled::new(context, cfg);
+//! ```
+//!
+//! # Implementation Notes
+//!
+//! - Genesis blocks are handled specially: epoch 0 returns the application's genesis block,
+//!   while subsequent epochs use the last block of the previous epoch as genesis
+//! - Blocks are automatically verified to be within the current epoch
+//!
+//! # Notarization and Data Availability
+//!
+//! In rare crash cases, it is possible for a notarization certificate to exist without a block being
+//! available to the honest parties (e.g., if the whole network crashed before receiving `f+1` shards
+//! and the proposer went permanently offline). In this case, `certify` will be unable to fetch the
+//! block before timeout and result in a nullification.
+//!
+//! For this reason, it should not be expected that every notarized payload will be certifiable due
+//! to the lack of an available block. However, if even one honest and online party has the block,
+//! they will attempt to forward it to others via marshal's resolver. This case is already present
+//! in the event of a block that was proposed with invalid codec; Marshal will not be able to reconstruct
+//! the block, and therefore won't serve it.
+//!
+//! ```text
+//!                                      ┌───────────────────────────────────────────────────┐
+//!                                      ▼                                                   │
+//! ┌─────────────────────┐   ┌─────────────────────┐   ┌─────────────────────┐   ┌─────────────────────┐
+//! │          B1         │◀──│          B2         │◀──│          B3         │XXX│          B4         │
+//! └─────────────────────┘   └─────────────────────┘   └──────────┬──────────┘   └─────────────────────┘
+//!                                                                │
+//!                                                          Failed Certify
+//! ```
+
+use crate::{
+    marshal::{
+        ancestry::AncestorStream,
+        application::{
+            validation::{
+                is_inferred_reproposal_at_certify, is_valid_reproposal_at_verify,
+                validate_coded_block_for_verification, validate_coded_proposal,
+                CodedProposalValidationError, LastBuilt,
+            },
+            verification_tasks::VerificationTasks,
+        },
+        coding::{
+            shards,
+            types::{coding_config_for_participants, hash_context, CodedBlock},
+            Coding,
+        },
+        core, Update,
+    },
+    simplex::{scheme::Scheme, types::Context},
+    types::{coding::Commitment, Epoch, Epocher, Round},
+    Application, Automaton, Block, CertifiableAutomaton, CertifiableBlock, Epochable, Heightable,
+    Relay, Reporter, VerifyingApplication,
+};
+use commonware_coding::{Config as CodingConfig, Scheme as CodingScheme};
+use commonware_cryptography::{
+    certificate::{Provider, Scheme as CertificateScheme},
+    sha256::Digest as Sha256Digest,
+    Committable, Digestible,
+};
+use commonware_macros::select;
+use commonware_parallel::Strategy;
+use commonware_runtime::{
+    telemetry::metrics::histogram::{Buckets, Timed},
+    Clock, Metrics, Spawner, Storage,
+};
+use commonware_utils::{
+    channel::{
+        fallible::OneshotExt,
+        oneshot::{self, error::RecvError},
+    },
+    sync::Mutex,
+    NZU16,
+};
+use futures::future::{ready, try_join, Either, Ready};
+use rand::Rng;
+use std::sync::{Arc, OnceLock};
+use tracing::{debug, warn};
+
+/// The [`CodingConfig`] used for genesis blocks. These blocks are never broadcasted in
+/// the proposal phase, and thus the configuration is irrelevant.
+const GENESIS_CODING_CONFIG: CodingConfig = CodingConfig {
+    minimum_shards: NZU16!(1),
+    extra_shards: NZU16!(1),
+};
+
+/// Configuration for initializing [`Marshaled`].
+#[allow(clippy::type_complexity)]
+pub struct MarshaledConfig<A, B, C, Z, S, ES>
+where
+    B: CertifiableBlock,
+    C: CodingScheme,
+    Z: Provider<Scope = Epoch, Scheme: Scheme<Commitment>>,
+    S: Strategy,
+    ES: Epocher,
+{
+    /// The underlying application to wrap.
+    pub application: A,
+    /// Mailbox for communicating with the marshal engine.
+    pub marshal:
+        core::Mailbox<Z::Scheme, Coding<B, C, <Z::Scheme as CertificateScheme>::PublicKey>>,
+    /// Mailbox for communicating with the shards engine.
+    pub shards: shards::Mailbox<B, C, <Z::Scheme as CertificateScheme>::PublicKey>,
+    /// Provider for signing schemes scoped by epoch.
+    pub scheme_provider: Z,
+    /// Strategy for parallel operations.
+    pub strategy: S,
+    /// Strategy for determining epoch boundaries.
+    pub epocher: ES,
+}
+
+/// An [`Application`] adapter that handles epoch transitions and erasure coded broadcast.
+///
+/// This wrapper intercepts consensus operations to enforce epoch boundaries. It prevents
+/// blocks from being produced outside their valid epoch and handles the special case of
+/// re-proposing boundary blocks during epoch transitions.
+#[derive(Clone)]
+#[allow(clippy::type_complexity)]
+pub struct Marshaled<E, A, B, C, Z, S, ES>
+where
+    E: Rng + Storage + Spawner + Metrics + Clock,
+    A: Application<E>,
+    B: CertifiableBlock,
+    C: CodingScheme,
+    Z: Provider<Scope = Epoch, Scheme: Scheme<Commitment>>,
+    S: Strategy,
+    ES: Epocher,
+{
+    context: E,
+    application: A,
+    marshal: core::Mailbox<Z::Scheme, Coding<B, C, <Z::Scheme as CertificateScheme>::PublicKey>>,
+    shards: shards::Mailbox<B, C, <Z::Scheme as CertificateScheme>::PublicKey>,
+    scheme_provider: Z,
+    epocher: ES,
+    strategy: S,
+    last_built: LastBuilt<CodedBlock<B, C>>,
+    verification_tasks: VerificationTasks<Commitment>,
+    cached_genesis: Arc<OnceLock<(Commitment, CodedBlock<B, C>)>>,
+
+    build_duration: Timed<E>,
+    verify_duration: Timed<E>,
+    proposal_parent_fetch_duration: Timed<E>,
+    erasure_encode_duration: Timed<E>,
+}
+
+impl<E, A, B, C, Z, S, ES> Marshaled<E, A, B, C, Z, S, ES>
+where
+    E: Rng + Storage + Spawner + Metrics + Clock,
+    A: VerifyingApplication<
+        E,
+        Block = B,
+        SigningScheme = Z::Scheme,
+        Context = Context<Commitment, <Z::Scheme as CertificateScheme>::PublicKey>,
+    >,
+    B: CertifiableBlock<Context = <A as Application<E>>::Context>,
+    C: CodingScheme,
+    Z: Provider<Scope = Epoch, Scheme: Scheme<Commitment>>,
+    S: Strategy,
+    ES: Epocher,
+{
+    /// Creates a new [`Marshaled`] wrapper.
+    ///
+    /// # Panics
+    ///
+    /// Panics if the marshal metadata store cannot be initialized.
+    pub fn new(context: E, cfg: MarshaledConfig<A, B, C, Z, S, ES>) -> Self {
+        let MarshaledConfig {
+            application,
+            marshal,
+            shards,
+            scheme_provider,
+            strategy,
+            epocher,
+        } = cfg;
+
+        use prometheus_client::metrics::histogram::Histogram;
+
+        let clock = Arc::new(context.clone());
+
+        let build_histogram = Histogram::new(Buckets::LOCAL);
+        context.register(
+            "build_duration",
+            "Histogram of time taken for the application to build a new block, in seconds",
+            build_histogram.clone(),
+        );
+        let build_duration = Timed::new(build_histogram, clock.clone());
+
+        let verify_histogram = Histogram::new(Buckets::LOCAL);
+        context.register(
+            "verify_duration",
+            "Histogram of time taken for the application to verify a block, in seconds",
+            verify_histogram.clone(),
+        );
+        let verify_duration = Timed::new(verify_histogram, clock.clone());
+
+        let parent_fetch_histogram = Histogram::new(Buckets::LOCAL);
+        context.register(
+            "parent_fetch_duration",
+            "Histogram of time taken to fetch a parent block in proposal, in seconds",
+            parent_fetch_histogram.clone(),
+        );
+        let proposal_parent_fetch_duration = Timed::new(parent_fetch_histogram, clock.clone());
+
+        let erasure_histogram = Histogram::new(Buckets::LOCAL);
+        context.register(
+            "erasure_encode_duration",
+            "Histogram of time taken to erasure encode a block, in seconds",
+            erasure_histogram.clone(),
+        );
+        let erasure_encode_duration = Timed::new(erasure_histogram, clock);
+
+        Self {
+            context,
+            application,
+            marshal,
+            shards,
+            scheme_provider,
+            strategy,
+            epocher,
+            last_built: Arc::new(Mutex::new(None)),
+            verification_tasks: VerificationTasks::new(),
+            cached_genesis: Arc::new(OnceLock::new()),
+
+            build_duration,
+            verify_duration,
+            proposal_parent_fetch_duration,
+            erasure_encode_duration,
+        }
+    }
+
+    /// Verifies a proposed block within epoch boundaries.
+    ///
+    /// This method validates that:
+    /// 1. The block is within the current epoch (unless it's a boundary block re-proposal)
+    /// 2. Re-proposals are only allowed for the last block in an epoch
+    /// 3. The block's parent digest matches the consensus context's expected parent
+    /// 4. The block's height is exactly one greater than the parent's height
+    /// 5. The block's embedded context digest matches the commitment
+    /// 6. The block's embedded context matches the consensus context
+    /// 7. The underlying application's verification logic passes
+    ///
+    /// Verification is spawned in a background task and returns a receiver that will contain
+    /// the verification result.
+    ///
+    /// If `prefetched_block` is provided, it will be used directly instead of fetching from
+    /// the marshal. This is useful in `certify` when we've already fetched the block to
+    /// extract its embedded context.
+    fn deferred_verify(
+        &mut self,
+        context: Context<Commitment, <Z::Scheme as CertificateScheme>::PublicKey>,
+        commitment: Commitment,
+        prefetched_block: Option<CodedBlock<B, C>>,
+    ) -> oneshot::Receiver<bool> {
+        let mut marshal = self.marshal.clone();
+        let mut application = self.application.clone();
+        let epocher = self.epocher.clone();
+        let verify_duration = self.verify_duration.clone();
+        let cached_genesis = self.cached_genesis.clone();
+
+        let (mut tx, rx) = oneshot::channel();
+        self.context
+            .with_label("deferred_verify")
+            .with_attribute("round", context.round)
+            .spawn(move |runtime_context| async move {
+                let round = context.round;
+
+                // Fetch parent block
+                let (parent_view, parent_commitment) = context.parent;
+                let parent_request = fetch_parent(
+                    parent_commitment,
+                    Some(Round::new(context.epoch(), parent_view)),
+                    &mut application,
+                    &mut marshal,
+                    cached_genesis,
+                )
+                .await;
+
+                // Get block either from prefetched or by subscribing
+                let (parent, block) = if let Some(block) = prefetched_block {
+                    // We have a prefetched block, just fetch the parent
+                    let parent = select! {
+                        _ = tx.closed() => {
+                            debug!(
+                                reason = "consensus dropped receiver",
+                                "skipping verification"
+                            );
+                            return;
+                        },
+                        result = parent_request => match result {
+                            Ok(parent) => parent,
+                            Err(_) => {
+                                debug!(reason = "failed to fetch parent", "skipping verification");
+                                return;
+                            }
+                        },
+                    };
+                    (parent, block)
+                } else {
+                    // No prefetched block, fetch both parent and block
+                    let block_request = marshal
+                        .subscribe_by_commitment(Some(round), commitment)
+                        .await;
+                    let block_requests = try_join(parent_request, block_request);
+
+                    select! {
+                        _ = tx.closed() => {
+                            debug!(
+                                reason = "consensus dropped receiver",
+                                "skipping verification"
+                            );
+                            return;
+                        },
+                        result = block_requests => match result {
+                            Ok(results) => results,
+                            Err(_) => {
+                                debug!(
+                                    reason = "failed to fetch parent or block",
+                                    "skipping verification"
+                                );
+                                return;
+                            }
+                        },
+                    }
+                };
+
+                if let Err(err) = validate_coded_block_for_verification(
+                    &epocher,
+                    &block,
+                    &parent,
+                    &context,
+                    commitment,
+                    parent_commitment,
+                ) {
+                    debug!(
+                        ?err,
+                        expected_commitment = %commitment,
+                        block_commitment = %block.commitment(),
+                        expected_parent_commitment = %parent_commitment,
+                        parent_commitment = %parent.commitment(),
+                        expected_parent = %parent.digest(),
+                        block_parent = %block.parent(),
+                        parent_height = %parent.height(),
+                        block_height = %block.height(),
+                        "block failed coded invariant validation"
+                    );
+                    tx.send_lossy(false);
+                    return;
+                }
+
+                let ancestry_stream = AncestorStream::new(
+                    marshal.clone(),
+                    [block.clone().into_inner(), parent.into_inner()],
+                );
+                let validity_request = application.verify(
+                    (runtime_context.with_label("app_verify"), context.clone()),
+                    ancestry_stream,
+                );
+
+                // If consensus drops the receiver, we can stop work early.
+                let mut timer = verify_duration.timer();
+                let application_valid = select! {
+                    _ = tx.closed() => {
+                        debug!(
+                            reason = "consensus dropped receiver",
+                            "skipping verification"
+                        );
+                        return;
+                    },
+                    is_valid = validity_request => is_valid,
+                };
+                timer.observe();
+                if application_valid {
+                    // The block is only persisted at this point.
+                    marshal.verified(round, block).await;
+                }
+                tx.send_lossy(application_valid);
+            });
+
+        rx
+    }
+}
+
+impl<E, A, B, C, Z, S, ES> Automaton for Marshaled<E, A, B, C, Z, S, ES>
+where
+    E: Rng + Storage + Spawner + Metrics + Clock,
+    A: VerifyingApplication<
+        E,
+        Block = B,
+        SigningScheme = Z::Scheme,
+        Context = Context<Commitment, <Z::Scheme as CertificateScheme>::PublicKey>,
+    >,
+    B: CertifiableBlock<Context = <A as Application<E>>::Context>,
+    C: CodingScheme,
+    Z: Provider<Scope = Epoch, Scheme: Scheme<Commitment>>,
+    S: Strategy,
+    ES: Epocher,
+{
+    type Digest = Commitment;
+    type Context = Context<Self::Digest, <Z::Scheme as CertificateScheme>::PublicKey>;
+
+    /// Returns the genesis digest for a given epoch.
+    ///
+    /// For epoch 0, this returns the application's genesis block digest. For subsequent
+    /// epochs, it returns the digest of the last block from the previous epoch, which
+    /// serves as the genesis block for the new epoch.
+    ///
+    /// # Panics
+    ///
+    /// Panics if a non-zero epoch is requested but the previous epoch's final block is not
+    /// available in storage. This indicates a critical error in the consensus engine startup
+    /// sequence, as engines must always have the genesis block before starting.
+    async fn genesis(&mut self, epoch: Epoch) -> Self::Digest {
+        let Some(previous_epoch) = epoch.previous() else {
+            let genesis_block = self.application.genesis().await;
+            return genesis_coding_commitment(&genesis_block);
+        };
+
+        let last_height = self
+            .epocher
+            .last(previous_epoch)
+            .expect("previous epoch should exist");
+        let Some(block) = self.marshal.get_block(last_height).await else {
+            // A new consensus engine will never be started without having the genesis block
+            // of the new epoch (the last block of the previous epoch) already stored.
+            unreachable!("missing starting epoch block at height {last_height}");
+        };
+        block.commitment()
+    }
+
+    /// Proposes a new block or re-proposes the epoch boundary block.
+    ///
+    /// This method builds a new block from the underlying application unless the parent block
+    /// is the last block in the current epoch. When at an epoch boundary, it re-proposes the
+    /// boundary block to avoid creating blocks that would be invalidated by the epoch transition.
+    ///
+    /// The proposal operation is spawned in a background task and returns a receiver that will
+    /// contain the proposed block's digest when ready. The built block is cached for later
+    /// broadcasting.
+    async fn propose(
+        &mut self,
+        consensus_context: Context<Commitment, <Z::Scheme as CertificateScheme>::PublicKey>,
+    ) -> oneshot::Receiver<Self::Digest> {
+        let mut marshal = self.marshal.clone();
+        let mut application = self.application.clone();
+        let last_built = self.last_built.clone();
+        let epocher = self.epocher.clone();
+        let strategy = self.strategy.clone();
+        let cached_genesis = self.cached_genesis.clone();
+
+        // If there's no scheme for the current epoch, we cannot verify the proposal.
+        // Send back a receiver with a dropped sender.
+        let Some(scheme) = self.scheme_provider.scoped(consensus_context.epoch()) else {
+            let (_, rx) = oneshot::channel();
+            return rx;
+        };
+
+        let n_participants =
+            u16::try_from(scheme.participants().len()).expect("too many participants");
+        let coding_config = coding_config_for_participants(n_participants);
+
+        // Metrics
+        let build_duration = self.build_duration.clone();
+        let proposal_parent_fetch_duration = self.proposal_parent_fetch_duration.clone();
+        let erasure_encode_duration = self.erasure_encode_duration.clone();
+
+        let (mut tx, rx) = oneshot::channel();
+        self.context
+            .with_label("propose")
+            .with_attribute("round", consensus_context.round)
+            .spawn(move |runtime_context| async move {
+                let (parent_view, parent_commitment) = consensus_context.parent;
+                let parent_request = fetch_parent(
+                    parent_commitment,
+                    Some(Round::new(consensus_context.epoch(), parent_view)),
+                    &mut application,
+                    &mut marshal,
+                    cached_genesis,
+                )
+                .await;
+
+                let mut parent_timer = proposal_parent_fetch_duration.timer();
+                let parent = select! {
+                    _ = tx.closed() => {
+                        debug!(reason = "consensus dropped receiver", "skipping proposal");
+                        return;
+                    },
+                    result = parent_request => match result {
+                        Ok(parent) => parent,
+                        Err(_) => {
+                            debug!(
+                                ?parent_commitment,
+                                reason = "failed to fetch parent block",
+                                "skipping proposal"
+                            );
+                            return;
+                        }
+                    },
+                };
+                parent_timer.observe();
+
+                // Special case: If the parent block is the last block in the epoch,
+                // re-propose it as to not produce any blocks that will be cut out
+                // by the epoch transition.
+                let last_in_epoch = epocher
+                    .last(consensus_context.epoch())
+                    .expect("current epoch should exist");
+                if parent.height() == last_in_epoch {
+                    let commitment = parent.commitment();
+                    {
+                        let mut lock = last_built.lock();
+                        *lock = Some((consensus_context.round, parent));
+                    }
+
+                    let success = tx.send_lossy(commitment);
+                    debug!(
+                        round = ?consensus_context.round,
+                        ?commitment,
+                        success,
+                        "re-proposed parent block at epoch boundary"
+                    );
+                    return;
+                }
+
+                let ancestor_stream = AncestorStream::new(marshal.clone(), [parent.into_inner()]);
+                let build_request = application.propose(
+                    (
+                        runtime_context.with_label("app_propose"),
+                        consensus_context.clone(),
+                    ),
+                    ancestor_stream,
+                );
+
+                let mut build_timer = build_duration.timer();
+                let built_block = select! {
+                    _ = tx.closed() => {
+                        debug!(reason = "consensus dropped receiver", "skipping proposal");
+                        return;
+                    },
+                    result = build_request => match result {
+                        Some(block) => block,
+                        None => {
+                            debug!(
+                                ?parent_commitment,
+                                reason = "block building failed",
+                                "skipping proposal"
+                            );
+                            return;
+                        }
+                    },
+                };
+                build_timer.observe();
+
+                let mut erasure_timer = erasure_encode_duration.timer();
+                let coded_block = CodedBlock::<B, C>::new(built_block, coding_config, &strategy);
+                erasure_timer.observe();
+
+                let commitment = coded_block.commitment();
+                {
+                    let mut lock = last_built.lock();
+                    *lock = Some((consensus_context.round, coded_block));
+                }
+
+                let success = tx.send_lossy(commitment);
+                debug!(
+                    round = ?consensus_context.round,
+                    ?commitment,
+                    success,
+                    "proposed new block"
+                );
+            });
+        rx
+    }
+
+    /// Verifies a received shard for a given round.
+    ///
+    /// This method validates that:
+    /// 1. The coding configuration matches the expected configuration for the current scheme.
+    /// 2. The commitment's context digest matches the consensus context (unless this is a re-proposal).
+    /// 3. The shard is contained within the consensus commitment.
+    ///
+    /// Verification is spawned in a background task and returns a receiver that will contain
+    /// the verification result. Additionally, this method kicks off deferred verification to
+    /// start block verification early (hidden behind shard validity and network latency).
+    async fn verify(
+        &mut self,
+        context: Context<Self::Digest, <Z::Scheme as CertificateScheme>::PublicKey>,
+        payload: Self::Digest,
+    ) -> oneshot::Receiver<bool> {
+        // If there's no scheme for the current epoch, we cannot vote on the proposal.
+        // Send back a receiver with a dropped sender.
+        let Some(scheme) = self.scheme_provider.scoped(context.epoch()) else {
+            let (_, rx) = oneshot::channel();
+            return rx;
+        };
+
+        let n_participants =
+            u16::try_from(scheme.participants().len()).expect("too many participants");
+        let coding_config = coding_config_for_participants(n_participants);
+        let is_reproposal = payload == context.parent.1;
+
+        // Validate proposal-level invariants:
+        // - coding config must match active participant set
+        // - context hash must match unless this is a re-proposal
+        let proposal_context = (!is_reproposal).then_some(&context);
+        if let Err(err) = validate_coded_proposal(payload, coding_config, proposal_context) {
+            match err {
+                CodedProposalValidationError::CodingConfig => {
+                    warn!(
+                        round = %context.round,
+                        got = ?payload.config(),
+                        expected = ?coding_config,
+                        "rejected proposal with unexpected coding configuration"
+                    );
+                }
+                CodedProposalValidationError::ContextHash => {
+                    let expected = hash_context(&context);
+                    let got = payload.context::<Sha256Digest>();
+                    warn!(
+                        round = %context.round,
+                        expected = ?expected,
+                        got = ?got,
+                        "rejected proposal with mismatched context digest"
+                    );
+                }
+            }
+
+            let (tx, rx) = oneshot::channel();
+            tx.send_lossy(false);
+            return rx;
+        }
+
+        // Re-proposals skip context-hash validation because the consensus context will point
+        // at the prior epoch-boundary block while the embedded block context is from the
+        // original proposal view.
+        //
+        // Re-proposals also skip shard-validity and deferred verification because:
+        // 1. The block was already verified when originally proposed
+        // 2. The parent-child height check would fail (parent IS the block)
+        // 3. Waiting for shards could stall if the leader doesn't rebroadcast
+        if is_reproposal {
+            // Fetch the block to verify it's at the epoch boundary.
+            // This should be fast since the parent block is typically already cached.
+            let block_rx = self
+                .marshal
+                .subscribe_by_commitment(Some(context.round), payload)
+                .await;
+            let marshal = self.marshal.clone();
+            let epocher = self.epocher.clone();
+            let round = context.round;
+            let verification_tasks = self.verification_tasks.clone();
+
+            // Register a verification task synchronously before spawning work so
+            // `certify` can always find it (no race with task startup).
+            let (task_tx, task_rx) = oneshot::channel();
+            verification_tasks.insert(round, payload, task_rx);
+
+            let (mut tx, rx) = oneshot::channel();
+            self.context
+                .with_label("verify_reproposal")
+                .spawn(move |_| async move {
+                    let block = select! {
+                        _ = tx.closed() => {
+                            debug!(
+                                reason = "consensus dropped receiver",
+                                "skipping re-proposal verification"
+                            );
+                            return;
+                        },
+                        block = block_rx => match block {
+                            Ok(block) => block,
+                            Err(_) => {
+                                debug!(
+                                    ?payload,
+                                    reason = "failed to fetch block for re-proposal verification",
+                                    "skipping re-proposal verification"
+                                );
+                                // Fetch failure is an availability issue, not an explicit
+                                // invalidity proof. Do not synthesize `false` here.
+                                return;
+                            }
+                        },
+                    };
+
+                    if !is_valid_reproposal_at_verify(&epocher, block.height(), round.epoch()) {
+                        debug!(
+                            height = %block.height(),
+                            "re-proposal is not at epoch boundary"
+                        );
+                        task_tx.send_lossy(false);
+                        tx.send_lossy(false);
+                        return;
+                    }
+
+                    // Valid re-proposal. Notify the marshal and complete the
+                    // verification task for `certify`.
+                    marshal.verified(round, block).await;
+                    task_tx.send_lossy(true);
+                    tx.send_lossy(true);
+                });
+            return rx;
+        }
+
+        // Inform the shard engine of an externally proposed commitment.
+        self.shards
+            .discovered(payload, context.leader.clone(), context.round)
+            .await;
+
+        // Kick off deferred verification early to hide verification latency behind
+        // shard validity checks and network latency for collecting votes.
+        let round = context.round;
+        let task = self.deferred_verify(context, payload, None);
+        self.verification_tasks.insert(round, payload, task);
+
+        match scheme.me() {
+            Some(_) => {
+                // Subscribe to shard validity. The subscription completes when a valid shard arrives.
+                let validity_rx = self.shards.subscribe_shard(payload).await;
+                let (tx, rx) = oneshot::channel();
+                self.context
+                    .with_label("shard_validity_wait")
+                    .spawn(|_| async move {
+                        if validity_rx.await.is_ok() {
+                            tx.send_lossy(true);
+                        }
+                    });
+                rx
+            }
+            None => {
+                // If we are not participating, there's no shard to verify; just accept the proposal.
+                //
+                // Later, when certifying, we will wait to receive the block from the network.
+                let (tx, rx) = oneshot::channel();
+                tx.send_lossy(true);
+                rx
+            }
+        }
+    }
+}
+
+impl<E, A, B, C, Z, S, ES> CertifiableAutomaton for Marshaled<E, A, B, C, Z, S, ES>
+where
+    E: Rng + Storage + Spawner + Metrics + Clock,
+    A: VerifyingApplication<
+        E,
+        Block = B,
+        SigningScheme = Z::Scheme,
+        Context = Context<Commitment, <Z::Scheme as CertificateScheme>::PublicKey>,
+    >,
+    B: CertifiableBlock<Context = <A as Application<E>>::Context>,
+    C: CodingScheme,
+    Z: Provider<Scope = Epoch, Scheme: Scheme<Commitment>>,
+    S: Strategy,
+    ES: Epocher,
+{
+    async fn certify(&mut self, round: Round, payload: Self::Digest) -> oneshot::Receiver<bool> {
+        // First, check for an in-progress verification task from `verify()`.
+        let task = self.verification_tasks.take(round, payload);
+        if let Some(task) = task {
+            return task;
+        }
+
+        // No in-progress task means we never verified this proposal locally.
+        // We can use the block's embedded context to move to the next view. If a Byzantine
+        // proposer embedded a malicious context, the f+1 honest validators from the notarizing quorum
+        // will verify against the proper context and reject the mismatch, preventing a 2f+1
+        // finalization quorum.
+        //
+        // Subscribe to the block and verify using its embedded context once available.
+        debug!(
+            ?round,
+            ?payload,
+            "subscribing to block for certification using embedded context"
+        );
+        let block_rx = self
+            .marshal
+            .subscribe_by_commitment(Some(round), payload)
+            .await;
+        let mut marshaled = self.clone();
+        let shards = self.shards.clone();
+        let (mut tx, rx) = oneshot::channel();
+        self.context
+            .with_label("certify")
+            .with_attribute("round", round)
+            .spawn(move |_| async move {
+                let block = select! {
+                    _ = tx.closed() => {
+                        debug!(
+                            reason = "consensus dropped receiver",
+                            "skipping certification"
+                        );
+                        return;
+                    },
+                    result = block_rx => match result {
+                        Ok(block) => block,
+                        Err(_) => {
+                            debug!(
+                                ?payload,
+                                reason = "failed to fetch block for certification",
+                                "skipping certification"
+                            );
+                            return;
+                        }
+                    },
+                };
+
+                // Re-proposal detection for certify path: we don't have the consensus
+                // context, only the block's embedded context from original proposal.
+                // Infer re-proposal from:
+                // 1. Block is at epoch boundary (only boundary blocks can be re-proposed)
+                // 2. Certification round's view > embedded context's view (re-proposals
+                //    retain their original embedded context, so a later view indicates
+                //    the block was re-proposed)
+                // 3. Same epoch (re-proposals don't cross epoch boundaries)
+                let embedded_context = block.context();
+                let is_reproposal = is_inferred_reproposal_at_certify(
+                    &marshaled.epocher,
+                    block.height(),
+                    embedded_context.round,
+                    round,
+                );
+                if is_reproposal {
+                    // NOTE: It is possible that, during crash recovery, we call
+                    // `marshal.verified` twice for the same block. That function is
+                    // idempotent, so this is safe.
+                    marshaled.marshal.verified(round, block).await;
+                    tx.send_lossy(true);
+                    return;
+                }
+
+                // Inform the shard engine of an externally proposed commitment.
+                shards
+                    .discovered(
+                        payload,
+                        embedded_context.leader.clone(),
+                        embedded_context.round,
+                    )
+                    .await;
+
+                // Use the block's embedded context for verification, passing the
+                // prefetched block to avoid fetching it again inside deferred_verify.
+                let verify_rx = marshaled.deferred_verify(embedded_context, payload, Some(block));
+                if let Ok(result) = verify_rx.await {
+                    tx.send_lossy(result);
+                }
+            });
+        rx
+    }
+}
+
+impl<E, A, B, C, Z, S, ES> Relay for Marshaled<E, A, B, C, Z, S, ES>
+where
+    E: Rng + Storage + Spawner + Metrics + Clock,
+    A: Application<
+        E,
+        Block = B,
+        Context = Context<Commitment, <Z::Scheme as CertificateScheme>::PublicKey>,
+    >,
+    B: CertifiableBlock<Context = <A as Application<E>>::Context>,
+    C: CodingScheme,
+    Z: Provider<Scope = Epoch, Scheme: Scheme<Commitment>>,
+    S: Strategy,
+    ES: Epocher,
+{
+    type Digest = Commitment;
+
+    /// Broadcasts a previously built block to the network.
+    ///
+    /// This uses the cached block from the last proposal operation. If no block was built or
+    /// the digest does not match the cached block, the broadcast is skipped with a warning.
+    async fn broadcast(&mut self, commitment: Self::Digest) {
+        let Some((round, block)) = self.last_built.lock().take() else {
+            warn!("missing block to broadcast");
+            return;
+        };
+
+        if block.commitment() != commitment {
+            warn!(
+                round = %round,
+                commitment = %block.commitment(),
+                height = %block.height(),
+                "skipping requested broadcast of block with mismatched commitment"
+            );
+            return;
+        }
+
+        debug!(
+            round = %round,
+            commitment = %block.commitment(),
+            height = %block.height(),
+            "requested broadcast of built block"
+        );
+
+        self.shards.proposed(round, block).await;
+    }
+}
+
+impl<E, A, B, C, Z, S, ES> Reporter for Marshaled<E, A, B, C, Z, S, ES>
+where
+    E: Rng + Storage + Spawner + Metrics + Clock,
+    A: Application<
+            E,
+            Block = B,
+            Context = Context<Commitment, <Z::Scheme as CertificateScheme>::PublicKey>,
+        > + Reporter<Activity = Update<B>>,
+    B: CertifiableBlock<Context = <A as Application<E>>::Context>,
+    C: CodingScheme,
+    Z: Provider<Scope = Epoch, Scheme: Scheme<Commitment>>,
+    S: Strategy,
+    ES: Epocher,
+{
+    type Activity = A::Activity;
+
+    /// Relays a report to the underlying [`Application`] and cleans up old verification data.
+    async fn report(&mut self, update: Self::Activity) {
+        // Clean up verification tasks and contexts for rounds <= the finalized round.
+        if let Update::Tip(round, _, _) = &update {
+            self.verification_tasks.retain_after(round);
+        }
+        self.application.report(update).await
+    }
+}
+
+/// Fetches the parent block given its digest and optional round.
+///
+/// This is a helper function used during proposal and verification to retrieve the parent
+/// block. If the parent digest matches the genesis block, it returns the genesis block
+/// directly without querying the marshal. Otherwise, it subscribes to the marshal to await
+/// the parent block's availability.
+///
+/// Returns an error if the marshal subscription is cancelled.
+async fn fetch_parent<E, S, A, B, C>(
+    parent_commitment: Commitment,
+    parent_round: Option<Round>,
+    application: &mut A,
+    marshal: &mut core::Mailbox<S, Coding<B, C, S::PublicKey>>,
+    cached_genesis: Arc<OnceLock<(Commitment, CodedBlock<B, C>)>>,
+) -> Either<Ready<Result<CodedBlock<B, C>, RecvError>>, oneshot::Receiver<CodedBlock<B, C>>>
+where
+    E: Rng + Spawner + Metrics + Clock,
+    S: CertificateScheme,
+    A: Application<E, Block = B, Context = Context<Commitment, S::PublicKey>>,
+    B: CertifiableBlock,
+    C: CodingScheme,
+{
+    if cached_genesis.get().is_none() {
+        let genesis = application.genesis().await;
+        let genesis_coding_commitment = genesis_coding_commitment(&genesis);
+        let coded_genesis = CodedBlock::<B, C>::new_trusted(genesis, genesis_coding_commitment);
+        let _ = cached_genesis.set((genesis_coding_commitment, coded_genesis));
+    }
+
+    let (genesis_commitment, coded_genesis) = cached_genesis
+        .get()
+        .expect("genesis cache should be initialized");
+    if parent_commitment == *genesis_commitment {
+        Either::Left(ready(Ok(coded_genesis.clone())))
+    } else {
+        Either::Right(
+            marshal
+                .subscribe_by_commitment(parent_round, parent_commitment)
+                .await,
+        )
+    }
+}
+
+/// Constructs the [`Commitment`] for the genesis block.
+fn genesis_coding_commitment<B: CertifiableBlock>(block: &B) -> Commitment {
+    Commitment::from((
+        block.digest(),
+        block.digest(),
+        hash_context(&block.context()),
+        GENESIS_CODING_CONFIG,
+    ))
+}
diff --git a/consensus/src/marshal/coding/mod.rs b/consensus/src/marshal/coding/mod.rs
new file mode 100644
index 000000000..6ee5eca5c
--- /dev/null
+++ b/consensus/src/marshal/coding/mod.rs
@@ -0,0 +1,1538 @@
+//! Ordered delivery of erasure-coded blocks.
+//!
+//! # Overview
+//!
+//! The coding marshal couples the consensus pipeline with erasure-coded block broadcast.
+//! Blocks are produced by an application, encoded into [`types::Shard`]s, fanned out to peers, and
+//! later reconstructed when a notarization or finalization proves that the data is needed.
+//! Compared to [`super::standard`], this variant makes more efficient usage of the network's bandwidth
+//! by spreading the load of block dissemination across all participants.
+//!
+//! # Components
+//!
+//! - [`crate::marshal::core::Actor`]: The unified marshal actor that orders finalized blocks,
+//!   handles acknowledgements from the application, and requests repairs when gaps are detected.
+//!   Used with [`Coding`] as the variant type parameter.
+//! - [`crate::marshal::core::Mailbox`]: Accepts requests from other local subsystems and forwards
+//!   them to the actor. Used with [`Coding`] as the variant type parameter.
+//! - [`shards::Engine`]: Broadcasts shards, verifies locally held fragments, and reconstructs
+//!   entire [`types::CodedBlock`]s on demand.
+//! - [`crate::marshal::resolver`]: Issues outbound fetches to remote peers when marshal is missing
+//!   a block, notarization, or finalization referenced by consensus.
+//! - [`types`]: Defines commitments, distribution shards, and helper builders used across the
+//!   module.
+//! - [`Marshaled`]: Wraps an [`crate::Application`] implementation so it automatically enforces
+//!   epoch boundaries and performs erasure encoding before a proposal leaves the application.
+//!
+//! # Data Flow
+//!
+//! 1. The application produces a block through [`Marshaled`], which encodes the payload and
+//!    obtains a [`crate::types::coding::Commitment`] describing the shard layout.
+//! 2. The block is broadcast via [`shards::Engine`]; each participant receives exactly one shard
+//!    and reshares it to everyone else once it verifies the fragment.
+//! 3. The actor ingests notarizations/finalizations from `simplex`, pulls reconstructed blocks
+//!    from the shard engine or backfills them through [`crate::marshal::resolver`], and durably
+//!    persists the ordered data.
+//! 4. The actor reports finalized blocks to the node's [`crate::Reporter`] at-least-once and
+//!    drives repair loops whenever notarizations reference yet-to-be-delivered payloads.
+//!
+//! # Storage and Repair
+//!
+//! Notarized data and certificates live in prunable archives managed internally, while finalized
+//! blocks are migrated into immutable archives. Any gaps are filled by asking peers for specific
+//! commitments through the resolver pipeline. The shard engine keeps only ephemeral, in-memory
+//! caches; once a block is finalized it is evicted from the reconstruction map, reducing memory
+//! pressure.
+//!
+//! # When to Use
+//!
+//! Choose this module when the consensus deployment wants erasure-coded dissemination with the
+//! same ordering guarantees provided by [`super::standard`]. The API is a breaking change from
+//! the standard marshal: applications must adapt to the coding-specific variant type and buffer
+//! implementation required by this module.
+
+pub mod shards;
+pub mod types;
+
+mod variant;
+pub use variant::Coding;
+
+mod marshaled;
+pub use marshaled::{Marshaled, MarshaledConfig};
+
+#[cfg(test)]
+mod tests {
+    use crate::{
+        marshal::{
+            coding::{
+                types::{coding_config_for_participants, CodedBlock},
+                Marshaled, MarshaledConfig,
+            },
+            mocks::{
+                harness::{
+                    self, default_leader, genesis_commitment, make_coding_block, setup_network,
+                    setup_network_links, CodingB, CodingCtx, CodingHarness, TestHarness,
+                    BLOCKS_PER_EPOCH, LINK, NAMESPACE, NUM_VALIDATORS, QUORUM, S, UNRELIABLE_LINK,
+                    V,
+                },
+                verifying::MockVerifyingApp,
+            },
+        },
+        simplex::{scheme::bls12381_threshold::vrf as bls12381_threshold_vrf, types::Proposal},
+        types::{coding::Commitment, Epoch, Epocher, FixedEpocher, Height, Round, View},
+        Automaton, CertifiableAutomaton,
+    };
+    use commonware_codec::FixedSize;
+    use commonware_coding::ReedSolomon;
+    use commonware_cryptography::{
+        certificate::{mocks::Fixture, ConstantProvider},
+        sha256::Sha256,
+        Committable, Digestible, Hasher as _,
+    };
+    use commonware_macros::{select, test_traced};
+    use commonware_p2p::Manager;
+    use commonware_parallel::Sequential;
+    use commonware_runtime::{deterministic, Clock, Metrics, Runner};
+    use commonware_utils::NZU16;
+    use std::time::Duration;
+
+    #[test_traced("WARN")]
+    fn test_coding_finalize_good_links() {
+        for seed in 0..5 {
+            let r1 = harness::finalize::<CodingHarness>(seed, LINK, false);
+            let r2 = harness::finalize::<CodingHarness>(seed, LINK, false);
+            assert_eq!(r1, r2);
+        }
+    }
+
+    #[test_traced("WARN")]
+    fn test_coding_finalize_bad_links() {
+        for seed in 0..5 {
+            let r1 = harness::finalize::<CodingHarness>(seed, UNRELIABLE_LINK, false);
+            let r2 = harness::finalize::<CodingHarness>(seed, UNRELIABLE_LINK, false);
+            assert_eq!(r1, r2);
+        }
+    }
+
+    #[test_traced("WARN")]
+    fn test_coding_finalize_good_links_quorum_sees_finalization() {
+        for seed in 0..5 {
+            let r1 = harness::finalize::<CodingHarness>(seed, LINK, true);
+            let r2 = harness::finalize::<CodingHarness>(seed, LINK, true);
+            assert_eq!(r1, r2);
+        }
+    }
+
+    #[test_traced("WARN")]
+    fn test_coding_finalize_bad_links_quorum_sees_finalization() {
+        for seed in 0..5 {
+            let r1 = harness::finalize::<CodingHarness>(seed, UNRELIABLE_LINK, true);
+            let r2 = harness::finalize::<CodingHarness>(seed, UNRELIABLE_LINK, true);
+            assert_eq!(r1, r2);
+        }
+    }
+
+    #[test_traced("WARN")]
+    fn test_coding_ack_pipeline_backlog() {
+        harness::ack_pipeline_backlog::<CodingHarness>();
+    }
+
+    #[test_traced("WARN")]
+    fn test_coding_ack_pipeline_backlog_persists_on_restart() {
+        harness::ack_pipeline_backlog_persists_on_restart::<CodingHarness>();
+    }
+
+    #[test_traced("WARN")]
+    fn test_coding_sync_height_floor() {
+        harness::sync_height_floor::<CodingHarness>();
+    }
+
+    #[test_traced("WARN")]
+    fn test_coding_prune_finalized_archives() {
+        harness::prune_finalized_archives::<CodingHarness>();
+    }
+
+    #[test_traced("WARN")]
+    fn test_coding_rejects_block_delivery_below_floor() {
+        harness::reject_stale_block_delivery_after_floor_update::<CodingHarness>();
+    }
+
+    #[test_traced("WARN")]
+    fn test_coding_subscribe_basic_block_delivery() {
+        harness::subscribe_basic_block_delivery::<CodingHarness>();
+    }
+
+    #[test_traced("WARN")]
+    fn test_coding_subscribe_multiple_subscriptions() {
+        harness::subscribe_multiple_subscriptions::<CodingHarness>();
+    }
+
+    #[test_traced("WARN")]
+    fn test_coding_subscribe_canceled_subscriptions() {
+        harness::subscribe_canceled_subscriptions::<CodingHarness>();
+    }
+
+    #[test_traced("WARN")]
+    fn test_coding_subscribe_blocks_from_different_sources() {
+        harness::subscribe_blocks_from_different_sources::<CodingHarness>();
+    }
+
+    #[test_traced("WARN")]
+    fn test_coding_get_info_basic_queries_present_and_missing() {
+        harness::get_info_basic_queries_present_and_missing::<CodingHarness>();
+    }
+
+    #[test_traced("WARN")]
+    fn test_coding_get_info_latest_progression_multiple_finalizations() {
+        harness::get_info_latest_progression_multiple_finalizations::<CodingHarness>();
+    }
+
+    #[test_traced("WARN")]
+    fn test_coding_get_block_by_height_and_latest() {
+        harness::get_block_by_height_and_latest::<CodingHarness>();
+    }
+
+    #[test_traced("WARN")]
+    fn test_coding_get_block_by_commitment_from_sources_and_missing() {
+        harness::get_block_by_commitment_from_sources_and_missing::<CodingHarness>();
+    }
+
+    #[test_traced("WARN")]
+    fn test_coding_get_finalization_by_height() {
+        harness::get_finalization_by_height::<CodingHarness>();
+    }
+
+    #[test_traced("WARN")]
+    fn test_coding_hint_finalized_triggers_fetch() {
+        harness::hint_finalized_triggers_fetch::<CodingHarness>();
+    }
+
+    #[test_traced("WARN")]
+    fn test_coding_ancestry_stream() {
+        harness::ancestry_stream::<CodingHarness>();
+    }
+
+    #[test_traced("WARN")]
+    fn test_coding_finalize_same_height_different_views() {
+        harness::finalize_same_height_different_views::<CodingHarness>();
+    }
+
+    #[test_traced("WARN")]
+    fn test_coding_init_processed_height() {
+        harness::init_processed_height::<CodingHarness>();
+    }
+
+    #[test_traced("INFO")]
+    fn test_coding_broadcast_caches_block() {
+        harness::broadcast_caches_block::<CodingHarness>();
+    }
+
+    /// Test that certifying a lower-view block after a higher-view block succeeds.
+    ///
+    /// This is a critical test for crash recovery scenarios where a validator may need
+    /// to certify blocks in non-sequential view order.
+    #[test_traced("INFO")]
+    fn test_certify_lower_view_after_higher_view() {
+        let runner = deterministic::Runner::timed(Duration::from_secs(60));
+        runner.start(|mut context| async move {
+            let mut oracle = setup_network(context.clone(), None);
+            let Fixture {
+                participants,
+                schemes,
+                ..
+            } = bls12381_threshold_vrf::fixture::<V, _>(&mut context, NAMESPACE, NUM_VALIDATORS);
+
+            let me = participants[0].clone();
+            let coding_config = coding_config_for_participants(NUM_VALIDATORS as u16);
+
+            let setup = CodingHarness::setup_validator(
+                context.with_label("validator_0"),
+                &mut oracle,
+                me.clone(),
+                ConstantProvider::new(schemes[0].clone()),
+            )
+            .await;
+            let marshal = setup.mailbox;
+            let shards = setup.extra;
+
+            let genesis_ctx = CodingCtx {
+                round: Round::zero(),
+                leader: default_leader(),
+                parent: (View::zero(), genesis_commitment()),
+            };
+            let genesis = make_coding_block(genesis_ctx, Sha256::hash(b""), Height::zero(), 0);
+
+            let mock_app: MockVerifyingApp<CodingB, S> = MockVerifyingApp::new(genesis.clone());
+
+            let cfg = MarshaledConfig {
+                application: mock_app,
+                marshal: marshal.clone(),
+                shards: shards.clone(),
+                scheme_provider: ConstantProvider::new(schemes[0].clone()),
+                epocher: FixedEpocher::new(BLOCKS_PER_EPOCH),
+                strategy: Sequential,
+            };
+            let mut marshaled = Marshaled::new(context.clone(), cfg);
+
+            // Create parent block at height 1
+            let parent_ctx = CodingCtx {
+                round: Round::new(Epoch::new(0), View::new(1)),
+                leader: default_leader(),
+                parent: (View::zero(), genesis_commitment()),
+            };
+            let parent = make_coding_block(parent_ctx, genesis.digest(), Height::new(1), 100);
+            let parent_digest = parent.digest();
+            let coded_parent = CodedBlock::new(parent.clone(), coding_config, &Sequential);
+            let parent_commitment = coded_parent.commitment();
+            shards
+                .clone()
+                .proposed(Round::new(Epoch::new(0), View::new(1)), coded_parent)
+                .await;
+
+            // Block A at view 5 (height 2) - create with context matching what verify will receive
+            let round_a = Round::new(Epoch::new(0), View::new(5));
+            let context_a = CodingCtx {
+                round: round_a,
+                leader: me.clone(),
+                parent: (View::new(1), parent_commitment),
+            };
+            let block_a = make_coding_block(context_a.clone(), parent_digest, Height::new(2), 200);
+            let coded_block_a = CodedBlock::new(block_a.clone(), coding_config, &Sequential);
+            let commitment_a = coded_block_a.commitment();
+            shards.clone().proposed(round_a, coded_block_a).await;
+
+            // Block B at view 10 (height 2, different block same height - could happen with
+            // different proposers or re-proposals)
+            let round_b = Round::new(Epoch::new(0), View::new(10));
+            let context_b = CodingCtx {
+                round: round_b,
+                leader: me.clone(),
+                parent: (View::new(1), parent_commitment),
+            };
+            let block_b = make_coding_block(context_b.clone(), parent_digest, Height::new(2), 300);
+            let coded_block_b = CodedBlock::new(block_b.clone(), coding_config, &Sequential);
+            let commitment_b = coded_block_b.commitment();
+            shards.clone().proposed(round_b, coded_block_b).await;
+
+            context.sleep(Duration::from_millis(10)).await;
+
+            // Step 1: Verify block A at view 5
+            let _ = marshaled.verify(context_a, commitment_a).await.await;
+
+            // Step 2: Verify block B at view 10
+            let _ = marshaled.verify(context_b, commitment_b).await.await;
+
+            // Step 3: Certify block B at view 10 FIRST
+            let certify_b = marshaled.certify(round_b, commitment_b).await;
+            assert!(
+                certify_b.await.unwrap(),
+                "Block B certification should succeed"
+            );
+
+            // Step 4: Certify block A at view 5 - should succeed
+            let certify_a = marshaled.certify(round_a, commitment_a).await;
+
+            // Use select with timeout to detect never-resolving receiver
+            select! {
+                result = certify_a => {
+                    assert!(result.unwrap(), "Block A certification should succeed");
+                },
+                _ = context.sleep(Duration::from_secs(5)) => {
+                    panic!("Block A certification timed out");
+                },
+            }
+        })
+    }
+
+    /// Regression test for re-proposal validation in optimistic_verify.
+    ///
+    /// Verifies that:
+    /// 1. Valid re-proposals at epoch boundaries are accepted
+    /// 2. Invalid re-proposals (not at epoch boundary) are rejected
+    ///
+    /// A re-proposal occurs when the parent digest equals the block being verified,
+    /// meaning the same block is being proposed again in a new view.
+    #[test_traced("INFO")]
+    fn test_marshaled_reproposal_validation() {
+        let runner = deterministic::Runner::timed(Duration::from_secs(60));
+        runner.start(|mut context| async move {
+            let mut oracle = setup_network(context.clone(), None);
+            let Fixture {
+                participants,
+                schemes,
+                ..
+            } = bls12381_threshold_vrf::fixture::<V, _>(&mut context, NAMESPACE, NUM_VALIDATORS);
+
+            let me = participants[0].clone();
+            let coding_config = coding_config_for_participants(NUM_VALIDATORS as u16);
+
+            let setup = CodingHarness::setup_validator(
+                context.with_label("validator_0"),
+                &mut oracle,
+                me.clone(),
+                ConstantProvider::new(schemes[0].clone()),
+            )
+            .await;
+            let marshal = setup.mailbox;
+            let shards = setup.extra;
+
+            let genesis_ctx = CodingCtx {
+                round: Round::zero(),
+                leader: default_leader(),
+                parent: (View::zero(), genesis_commitment()),
+            };
+            let genesis = make_coding_block(genesis_ctx, Sha256::hash(b""), Height::zero(), 0);
+
+            let mock_app: MockVerifyingApp<CodingB, S> = MockVerifyingApp::new(genesis.clone());
+            let cfg = MarshaledConfig {
+                application: mock_app,
+                marshal: marshal.clone(),
+                shards: shards.clone(),
+                scheme_provider: ConstantProvider::new(schemes[0].clone()),
+                epocher: FixedEpocher::new(BLOCKS_PER_EPOCH),
+                strategy: Sequential,
+            };
+            let mut marshaled = Marshaled::new(context.clone(), cfg);
+
+            // Build a chain up to the epoch boundary (height 19 is the last block in epoch 0
+            // with BLOCKS_PER_EPOCH=20, since epoch 0 covers heights 0-19)
+            let mut parent = genesis.digest();
+            let mut last_view = View::zero();
+            let mut last_commitment = genesis_commitment();
+            for i in 1..BLOCKS_PER_EPOCH.get() {
+                let round = Round::new(Epoch::new(0), View::new(i));
+                let ctx = CodingCtx {
+                    round,
+                    leader: me.clone(),
+                    parent: (last_view, last_commitment),
+                };
+                let block = make_coding_block(ctx.clone(), parent, Height::new(i), i * 100);
+                let coded_block = CodedBlock::new(block.clone(), coding_config, &Sequential);
+                last_commitment = coded_block.commitment();
+                shards.clone().proposed(round, coded_block).await;
+                parent = block.digest();
+                last_view = View::new(i);
+            }
+
+            // Create the epoch boundary block (height 19, last block in epoch 0)
+            let boundary_height = Height::new(BLOCKS_PER_EPOCH.get() - 1);
+            let boundary_round = Round::new(Epoch::new(0), View::new(boundary_height.get()));
+            let boundary_context = CodingCtx {
+                round: boundary_round,
+                leader: me.clone(),
+                parent: (last_view, last_commitment),
+            };
+            let boundary_block = make_coding_block(
+                boundary_context.clone(),
+                parent,
+                boundary_height,
+                boundary_height.get() * 100,
+            );
+            let coded_boundary =
+                CodedBlock::new(boundary_block.clone(), coding_config, &Sequential);
+            let boundary_commitment = coded_boundary.commitment();
+            shards
+                .clone()
+                .proposed(boundary_round, coded_boundary)
+                .await;
+
+            context.sleep(Duration::from_millis(10)).await;
+
+            // Test 1: Valid re-proposal at epoch boundary should be accepted
+            // Re-proposal context: parent digest equals the block being verified
+            // Re-proposals happen within the same epoch when the parent is the last block
+            //
+            // In the coding marshal, verify() returns shard validity while deferred_verify
+            // runs in the background. We call verify() to register the verification task,
+            // then certify() returns the deferred_verify result.
+            let reproposal_round = Round::new(Epoch::new(0), View::new(20));
+            let reproposal_context = CodingCtx {
+                round: reproposal_round,
+                leader: me.clone(),
+                parent: (View::new(boundary_height.get()), boundary_commitment), // Parent IS the boundary block
+            };
+
+            // Call verify to kick off deferred verification.
+            // We must await the verify result to ensure the verification task is
+            // registered before calling certify.
+            let shard_validity = marshaled
+                .verify(reproposal_context.clone(), boundary_commitment)
+                .await
+                .await;
+            assert!(
+                shard_validity.unwrap(),
+                "Re-proposal verify should return true for shard validity"
+            );
+
+            // Use certify to get the actual deferred_verify result
+            let certify_result = marshaled
+                .certify(reproposal_round, boundary_commitment)
+                .await
+                .await;
+            assert!(
+                certify_result.unwrap(),
+                "Valid re-proposal at epoch boundary should be accepted"
+            );
+
+            // Test 2: Invalid re-proposal (not at epoch boundary) should be rejected
+            // Create a block at height 10 (not at epoch boundary)
+            let non_boundary_height = Height::new(10);
+            let non_boundary_round = Round::new(Epoch::new(0), View::new(10));
+            // For simplicity, we'll create a fresh non-boundary block and test re-proposal
+            let non_boundary_context = CodingCtx {
+                round: non_boundary_round,
+                leader: me.clone(),
+                parent: (View::new(9), last_commitment), // Use a prior commitment
+            };
+            let non_boundary_block = make_coding_block(
+                non_boundary_context.clone(),
+                parent,
+                non_boundary_height,
+                1000,
+            );
+            let coded_non_boundary =
+                CodedBlock::new(non_boundary_block.clone(), coding_config, &Sequential);
+            let non_boundary_commitment = coded_non_boundary.commitment();
+
+            // Make the non-boundary block available
+            shards
+                .clone()
+                .proposed(non_boundary_round, coded_non_boundary)
+                .await;
+
+            context.sleep(Duration::from_millis(10)).await;
+
+            // Attempt to re-propose the non-boundary block
+            let invalid_reproposal_round = Round::new(Epoch::new(0), View::new(15));
+            let invalid_reproposal_context = CodingCtx {
+                round: invalid_reproposal_round,
+                leader: me.clone(),
+                parent: (View::new(10), non_boundary_commitment),
+            };
+
+            // Call verify to kick off deferred verification.
+            // We must await the verify result to ensure the verification task is
+            // registered before calling certify.
+            let shard_validity = marshaled
+                .verify(invalid_reproposal_context, non_boundary_commitment)
+                .await
+                .await;
+            assert!(
+                !shard_validity.unwrap(),
+                "Invalid re-proposal verify should return false"
+            );
+
+            // Use certify to get the actual deferred_verify result
+            let certify_result = marshaled
+                .certify(invalid_reproposal_round, non_boundary_commitment)
+                .await
+                .await;
+            assert!(
+                !certify_result.unwrap(),
+                "Invalid re-proposal (not at epoch boundary) should be rejected"
+            );
+
+            // Test 3: Re-proposal with mismatched epoch should be rejected
+            // This is a regression test - re-proposals must be in the same epoch as the block.
+            let cross_epoch_reproposal_round = Round::new(Epoch::new(1), View::new(20));
+            let cross_epoch_reproposal_context = CodingCtx {
+                round: cross_epoch_reproposal_round,
+                leader: me.clone(),
+                parent: (View::new(boundary_height.get()), boundary_commitment),
+            };
+
+            // Call verify to kick off deferred verification.
+            // We must await the verify result to ensure the verification task is
+            // registered before calling certify.
+            let shard_validity = marshaled
+                .verify(cross_epoch_reproposal_context.clone(), boundary_commitment)
+                .await
+                .await;
+            assert!(
+                !shard_validity.unwrap(),
+                "Cross-epoch re-proposal verify should return false"
+            );
+
+            // Use certify to get the actual deferred_verify result
+            let certify_result = marshaled
+                .certify(cross_epoch_reproposal_round, boundary_commitment)
+                .await
+                .await;
+            assert!(
+                !certify_result.unwrap(),
+                "Re-proposal with mismatched epoch should be rejected"
+            );
+
+            // Note: Tests for certify-only paths (crash recovery scenarios) are not included here
+            // because they require multiple validators to reconstruct blocks from shards. In a
+            // single-validator test setup, block reconstruction fails due to insufficient shards.
+            // These paths are tested in integration tests with multiple validators.
+        })
+    }
+
+    #[test_traced("WARN")]
+    fn test_marshaled_rejects_mismatched_context_hash() {
+        let runner = deterministic::Runner::timed(Duration::from_secs(30));
+        runner.start(|mut context| async move {
+            let mut oracle = setup_network(context.clone(), None);
+            let Fixture {
+                participants,
+                schemes,
+                ..
+            } = bls12381_threshold_vrf::fixture::<V, _>(&mut context, NAMESPACE, NUM_VALIDATORS);
+
+            let me = participants[0].clone();
+            let coding_config = coding_config_for_participants(NUM_VALIDATORS as u16);
+
+            let setup = CodingHarness::setup_validator(
+                context.with_label("validator_0"),
+                &mut oracle,
+                me.clone(),
+                ConstantProvider::new(schemes[0].clone()),
+            )
+            .await;
+            let marshal = setup.mailbox;
+            let shards = setup.extra;
+
+            let genesis_ctx = CodingCtx {
+                round: Round::zero(),
+                leader: default_leader(),
+                parent: (View::zero(), genesis_commitment()),
+            };
+            let genesis = make_coding_block(genesis_ctx, Sha256::hash(b""), Height::zero(), 0);
+
+            let mock_app: MockVerifyingApp<CodingB, S> = MockVerifyingApp::new(genesis.clone());
+            let cfg = MarshaledConfig {
+                application: mock_app,
+                marshal: marshal.clone(),
+                shards: shards.clone(),
+                scheme_provider: ConstantProvider::new(schemes[0].clone()),
+                epocher: FixedEpocher::new(BLOCKS_PER_EPOCH),
+                strategy: Sequential,
+            };
+            let mut marshaled = Marshaled::new(context.clone(), cfg);
+
+            // Create parent block at height 1 so the commitment is well-formed.
+            let parent_ctx = CodingCtx {
+                round: Round::new(Epoch::zero(), View::new(1)),
+                leader: default_leader(),
+                parent: (View::zero(), genesis_commitment()),
+            };
+            let parent = make_coding_block(parent_ctx, genesis.digest(), Height::new(1), 100);
+            let coded_parent = CodedBlock::new(parent.clone(), coding_config, &Sequential);
+            let parent_commitment = coded_parent.commitment();
+            shards
+                .clone()
+                .proposed(Round::new(Epoch::zero(), View::new(1)), coded_parent)
+                .await;
+
+            // Build a block with context A (commitment hash uses this context).
+            let round_a = Round::new(Epoch::zero(), View::new(2));
+            let context_a = CodingCtx {
+                round: round_a,
+                leader: me.clone(),
+                parent: (View::new(1), parent_commitment),
+            };
+            let block_a = make_coding_block(context_a, parent.digest(), Height::new(2), 200);
+            let coded_block_a: CodedBlock<_, ReedSolomon<Sha256>> =
+                CodedBlock::new(block_a, coding_config, &Sequential);
+            let commitment_a = coded_block_a.commitment();
+
+            // Verify using a different consensus context B (hash mismatch).
+            let round_b = Round::new(Epoch::zero(), View::new(3));
+            let context_b = CodingCtx {
+                round: round_b,
+                leader: participants[1].clone(),
+                parent: (View::new(1), parent_commitment),
+            };
+
+            let verify_rx = marshaled.verify(context_b, commitment_a).await;
+            select! {
+                result = verify_rx => {
+                    assert!(
+                        !result.unwrap(),
+                        "mismatched context hash should be rejected"
+                    );
+                },
+                _ = context.sleep(Duration::from_secs(5)) => {
+                    panic!("verify should reject mismatched context hash promptly");
+                },
+            }
+        })
+    }
+
+    #[test_traced("WARN")]
+    fn test_reproposal_verify_receiver_drop_does_not_synthesize_false() {
+        let runner = deterministic::Runner::timed(Duration::from_secs(30));
+        runner.start(|mut context| async move {
+            let mut oracle = setup_network(context.clone(), None);
+            let Fixture {
+                participants,
+                schemes,
+                ..
+            } = bls12381_threshold_vrf::fixture::<V, _>(&mut context, NAMESPACE, NUM_VALIDATORS);
+
+            let me = participants[0].clone();
+            let coding_config = coding_config_for_participants(NUM_VALIDATORS as u16);
+
+            let setup = CodingHarness::setup_validator(
+                context.with_label("validator_0"),
+                &mut oracle,
+                me.clone(),
+                ConstantProvider::new(schemes[0].clone()),
+            )
+            .await;
+            let marshal = setup.mailbox;
+            let shards = setup.extra;
+
+            let genesis_ctx = CodingCtx {
+                round: Round::zero(),
+                leader: default_leader(),
+                parent: (View::zero(), genesis_commitment()),
+            };
+            let genesis = make_coding_block(genesis_ctx, Sha256::hash(b""), Height::zero(), 0);
+
+            let mock_app: MockVerifyingApp<CodingB, S> = MockVerifyingApp::new(genesis.clone());
+            let cfg = MarshaledConfig {
+                application: mock_app,
+                marshal: marshal.clone(),
+                shards: shards.clone(),
+                scheme_provider: ConstantProvider::new(schemes[0].clone()),
+                epocher: FixedEpocher::new(BLOCKS_PER_EPOCH),
+                strategy: Sequential,
+            };
+            let mut marshaled = Marshaled::new(context.clone(), cfg);
+
+            // Re-proposal payload with valid coding config, but no block available.
+            let missing_payload = Commitment::from((
+                Sha256::hash(b"missing_block"),
+                Sha256::hash(b"missing_root"),
+                Sha256::hash(b"missing_context"),
+                coding_config,
+            ));
+            let round = Round::new(Epoch::zero(), View::new(1));
+            let reproposal_context = CodingCtx {
+                round,
+                leader: me,
+                parent: (View::zero(), missing_payload),
+            };
+
+            // Start verify, then drop the receiver immediately.
+            let verify_rx = marshaled.verify(reproposal_context, missing_payload).await;
+            drop(verify_rx);
+
+            // Certify should resolve promptly from the in-progress task, but must
+            // not synthesize `false` when verification was canceled before a verdict.
+            let certify_rx = marshaled.certify(round, missing_payload).await;
+            select! {
+                result = certify_rx => {
+                    assert!(
+                        result.is_err(),
+                        "certify should resolve without an explicit verdict when verify receiver is dropped"
+                    );
+                },
+                _ = context.sleep(Duration::from_secs(5)) => {
+                    panic!("certify task should resolve promptly after verify receiver drop");
+                },
+            }
+        })
+    }
+
+    #[test_traced("WARN")]
+    fn test_reproposal_missing_block_does_not_synthesize_false() {
+        let runner = deterministic::Runner::timed(Duration::from_secs(30));
+        runner.start(|mut context| async move {
+            let mut oracle = setup_network(context.clone(), None);
+            let Fixture {
+                participants,
+                schemes,
+                ..
+            } = bls12381_threshold_vrf::fixture::<V, _>(&mut context, NAMESPACE, NUM_VALIDATORS);
+
+            let me = participants[0].clone();
+            let coding_config = coding_config_for_participants(NUM_VALIDATORS as u16);
+
+            let setup = CodingHarness::setup_validator(
+                context.with_label("validator_0"),
+                &mut oracle,
+                me.clone(),
+                ConstantProvider::new(schemes[0].clone()),
+            )
+            .await;
+            let marshal = setup.mailbox;
+            let shards = setup.extra;
+
+            let genesis_ctx = CodingCtx {
+                round: Round::zero(),
+                leader: default_leader(),
+                parent: (View::zero(), genesis_commitment()),
+            };
+            let genesis = make_coding_block(genesis_ctx, Sha256::hash(b""), Height::zero(), 0);
+
+            let mock_app: MockVerifyingApp<CodingB, S> = MockVerifyingApp::new(genesis.clone());
+            let cfg = MarshaledConfig {
+                application: mock_app,
+                marshal: marshal.clone(),
+                shards: shards.clone(),
+                scheme_provider: ConstantProvider::new(schemes[0].clone()),
+                epocher: FixedEpocher::new(BLOCKS_PER_EPOCH),
+                strategy: Sequential,
+            };
+            let mut marshaled = Marshaled::new(context.clone(), cfg);
+
+            // Re-proposal payload with valid coding config, but no block available.
+            let missing_payload = Commitment::from((
+                Sha256::hash(b"missing_block"),
+                Sha256::hash(b"missing_root"),
+                Sha256::hash(b"missing_context"),
+                coding_config,
+            ));
+            let round = Round::new(Epoch::zero(), View::new(1));
+            let reproposal_context = CodingCtx {
+                round,
+                leader: me,
+                parent: (View::zero(), missing_payload),
+            };
+
+            // Verify must not synthesize `false` when the block cannot be fetched.
+            let verify_rx = marshaled.verify(reproposal_context, missing_payload).await;
+
+            // Ensure the verification task has registered its subscription, then
+            // force cancellation by pruning the missing commitment.
+            context.sleep(Duration::from_millis(100)).await;
+            shards.prune(missing_payload).await;
+
+            select! {
+                result = verify_rx => {
+                    assert!(
+                        result.is_err(),
+                        "verify should resolve without explicit false when re-proposal block is unavailable"
+                    );
+                },
+                _ = context.sleep(Duration::from_secs(5)) => {
+                    panic!("verify should resolve promptly when re-proposal block is unavailable");
+                },
+            }
+
+            // Certify should consume the same unresolved verification task.
+            let certify_rx = marshaled.certify(round, missing_payload).await;
+            select! {
+                result = certify_rx => {
+                    assert!(
+                        result.is_err(),
+                        "certify should resolve without explicit false when re-proposal block is unavailable"
+                    );
+                },
+                _ = context.sleep(Duration::from_secs(5)) => {
+                    panic!("certify should resolve promptly when re-proposal block is unavailable");
+                },
+            }
+        })
+    }
+
+    #[test_traced("WARN")]
+    fn test_core_subscription_closes_when_coding_buffer_prunes_missing_commitment() {
+        let runner = deterministic::Runner::timed(Duration::from_secs(30));
+        runner.start(|mut context| async move {
+            let mut oracle = setup_network(context.clone(), None);
+            let Fixture {
+                participants,
+                schemes,
+                ..
+            } = bls12381_threshold_vrf::fixture::<V, _>(&mut context, NAMESPACE, NUM_VALIDATORS);
+
+            let setup = CodingHarness::setup_validator(
+                context.with_label("validator_0"),
+                &mut oracle,
+                participants[0].clone(),
+                ConstantProvider::new(schemes[0].clone()),
+            )
+            .await;
+            let marshal = setup.mailbox;
+            let shards = setup.extra;
+
+            let coding_config = coding_config_for_participants(NUM_VALIDATORS as u16);
+            let missing_commitment = Commitment::from((
+                Sha256::hash(b"missing_block"),
+                Sha256::hash(b"missing_root"),
+                Sha256::hash(b"missing_context"),
+                coding_config,
+            ));
+            let round = Round::new(Epoch::zero(), View::new(1));
+
+            // Subscribe through the core actor. This internally subscribes to the
+            // coding shard buffer and registers local waiters.
+            let block_rx = marshal
+                .subscribe_by_commitment(Some(round), missing_commitment)
+                .await;
+
+            // Allow core actor to register the underlying buffer subscription.
+            context.sleep(Duration::from_millis(100)).await;
+
+            // Prune the missing commitment in the shard engine, which should cancel
+            // the underlying buffer subscription.
+            shards.prune(missing_commitment).await;
+
+            // The core actor must surface cancellation by closing the subscription,
+            // not by panicking or leaving the waiter parked indefinitely.
+            select! {
+                result = block_rx => {
+                    assert!(
+                        result.is_err(),
+                        "core subscription should close when coding buffer drops subscription"
+                    );
+                },
+                _ = context.sleep(Duration::from_secs(5)) => {
+                    panic!("core subscription should resolve promptly after coding prune");
+                },
+            }
+        })
+    }
+
+    #[test_traced("WARN")]
+    fn test_marshaled_rejects_unsupported_epoch() {
+        #[derive(Clone)]
+        struct LimitedEpocher {
+            inner: FixedEpocher,
+            max_epoch: u64,
+        }
+
+        impl Epocher for LimitedEpocher {
+            fn containing(&self, height: Height) -> Option<crate::types::EpochInfo> {
+                let bounds = self.inner.containing(height)?;
+                if bounds.epoch().get() > self.max_epoch {
+                    None
+                } else {
+                    Some(bounds)
+                }
+            }
+
+            fn first(&self, epoch: Epoch) -> Option<Height> {
+                if epoch.get() > self.max_epoch {
+                    None
+                } else {
+                    self.inner.first(epoch)
+                }
+            }
+
+            fn last(&self, epoch: Epoch) -> Option<Height> {
+                if epoch.get() > self.max_epoch {
+                    None
+                } else {
+                    self.inner.last(epoch)
+                }
+            }
+        }
+
+        let runner = deterministic::Runner::timed(Duration::from_secs(60));
+        runner.start(|mut context| async move {
+            let mut oracle = setup_network(context.clone(), None);
+            let Fixture {
+                participants,
+                schemes,
+                ..
+            } = bls12381_threshold_vrf::fixture::<V, _>(&mut context, NAMESPACE, NUM_VALIDATORS);
+
+            let me = participants[0].clone();
+            let coding_config = coding_config_for_participants(NUM_VALIDATORS as u16);
+
+            let setup = CodingHarness::setup_validator(
+                context.with_label("validator_0"),
+                &mut oracle,
+                me.clone(),
+                ConstantProvider::new(schemes[0].clone()),
+            )
+            .await;
+            let marshal = setup.mailbox;
+            let shards = setup.extra;
+
+            let genesis_ctx = CodingCtx {
+                round: Round::zero(),
+                leader: default_leader(),
+                parent: (View::zero(), genesis_commitment()),
+            };
+            let genesis = make_coding_block(genesis_ctx, Sha256::hash(b""), Height::zero(), 0);
+
+            let mock_app: MockVerifyingApp<CodingB, S> = MockVerifyingApp::new(genesis.clone());
+            let limited_epocher = LimitedEpocher {
+                inner: FixedEpocher::new(BLOCKS_PER_EPOCH),
+                max_epoch: 0,
+            };
+            let cfg = MarshaledConfig {
+                application: mock_app,
+                marshal: marshal.clone(),
+                shards: shards.clone(),
+                scheme_provider: ConstantProvider::new(schemes[0].clone()),
+                epocher: limited_epocher,
+                strategy: Sequential,
+            };
+            let mut marshaled = Marshaled::new(context.clone(), cfg);
+
+            // Create a parent block at height 19 (last block in epoch 0, which is supported)
+            let parent_ctx = CodingCtx {
+                round: Round::new(Epoch::zero(), View::new(19)),
+                leader: default_leader(),
+                parent: (View::zero(), genesis_commitment()),
+            };
+            let parent = make_coding_block(parent_ctx, genesis.digest(), Height::new(19), 1000);
+            let parent_digest = parent.digest();
+            let coded_parent = CodedBlock::new(parent.clone(), coding_config, &Sequential);
+            let parent_commitment = coded_parent.commitment();
+            shards
+                .clone()
+                .proposed(Round::new(Epoch::zero(), View::new(19)), coded_parent)
+                .await;
+
+            // Create a block at height 20 (first block in epoch 1, which is NOT supported)
+            let block_ctx = CodingCtx {
+                round: Round::new(Epoch::new(1), View::new(20)),
+                leader: default_leader(),
+                parent: (View::new(19), parent_commitment),
+            };
+            let block = make_coding_block(block_ctx, parent_digest, Height::new(20), 2000);
+            let coded_block = CodedBlock::new(block.clone(), coding_config, &Sequential);
+            let block_commitment = coded_block.commitment();
+            shards
+                .clone()
+                .proposed(Round::new(Epoch::new(1), View::new(20)), coded_block)
+                .await;
+
+            context.sleep(Duration::from_millis(10)).await;
+
+            // In the coding marshal, verify() returns shard validity while deferred_verify
+            // runs in the background. We need to use certify() to get the deferred_verify result.
+            let unsupported_round = Round::new(Epoch::new(1), View::new(20));
+            let unsupported_context = CodingCtx {
+                round: unsupported_round,
+                leader: me.clone(),
+                parent: (View::new(19), parent_commitment),
+            };
+
+            // Call verify to kick off deferred verification
+            let _shard_validity = marshaled
+                .verify(unsupported_context, block_commitment)
+                .await;
+
+            // Use certify to get the actual deferred_verify result
+            let certify_result = marshaled
+                .certify(unsupported_round, block_commitment)
+                .await
+                .await;
+
+            assert!(
+                !certify_result.unwrap(),
+                "Block in unsupported epoch should be rejected"
+            );
+        })
+    }
+
+    #[test_traced("WARN")]
+    fn test_marshaled_rejects_invalid_ancestry() {
+        let runner = deterministic::Runner::timed(Duration::from_secs(60));
+        runner.start(|mut context| async move {
+            let mut oracle = setup_network(context.clone(), None);
+            let Fixture {
+                participants,
+                schemes,
+                ..
+            } = bls12381_threshold_vrf::fixture::<V, _>(&mut context, NAMESPACE, NUM_VALIDATORS);
+
+            let me = participants[0].clone();
+            let coding_config = coding_config_for_participants(NUM_VALIDATORS as u16);
+
+            let setup = CodingHarness::setup_validator(
+                context.with_label("validator_0"),
+                &mut oracle,
+                me.clone(),
+                ConstantProvider::new(schemes[0].clone()),
+            )
+            .await;
+            let marshal = setup.mailbox;
+            let shards = setup.extra;
+
+            // Create genesis block
+            let genesis_ctx = CodingCtx {
+                round: Round::zero(),
+                leader: default_leader(),
+                parent: (View::zero(), genesis_commitment()),
+            };
+            let genesis = make_coding_block(genesis_ctx, Sha256::hash(b""), Height::zero(), 0);
+
+            // Wrap with Marshaled verifier
+            let mock_app: MockVerifyingApp<CodingB, S> = MockVerifyingApp::new(genesis.clone());
+            let cfg = MarshaledConfig {
+                application: mock_app,
+                marshal: marshal.clone(),
+                shards: shards.clone(),
+                scheme_provider: ConstantProvider::new(schemes[0].clone()),
+                epocher: FixedEpocher::new(BLOCKS_PER_EPOCH),
+                strategy: Sequential,
+            };
+            let mut marshaled = Marshaled::new(context.clone(), cfg);
+
+            // Test case 1: Non-contiguous height
+            //
+            // We need both blocks in the same epoch.
+            // With BLOCKS_PER_EPOCH=20: epoch 0 is heights 0-19, epoch 1 is heights 20-39
+            //
+            // Store honest parent at height 21 (epoch 1)
+            let honest_parent_ctx = CodingCtx {
+                round: Round::new(Epoch::new(1), View::new(21)),
+                leader: default_leader(),
+                parent: (View::zero(), genesis_commitment()),
+            };
+            let honest_parent = make_coding_block(
+                honest_parent_ctx,
+                genesis.digest(),
+                Height::new(BLOCKS_PER_EPOCH.get() + 1),
+                1000,
+            );
+            let parent_digest = honest_parent.digest();
+            let coded_parent = CodedBlock::new(honest_parent.clone(), coding_config, &Sequential);
+            let parent_commitment = coded_parent.commitment();
+            shards
+                .clone()
+                .proposed(Round::new(Epoch::new(1), View::new(21)), coded_parent)
+                .await;
+
+            // Byzantine proposer broadcasts malicious block at height 35
+            // The block has the correct context (matching what consensus will provide)
+            // but contains invalid content (non-contiguous height: 21 -> 35 instead of 21 -> 22)
+            let byzantine_round = Round::new(Epoch::new(1), View::new(35));
+            let byzantine_context = CodingCtx {
+                round: byzantine_round,
+                leader: me.clone(),
+                parent: (View::new(21), parent_commitment), // Consensus says parent is at height 21
+            };
+            let malicious_block = make_coding_block(
+                byzantine_context.clone(),
+                parent_digest,
+                Height::new(BLOCKS_PER_EPOCH.get() + 15), // Byzantine: non-contiguous height
+                2000,
+            );
+            let coded_malicious =
+                CodedBlock::new(malicious_block.clone(), coding_config, &Sequential);
+            let malicious_commitment = coded_malicious.commitment();
+            shards
+                .clone()
+                .proposed(byzantine_round, coded_malicious)
+                .await;
+
+            // Small delay to ensure broadcast is processed
+            context.sleep(Duration::from_millis(10)).await;
+
+            // Marshaled.verify() kicks off deferred verification in the background.
+            // The Marshaled verifier will:
+            // 1. Fetch honest_parent (height 21) from marshal based on context.parent
+            // 2. Fetch malicious_block (height 35) from marshal based on digest
+            // 3. Validate height is contiguous (fail)
+            // 4. Return false
+            let _shard_validity = marshaled
+                .verify(byzantine_context, malicious_commitment)
+                .await;
+
+            // Use certify to get the actual deferred_verify result
+            let certify_result = marshaled
+                .certify(byzantine_round, malicious_commitment)
+                .await
+                .await;
+
+            assert!(
+                !certify_result.unwrap(),
+                "Byzantine block with non-contiguous heights should be rejected"
+            );
+
+            // Test case 2: Mismatched parent digest
+            //
+            // Create another malicious block with correct context and height
+            // but referencing the wrong parent digest (genesis instead of honest_parent)
+            let byzantine_round2 = Round::new(Epoch::new(1), View::new(22));
+            let byzantine_context2 = CodingCtx {
+                round: byzantine_round2,
+                leader: me.clone(),
+                parent: (View::new(21), parent_commitment), // Consensus says parent is at height 21
+            };
+            let malicious_block2 = make_coding_block(
+                byzantine_context2.clone(),
+                genesis.digest(), // Byzantine: wrong parent digest
+                Height::new(BLOCKS_PER_EPOCH.get() + 2),
+                3000,
+            );
+            let coded_malicious2 =
+                CodedBlock::new(malicious_block2.clone(), coding_config, &Sequential);
+            let malicious_commitment2 = coded_malicious2.commitment();
+            shards
+                .clone()
+                .proposed(byzantine_round2, coded_malicious2)
+                .await;
+
+            // Small delay to ensure broadcast is processed
+            context.sleep(Duration::from_millis(10)).await;
+
+            // Marshaled.verify() kicks off deferred verification in the background.
+            // The Marshaled verifier will:
+            // 1. Fetch honest_parent (height 21) from marshal based on context.parent
+            // 2. Fetch malicious_block (height 22) from marshal based on digest
+            // 3. Validate height is contiguous
+            // 4. Validate parent commitment matches (fail)
+            // 5. Return false
+            let _shard_validity = marshaled
+                .verify(byzantine_context2, malicious_commitment2)
+                .await;
+
+            // Use certify to get the actual deferred_verify result
+            let certify_result = marshaled
+                .certify(byzantine_round2, malicious_commitment2)
+                .await
+                .await;
+
+            assert!(
+                !certify_result.unwrap(),
+                "Byzantine block with mismatched parent commitment should be rejected"
+            );
+        })
+    }
+
+    #[test_traced("WARN")]
+    fn test_certify_without_prior_verify_crash_recovery() {
+        // After a crash, consensus may call certify() without a prior verify().
+        // The certify path (marshaled.rs:842-936) should:
+        //   1. Find no in-progress verification task
+        //   2. Subscribe to the block from the shard engine
+        //   3. Use the block's embedded context for deferred_verify
+        //   4. Return Ok(true) for a valid block
+        let runner = deterministic::Runner::timed(Duration::from_secs(30));
+        runner.start(|mut context| async move {
+            let mut oracle = setup_network(context.clone(), None);
+            let Fixture {
+                participants,
+                schemes,
+                ..
+            } = bls12381_threshold_vrf::fixture::<V, _>(&mut context, NAMESPACE, NUM_VALIDATORS);
+
+            let me = participants[0].clone();
+            let coding_config = coding_config_for_participants(NUM_VALIDATORS as u16);
+
+            let setup = CodingHarness::setup_validator(
+                context.with_label("validator_0"),
+                &mut oracle,
+                me.clone(),
+                ConstantProvider::new(schemes[0].clone()),
+            )
+            .await;
+            let marshal = setup.mailbox;
+            let shards = setup.extra;
+
+            let genesis_ctx = CodingCtx {
+                round: Round::zero(),
+                leader: default_leader(),
+                parent: (View::zero(), genesis_commitment()),
+            };
+            let genesis = make_coding_block(genesis_ctx, Sha256::hash(b""), Height::zero(), 0);
+
+            let mock_app: MockVerifyingApp<CodingB, S> = MockVerifyingApp::new(genesis.clone());
+            let cfg = MarshaledConfig {
+                application: mock_app,
+                marshal: marshal.clone(),
+                shards: shards.clone(),
+                scheme_provider: ConstantProvider::new(schemes[0].clone()),
+                epocher: FixedEpocher::new(BLOCKS_PER_EPOCH),
+                strategy: Sequential,
+            };
+            let mut marshaled = Marshaled::new(context.clone(), cfg);
+
+            // Create parent at height 1.
+            let parent_round = Round::new(Epoch::zero(), View::new(1));
+            let parent_ctx = CodingCtx {
+                round: parent_round,
+                leader: default_leader(),
+                parent: (View::zero(), genesis_commitment()),
+            };
+            let parent = make_coding_block(parent_ctx, genesis.digest(), Height::new(1), 100);
+            let coded_parent = CodedBlock::new(parent.clone(), coding_config, &Sequential);
+            let parent_commitment = coded_parent.commitment();
+            shards.clone().proposed(parent_round, coded_parent).await;
+
+            // Create child at height 2.
+            let child_round = Round::new(Epoch::zero(), View::new(2));
+            let child_ctx = CodingCtx {
+                round: child_round,
+                leader: me.clone(),
+                parent: (View::new(1), parent_commitment),
+            };
+            let child = make_coding_block(child_ctx, parent.digest(), Height::new(2), 200);
+            let coded_child = CodedBlock::new(child, coding_config, &Sequential);
+            let child_commitment = coded_child.commitment();
+            shards.clone().proposed(child_round, coded_child).await;
+
+            context.sleep(Duration::from_millis(10)).await;
+
+            // Call certify directly without any prior verify (simulating crash recovery).
+            let certify_rx = marshaled.certify(child_round, child_commitment).await;
+            select! {
+                result = certify_rx => {
+                    assert!(
+                        result.unwrap(),
+                        "certify without prior verify should succeed for valid block"
+                    );
+                },
+                _ = context.sleep(Duration::from_secs(5)) => {
+                    panic!("certify should complete within timeout");
+                },
+            }
+        })
+    }
+
+    /// Regression test: a Byzantine leader must not be able to crash honest nodes
+    /// by proposing a `Commitment` with invalid `CodingConfig` bytes (e.g.
+    /// zero-valued `NonZeroU16` fields). The fix validates the embedded config
+    /// during deserialization so malformed commitments are rejected at the codec
+    /// level before reaching `verify()`.
+    #[test_traced("WARN")]
+    fn test_malformed_commitment_config_rejected_at_deserialization() {
+        use commonware_codec::{Encode, ReadExt};
+
+        // Construct a Commitment with all-zero bytes (invalid CodingConfig:
+        // minimum_shards=0, extra_shards=0). Serialize it and attempt to
+        // deserialize -- this must fail.
+        let malformed_bytes = [0u8; Commitment::SIZE];
+        let result = Commitment::read(&mut &malformed_bytes[..]);
+        assert!(
+            result.is_err(),
+            "deserialization of Commitment with zeroed CodingConfig must fail"
+        );
+
+        // A validly-constructed Commitment must still round-trip.
+        let coding_config = coding_config_for_participants(NUM_VALIDATORS as u16);
+        let valid = Commitment::from((
+            Sha256::hash(b"block"),
+            Sha256::hash(b"root"),
+            Sha256::hash(b"context"),
+            coding_config,
+        ));
+        let encoded = valid.encode();
+        let decoded =
+            Commitment::read(&mut &encoded[..]).expect("valid Commitment must deserialize");
+        assert_eq!(valid, decoded);
+    }
+
+    #[test_traced("WARN")]
+    fn test_subscription_by_commitment_rejects_digest_alias() {
+        let runner = deterministic::Runner::timed(Duration::from_secs(30));
+        runner.start(|mut context| async move {
+            let mut oracle = setup_network(context.clone(), None);
+            let Fixture {
+                participants,
+                schemes,
+                ..
+            } = bls12381_threshold_vrf::fixture::<V, _>(&mut context, NAMESPACE, NUM_VALIDATORS);
+
+            let setup = CodingHarness::setup_validator(
+                context.with_label("validator_0"),
+                &mut oracle,
+                participants[0].clone(),
+                ConstantProvider::new(schemes[0].clone()),
+            )
+            .await;
+            let marshal = setup.mailbox;
+            let shards = setup.extra;
+
+            let coding_config_a = coding_config_for_participants(NUM_VALIDATORS as u16);
+            // Keep the total shard count unchanged while changing the commitment.
+            let coding_config_b = commonware_coding::Config {
+                minimum_shards: coding_config_a.minimum_shards.checked_add(1).unwrap(),
+                extra_shards: NZU16!(coding_config_a.extra_shards.get() - 1),
+            };
+
+            let genesis_ctx = CodingCtx {
+                round: Round::zero(),
+                leader: default_leader(),
+                parent: (View::zero(), genesis_commitment()),
+            };
+            let genesis = make_coding_block(genesis_ctx, Sha256::hash(b""), Height::zero(), 0);
+
+            // Create parent block at height 1.
+            let parent_round = Round::new(Epoch::zero(), View::new(1));
+            let parent_ctx = CodingCtx {
+                round: parent_round,
+                leader: participants[0].clone(),
+                parent: (View::zero(), genesis_commitment()),
+            };
+            let parent = make_coding_block(parent_ctx, genesis.digest(), Height::new(1), 100);
+            let parent_digest = parent.digest();
+            let coded_parent: CodedBlock<_, ReedSolomon<Sha256>> =
+                CodedBlock::new(parent, coding_config_a, &Sequential);
+            let parent_commitment = coded_parent.commitment();
+            shards.clone().proposed(parent_round, coded_parent).await;
+
+            // Create two coded variants of the same block at height 2.
+            let round = Round::new(Epoch::zero(), View::new(2));
+            let block_ctx = CodingCtx {
+                round,
+                leader: participants[0].clone(),
+                parent: (View::new(1), parent_commitment),
+            };
+            let block = make_coding_block(block_ctx, parent_digest, Height::new(2), 200);
+            let coded_block_a: CodedBlock<_, ReedSolomon<Sha256>> =
+                CodedBlock::new(block.clone(), coding_config_a, &Sequential);
+            let coded_block_b: CodedBlock<_, ReedSolomon<Sha256>> =
+                CodedBlock::new(block, coding_config_b, &Sequential);
+
+            let commitment_a = coded_block_a.commitment();
+            let commitment_b = coded_block_b.commitment();
+            assert_eq!(coded_block_a.digest(), coded_block_b.digest());
+            assert_ne!(commitment_a, commitment_b);
+
+            // Subscribe for commitment_a, then publish commitment_b. This must not resolve.
+            let block_rx = marshal
+                .subscribe_by_commitment(Some(round), commitment_a)
+                .await;
+            context.sleep(Duration::from_millis(100)).await;
+            marshal.proposed(round, coded_block_b).await;
+            select! {
+                result = block_rx => {
+                    let block =
+                        result.expect("subscription should stay open for mismatched commitment");
+                    panic!(
+                        "subscription resolved with mismatched commitment: expected {:?}, got {:?}",
+                        commitment_a,
+                        block.commitment()
+                    );
+                },
+                _ = context.sleep(Duration::from_millis(500)) => {},
+            }
+
+            // A fresh subscription for commitment_a must resolve once commitment_a arrives.
+            let block_rx = marshal
+                .subscribe_by_commitment(Some(round), commitment_a)
+                .await;
+            context.sleep(Duration::from_millis(100)).await;
+            marshal.proposed(round, coded_block_a).await;
+            select! {
+                result = block_rx => {
+                    let block =
+                        result.expect("subscription should resolve for matching commitment");
+                    assert_eq!(
+                        block.commitment(),
+                        commitment_a,
+                        "subscription should resolve only for the requested commitment"
+                    );
+                },
+                _ = context.sleep(Duration::from_secs(5)) => {
+                    panic!("subscription should resolve after matching commitment is proposed");
+                },
+            }
+        })
+    }
+
+    #[test_traced("WARN")]
+    fn test_backfill_block_mismatched_commitment() {
+        // Regression: when backfilling by Request::Block(digest), a peer may return
+        // a coded block with matching inner digest but a different coding commitment.
+        // If a finalization for this digest is already cached, marshal must reject
+        // the block unless V::commitment(block) matches the finalization payload.
+        let runner = deterministic::Runner::timed(Duration::from_secs(30));
+        runner.start(|mut context| async move {
+            let mut oracle = setup_network(context.clone(), Some(1));
+            let Fixture {
+                participants,
+                schemes,
+                ..
+            } = bls12381_threshold_vrf::fixture::<V, _>(&mut context, NAMESPACE, NUM_VALIDATORS);
+
+            let coding_config_a = coding_config_for_participants(NUM_VALIDATORS as u16);
+            // Same total shards (4) but different min/extra split produces a different
+            // coding root and config bytes, yielding a different commitment.
+            let coding_config_b = commonware_coding::Config {
+                minimum_shards: coding_config_a.minimum_shards.checked_add(1).unwrap(),
+                extra_shards: NZU16!(coding_config_a.extra_shards.get() - 1),
+            };
+
+            let v0_setup = CodingHarness::setup_validator(
+                context.with_label("validator_0"),
+                &mut oracle,
+                participants[0].clone(),
+                ConstantProvider::new(schemes[0].clone()),
+            )
+            .await;
+            let v1_setup = CodingHarness::setup_validator(
+                context.with_label("validator_1"),
+                &mut oracle,
+                participants[1].clone(),
+                ConstantProvider::new(schemes[1].clone()),
+            )
+            .await;
+
+            setup_network_links(&mut oracle, &participants[..2], LINK).await;
+            oracle
+                .manager()
+                .track(0, participants[..2].to_vec().try_into().unwrap())
+                .await;
+
+            let mut v0_mailbox = v0_setup.mailbox;
+            let v1_mailbox = v1_setup.mailbox;
+
+            let genesis_ctx = CodingCtx {
+                round: Round::zero(),
+                leader: default_leader(),
+                parent: (View::zero(), genesis_commitment()),
+            };
+            let genesis = make_coding_block(genesis_ctx, Sha256::hash(b""), Height::zero(), 0);
+
+            let round1 = Round::new(Epoch::zero(), View::new(1));
+            let block1_ctx = CodingCtx {
+                round: round1,
+                leader: participants[0].clone(),
+                parent: (View::zero(), genesis_commitment()),
+            };
+            let block1 = make_coding_block(block1_ctx, genesis.digest(), Height::new(1), 100);
+
+            let coded_block_a: CodedBlock<_, ReedSolomon<Sha256>> =
+                CodedBlock::new(block1.clone(), coding_config_a, &Sequential);
+            let commitment_a = coded_block_a.commitment();
+
+            let coded_block_b: CodedBlock<_, ReedSolomon<Sha256>> =
+                CodedBlock::new(block1.clone(), coding_config_b, &Sequential);
+            let commitment_b = coded_block_b.commitment();
+
+            assert_eq!(coded_block_a.digest(), coded_block_b.digest());
+            assert_ne!(commitment_a, commitment_b);
+
+            // Validator 1 proposes coded_block_b (same inner block, different coding).
+            // This stores it in v1's shard engine and actor cache.
+            v1_mailbox.proposed(round1, coded_block_b.clone()).await;
+            context.sleep(Duration::from_millis(100)).await;
+
+            // Create finalization referencing commitment_a (the "correct" commitment).
+            let proposal: Proposal<Commitment> = Proposal {
+                round: round1,
+                parent: View::zero(),
+                payload: commitment_a,
+            };
+            let finalization = CodingHarness::make_finalization(proposal.clone(), &schemes, QUORUM);
+
+            // Report finalization to v0. v0 doesn't have the block:
+            //   - it fetches Request::Block(digest)
+            //   - v1 responds with coded_block_b (same digest, wrong commitment)
+            //   - deliver path must reject because cached finalization expects commitment_a
+            CodingHarness::report_finalization(&mut v0_mailbox, finalization).await;
+
+            // Wait for the fetch cycle to complete.
+            context.sleep(Duration::from_secs(5)).await;
+
+            // The mismatched block must not be stored.
+            let stored = v0_mailbox.get_block(Height::new(1)).await;
+            assert!(
+                stored.is_none(),
+                "v0 should reject backfilled block with mismatched commitment"
+            );
+
+            // Without the block, finalization should not be persisted by height yet.
+            let stored_finalization = v0_mailbox.get_finalization(Height::new(1)).await;
+            assert!(
+                stored_finalization.is_none(),
+                "finalization should not be archived until matching block is available"
+            );
+        })
+    }
+}
diff --git a/consensus/src/marshal/coding/shards/engine.rs b/consensus/src/marshal/coding/shards/engine.rs
new file mode 100644
index 000000000..b39f348a3
--- /dev/null
+++ b/consensus/src/marshal/coding/shards/engine.rs
@@ -0,0 +1,4065 @@
+//! Shard engine for erasure-coded block distribution and reconstruction.
+//!
+//! This module implements the core logic for distributing blocks as erasure-coded
+//! shards and reconstructing blocks from received shards.
+//!
+//! # Overview
+//!
+//! The shard engine serves two primary functions:
+//! 1. Broadcast: When a node proposes a block, the engine broadcasts
+//!    erasure-coded shards to all participants.
+//! 2. Block Reconstruction: When a node receives shards from peers, the engine
+//!    validates them incrementally and reconstructs the original block once
+//!    enough valid shards are available.
+//!
+//! # Shard Types
+//!
+//! The engine distinguishes between two shard types:
+//!
+//! - Strong shards (`Scheme::StrongShard`): Original erasure-coded shards sent by the proposer.
+//!   These contain the data needed to derive checking data for validation.
+//!
+//! - Weak shards (`Scheme::WeakShard`): Shards that have been validated and re-broadcast
+//!   by participants. These require checking data (derived from a strong shard)
+//!   for validation.
+//!
+//! _These are separated because some coding schemes enable the proposer to send extra data along
+//! with the shard, reducing redundant transmission of checking data from multiple participants._
+//!
+//! # Message Flow
+//!
+//! ```text
+//!                           PROPOSER
+//!                              |
+//!                              | Proposed(block)
+//!                              v
+//!                    +------------------+
+//!                    |   Shard Engine   |
+//!                    +------------------+
+//!                              |
+//!            broadcast_shards (strong shards to each participant)
+//!                              |
+//!         +--------------------+--------------------+
+//!         |                    |                    |
+//!         v                    v                    v
+//!    Participant 0        Participant 1        Participant N
+//!         |                    |                    |
+//!         | (receive strong    | (receive strong    |
+//!         |  shard for self)   |  shard for self)   |
+//!         v                    v                    v
+//!    +----------+         +----------+         +----------+
+//!    | Buffer   |         | Buffer   |         | Buffer   |
+//!    | (await   |         | (await   |         | (await   |
+//!    |  leader) |         |  leader) |         |  leader) |
+//!    +----------+         +----------+         +----------+
+//!         |                    |                    |
+//!         | Discovered         | Discovered         |
+//!         | (leader identity)  | (leader identity)  |
+//!         v                    v                    v
+//!    +----------+         +----------+         +----------+
+//!    | Validate |         | Validate |         | Validate |
+//!    | (weaken) |         | (weaken) |         | (weaken) |
+//!    +----------+         +----------+         +----------+
+//!         |                    |                    |
+//!         | Store checking     | Store checking     |
+//!         | data + checked     | data + checked     |
+//!         | shard              | shard              |
+//!         |                    |                    |
+//!         +--------------------+--------------------+
+//!                              |
+//!                    (gossip weak shards)
+//!                              |
+//!         +--------------------+--------------------+
+//!         |                    |                    |
+//!         v                    v                    v
+//!    +----------+         +----------+         +----------+
+//!    | Validate |         | Validate |         | Validate |
+//!    | (check)  |         | (check)  |         | (check)  |
+//!    +----------+         +----------+         +----------+
+//!         |                    |                    |
+//!         v                    v                    v
+//!    Accumulate checked shards until minimum_shards reached
+//!         |                    |                    |
+//!         v                    v                    v
+//!    +-------------+      +-------------+      +-------------+
+//!    | Reconstruct |      | Reconstruct |      | Reconstruct |
+//!    |    Block    |      |    Block    |      |    Block    |
+//!    +-------------+      +-------------+      +-------------+
+//! ```
+//!
+//! # Reconstruction State Machine
+//!
+//! For each [`Commitment`] with a known leader, participating nodes
+//! maintain a [`ReconstructionState`]. Before leader announcement, shards are buffered in
+//! bounded per-peer queues:
+//!
+//! ```text
+//!    +----------------------+
+//!    | AwaitingQuorum       |
+//!    | - leader known       |
+//!    | - buffer weak        |  <--- pre-leader buffered shards are ingested here
+//!    | - checking_data when |
+//!    |   strong verified    |
+//!    +----------------------+
+//!               |
+//!               | quorum met + batch validation passes
+//!               v
+//!    +----------------------+
+//!    | Ready                |
+//!    | - has checking_data  |
+//!    | - checked shards     |
+//!    | (frozen; no new weak |
+//!    |  shards accepted)    |
+//!    +----------------------+
+//!               |
+//!               | checked_shards.len() >= minimum_shards
+//!               v
+//!    +----------------------+
+//!    | Reconstruction        |
+//!    | Attempt               |
+//!    +----------------------+
+//!               |
+//!          +----+----+
+//!          |         |
+//!          v         v
+//!       Success    Failure
+//!          |         |
+//!          v         v
+//!       Cache      Remove
+//!       Block      State
+//! ```
+//!
+//! # Peer Validation and Blocking Rules
+//!
+//! The engine enforces strict validation to prevent Byzantine attacks:
+//!
+//! - All shards MUST be sent by participants in the current epoch.
+//! - Strong shards MUST correspond to the recipient's index.
+//! - Weak shards MUST be sent by the participant whose index matches
+//!   the shard index.
+//! - All shards MUST pass cryptographic verification against the commitment.
+//! - Each participant may only contribute ONE weak shard per commitment.
+//! - Sending a second shard (strong or weak) with different data than the
+//!   first (equivocation) results in blocking. Exact duplicates are silently
+//!   ignored.
+//!
+//! Peers violating these rules are blocked via the [`Blocker`] trait.
+//! Validation and blocking rules are applied while a commitment is actively
+//! tracked in reconstruction state. Once a block is already reconstructed and
+//! cached, additional shards for that commitment are ignored.
+//!
+//! _Strong shards are only accepted from the leader. If the leader is not
+//! yet known, shards are buffered in fixed-size per-peer queues until consensus
+//! signals the leader via [`Discovered`]. Once leader is known, buffered
+//! shards for that commitment are ingested into the active state machine._
+//!
+//! [`Discovered`]: super::Message::Discovered
+
+use super::{
+    mailbox::{Mailbox, Message},
+    metrics::{Peer, ShardMetrics},
+};
+use crate::{
+    marshal::{
+        application::validation::{
+            validate_reconstruction, ReconstructionValidationError as InvariantError,
+        },
+        coding::types::{CodedBlock, DistributionShard, Shard},
+    },
+    types::{coding::Commitment, Epoch, Round},
+    Block, CertifiableBlock, Heightable,
+};
+use commonware_codec::{Decode, Error as CodecError, Read};
+use commonware_coding::{Config as CodingConfig, Scheme as CodingScheme};
+use commonware_cryptography::{
+    certificate::{Provider, Scheme as CertificateScheme},
+    Committable, Digestible, Hasher, PublicKey,
+};
+use commonware_macros::select_loop;
+use commonware_p2p::{
+    utils::codec::{WrappedBackgroundReceiver, WrappedSender},
+    Blocker, Receiver, Recipients, Sender,
+};
+use commonware_parallel::Strategy;
+use commonware_runtime::{
+    spawn_cell,
+    telemetry::metrics::{histogram::HistogramExt, status::GaugeExt},
+    BufferPooler, Clock, ContextCell, Handle, Metrics, Spawner,
+};
+use commonware_utils::{
+    bitmap::BitMap,
+    channel::{fallible::OneshotExt, mpsc, oneshot},
+    ordered::Quorum,
+    Participant,
+};
+use rand::Rng;
+use std::{
+    collections::{BTreeMap, VecDeque},
+    num::NonZeroUsize,
+    sync::Arc,
+};
+use thiserror::Error;
+use tracing::{debug, warn};
+
+/// An error that can occur during reconstruction of a [`CodedBlock`] from [`Shard`]s
+#[derive(Debug, Error)]
+pub enum Error<C: CodingScheme> {
+    /// An error occurred while recovering the encoded blob from the [`Shard`]s
+    #[error(transparent)]
+    Coding(C::Error),
+
+    /// An error occurred while decoding the reconstructed blob into a [`CodedBlock`]
+    #[error(transparent)]
+    Codec(#[from] CodecError),
+
+    /// The reconstructed block's digest does not match the commitment's block digest
+    #[error("block digest mismatch: reconstructed block does not match commitment digest")]
+    DigestMismatch,
+
+    /// The reconstructed block's config does not match the commitment's coding config
+    #[error("block config mismatch: reconstructed config does not match commitment config")]
+    ConfigMismatch,
+
+    /// The reconstructed block's embedded context does not match the commitment context hash
+    #[error("block context mismatch: reconstructed context does not match commitment context")]
+    ContextMismatch,
+}
+
+#[derive(Clone, Copy, Debug, PartialEq, Eq, PartialOrd, Ord)]
+enum BlockSubscriptionKey<D> {
+    Commitment(Commitment),
+    Digest(D),
+}
+
+/// Configuration for the [`Engine`].
+pub struct Config<P, S, X, C, H, B, T>
+where
+    P: PublicKey,
+    S: Provider<Scope = Epoch>,
+    X: Blocker<PublicKey = P>,
+    C: CodingScheme,
+    H: Hasher,
+    B: CertifiableBlock,
+    T: Strategy,
+{
+    /// The scheme provider.
+    pub scheme_provider: S,
+
+    /// The peer blocker.
+    pub blocker: X,
+
+    /// [`Read`] configuration for decoding [`Shard`]s.
+    pub shard_codec_cfg: <Shard<C, H> as Read>::Cfg,
+
+    /// [`commonware_codec::Read`] configuration for decoding blocks.
+    pub block_codec_cfg: B::Cfg,
+
+    /// The strategy used for parallel computation.
+    pub strategy: T,
+
+    /// The size of the mailbox buffer.
+    pub mailbox_size: usize,
+
+    /// Number of pre-leader shards to buffer per peer.
+    ///
+    /// Shards for commitments without a reconstruction state are buffered per
+    /// peer in a fixed-size ring to bound memory under Byzantine spam. These
+    /// shards are only ingested when consensus provides a leader via
+    /// [`Discovered`](super::Message::Discovered).
+    ///
+    /// The worst-case total memory usage for pre-leader buffers is
+    /// `num_participants * pre_leader_buffer_size * max_shard_size`.
+    pub peer_buffer_size: NonZeroUsize,
+
+    /// Capacity of the channel between the background receiver and the engine.
+    ///
+    /// The background receiver decodes incoming network messages in a separate
+    /// task and forwards them to the engine over an `mpsc` channel with this
+    /// capacity.
+    pub background_channel_capacity: usize,
+}
+
+/// A network layer for broadcasting and receiving [`CodedBlock`]s as [`Shard`]s.
+///
+/// When enough [`Shard`]s are present in the mailbox, the [`Engine`] may facilitate
+/// reconstruction of the original [`CodedBlock`] and notify any subscribers waiting for it.
+pub struct Engine<E, S, X, C, H, B, P, T>
+where
+    E: BufferPooler + Rng + Spawner + Metrics + Clock,
+    S: Provider<Scope = Epoch>,
+    S::Scheme: CertificateScheme<PublicKey = P>,
+    X: Blocker,
+    C: CodingScheme,
+    H: Hasher,
+    B: CertifiableBlock,
+    P: PublicKey,
+    T: Strategy,
+{
+    /// Context held by the actor.
+    context: ContextCell<E>,
+
+    /// Receiver for incoming messages to the actor.
+    mailbox: mpsc::Receiver<Message<B, C, P>>,
+
+    /// The scheme provider.
+    scheme_provider: S,
+
+    /// The peer blocker.
+    blocker: X,
+
+    /// [`Read`] configuration for decoding [`Shard`]s.
+    shard_codec_cfg: <Shard<C, H> as Read>::Cfg,
+
+    /// [`Read`] configuration for decoding [`CodedBlock`]s.
+    block_codec_cfg: B::Cfg,
+
+    /// The strategy used for parallel shard verification.
+    strategy: T,
+
+    /// A map of [`Commitment`]s to [`ReconstructionState`]s.
+    state: BTreeMap<Commitment, ReconstructionState<P, C, H>>,
+
+    /// Per-peer ring buffers for shards received before leader announcement.
+    peer_buffers: BTreeMap<P, VecDeque<Shard<C, H>>>,
+
+    /// Maximum buffered pre-leader shards per peer.
+    peer_buffer_size: NonZeroUsize,
+
+    /// Capacity of the background receiver channel.
+    background_channel_capacity: usize,
+
+    /// An ephemeral cache of reconstructed blocks, keyed by commitment.
+    ///
+    /// These blocks are evicted after a durability signal from the marshal.
+    /// Wrapped in [`Arc`] to enable cheap cloning when serving multiple subscribers.
+    reconstructed_blocks: BTreeMap<Commitment, Arc<CodedBlock<B, C>>>,
+
+    /// Open subscriptions for the receipt of our valid shard corresponding
+    /// to the keyed [`Commitment`] from the leader.
+    shard_subscriptions: BTreeMap<Commitment, Vec<oneshot::Sender<()>>>,
+
+    /// Open subscriptions for the reconstruction of a [`CodedBlock`] with
+    /// the keyed [`Commitment`].
+    #[allow(clippy::type_complexity)]
+    block_subscriptions:
+        BTreeMap<BlockSubscriptionKey<B::Digest>, Vec<oneshot::Sender<Arc<CodedBlock<B, C>>>>>,
+
+    /// Metrics for the shard engine.
+    metrics: ShardMetrics,
+}
+
+impl<E, S, X, C, H, B, P, T> Engine<E, S, X, C, H, B, P, T>
+where
+    E: BufferPooler + Rng + Spawner + Metrics + Clock,
+    S: Provider<Scope = Epoch>,
+    S::Scheme: CertificateScheme<PublicKey = P>,
+    X: Blocker<PublicKey = P>,
+    C: CodingScheme,
+    H: Hasher,
+    B: CertifiableBlock,
+    P: PublicKey,
+    T: Strategy,
+{
+    /// Create a new [`Engine`] with the given configuration.
+    pub fn new(context: E, config: Config<P, S, X, C, H, B, T>) -> (Self, Mailbox<B, C, P>) {
+        let metrics = ShardMetrics::new(&context);
+        let (sender, mailbox) = mpsc::channel(config.mailbox_size);
+        (
+            Self {
+                context: ContextCell::new(context),
+                mailbox,
+                scheme_provider: config.scheme_provider,
+                blocker: config.blocker,
+                shard_codec_cfg: config.shard_codec_cfg,
+                block_codec_cfg: config.block_codec_cfg,
+                strategy: config.strategy,
+                state: BTreeMap::new(),
+                peer_buffers: BTreeMap::new(),
+                peer_buffer_size: config.peer_buffer_size,
+                background_channel_capacity: config.background_channel_capacity,
+                reconstructed_blocks: BTreeMap::new(),
+                shard_subscriptions: BTreeMap::new(),
+                block_subscriptions: BTreeMap::new(),
+                metrics,
+            },
+            Mailbox::new(sender),
+        )
+    }
+
+    /// Start the engine.
+    pub fn start(
+        mut self,
+        network: (impl Sender<PublicKey = P>, impl Receiver<PublicKey = P>),
+    ) -> Handle<()> {
+        spawn_cell!(self.context, self.run(network).await)
+    }
+
+    /// Run the shard engine's event loop.
+    async fn run(
+        mut self,
+        (sender, receiver): (impl Sender<PublicKey = P>, impl Receiver<PublicKey = P>),
+    ) {
+        let mut sender = WrappedSender::<_, Shard<C, H>>::new(
+            self.context.network_buffer_pool().clone(),
+            sender,
+        );
+        let (receiver_service, mut receiver): (_, mpsc::Receiver<(P, Shard<C, H>)>) =
+            WrappedBackgroundReceiver::new(
+                self.context.with_label("shard_ingress"),
+                receiver,
+                self.shard_codec_cfg.clone(),
+                self.blocker.clone(),
+                self.background_channel_capacity,
+                &self.strategy,
+            );
+        // Keep the handle alive to prevent the background receiver from being aborted.
+        let _receiver_handle = receiver_service.start();
+
+        select_loop! {
+            self.context,
+            on_start => {
+                let _ = self
+                    .metrics
+                    .reconstruction_states_count
+                    .try_set(self.state.len());
+                let _ = self
+                    .metrics
+                    .reconstructed_blocks_cache_count
+                    .try_set(self.reconstructed_blocks.len());
+
+                // Clean up closed subscriptions.
+                self.block_subscriptions.retain(|_, subscribers| {
+                    subscribers.retain(|tx| !tx.is_closed());
+                    !subscribers.is_empty()
+                });
+                self.shard_subscriptions.retain(|_, subscribers| {
+                    subscribers.retain(|tx| !tx.is_closed());
+                    !subscribers.is_empty()
+                });
+            },
+            on_stopped => {
+                debug!("received shutdown signal, stopping shard engine");
+            },
+            Some(message) = self.mailbox.recv() else {
+                debug!("shard mailbox closed, stopping shard engine");
+                return;
+            } => match message {
+                Message::Proposed { block, round } => {
+                    self.broadcast_shards(&mut sender, round, block).await;
+                }
+                Message::Discovered {
+                    commitment,
+                    leader,
+                    round,
+                } => {
+                    self.handle_external_proposal(&mut sender, commitment, leader, round)
+                        .await;
+                }
+                Message::GetByCommitment {
+                    commitment,
+                    response,
+                } => {
+                    let block = self.reconstructed_blocks.get(&commitment).cloned();
+                    response.send_lossy(block);
+                }
+                Message::GetByDigest { digest, response } => {
+                    let block = self
+                        .reconstructed_blocks
+                        .iter()
+                        .find_map(|(_, b)| (b.digest() == digest).then_some(b))
+                        .cloned();
+                    response.send_lossy(block);
+                }
+                Message::SubscribeShard {
+                    commitment,
+                    response,
+                } => {
+                    self.handle_shard_subscription(commitment, response);
+                }
+                Message::SubscribeByCommitment {
+                    commitment,
+                    response,
+                } => {
+                    self.handle_block_subscription(
+                        BlockSubscriptionKey::Commitment(commitment),
+                        response,
+                    );
+                }
+                Message::SubscribeByDigest { digest, response } => {
+                    self.handle_block_subscription(BlockSubscriptionKey::Digest(digest), response);
+                }
+                Message::Prune { min } => {
+                    self.prune(min);
+                }
+            },
+            Some((peer, shard)) = receiver.recv() else {
+                debug!("receiver closed, stopping shard engine");
+                return;
+            } => {
+                // Track shard receipt per peer.
+                self.metrics
+                    .shards_received
+                    .get_or_create(&Peer::new(&peer))
+                    .inc();
+
+                let commitment = shard.commitment();
+                if self.reconstructed_blocks.contains_key(&commitment) {
+                    continue;
+                }
+
+                if let Some(state) = self.state.get_mut(&commitment) {
+                    let round = state.round();
+                    let Some(scheme) = self.scheme_provider.scoped(round.epoch()) else {
+                        warn!(%commitment, "no scheme for epoch, ignoring shard");
+                        continue;
+                    };
+                    let progressed = state
+                        .on_network_shard(
+                            peer,
+                            shard,
+                            InsertCtx::new(scheme.as_ref(), &self.strategy),
+                            &mut self.blocker,
+                        )
+                        .await;
+                    if progressed {
+                        self.try_advance(&mut sender, commitment).await;
+                    }
+                } else {
+                    self.buffer_pre_leader_shard(peer, shard);
+                }
+            },
+        }
+    }
+
+    /// Attempts to reconstruct a [`CodedBlock`] from the checked [`Shard`]s present in the
+    /// [`ReconstructionState`].
+    ///
+    /// # Returns
+    /// - `Ok(Some(block))` if reconstruction was successful or the block was already reconstructed.
+    /// - `Ok(None)` if reconstruction could not be attempted due to insufficient checked shards.
+    /// - `Err(_)` if reconstruction was attempted but failed.
+    fn try_reconstruct(
+        &mut self,
+        commitment: Commitment,
+    ) -> Result<Option<Arc<CodedBlock<B, C>>>, Error<C>> {
+        if let Some(block) = self.reconstructed_blocks.get(&commitment) {
+            return Ok(Some(Arc::clone(block)));
+        }
+        let Some(state) = self.state.get(&commitment) else {
+            return Ok(None);
+        };
+        if state.checked_shards().len() < usize::from(commitment.config().minimum_shards.get()) {
+            debug!(%commitment, "not enough checked shards to reconstruct block");
+            return Ok(None);
+        }
+        let checking_data = state
+            .checking_data()
+            .expect("checking data must be present");
+
+        // Attempt to reconstruct the encoded blob
+        let start = self.context.current();
+        let blob = C::decode(
+            &commitment.config(),
+            &commitment.root(),
+            checking_data.clone(),
+            state.checked_shards(),
+            &self.strategy,
+        )
+        .map_err(Error::Coding)?;
+        self.metrics
+            .erasure_decode_duration
+            .observe_between(start, self.context.current());
+
+        // Attempt to decode the block from the encoded blob
+        let (inner, config): (B, CodingConfig) =
+            Decode::decode_cfg(&mut blob.as_slice(), &(self.block_codec_cfg.clone(), ()))?;
+
+        match validate_reconstruction(&inner, config, commitment) {
+            Ok(()) => {}
+            Err(InvariantError::BlockDigest) => {
+                return Err(Error::DigestMismatch);
+            }
+            Err(InvariantError::CodingConfig) => {
+                warn!(
+                    %commitment,
+                    expected_config = ?commitment.config(),
+                    actual_config = ?config,
+                    "reconstructed block config does not match commitment config, but digest matches"
+                );
+                return Err(Error::ConfigMismatch);
+            }
+            Err(InvariantError::ContextHash(expected, actual)) => {
+                warn!(
+                    %commitment,
+                    expected_context_digest = ?expected,
+                    actual_context_digest = ?actual,
+                    "reconstructed block context hash does not match commitment context hash"
+                );
+                return Err(Error::ContextMismatch);
+            }
+        }
+
+        // Construct a coding block with a _trusted_ commitment. `S::decode` verified the blob's
+        // integrity against the commitment, so shards can be lazily re-constructed if need be.
+        let block = Arc::new(CodedBlock::new_trusted(inner, commitment));
+        self.cache_block(Arc::clone(&block));
+        self.metrics.blocks_reconstructed_total.inc();
+        Ok(Some(block))
+    }
+
+    /// Handles leader announcements for a commitment and advances reconstruction.
+    async fn handle_external_proposal<Sr: Sender<PublicKey = P>>(
+        &mut self,
+        sender: &mut WrappedSender<Sr, Shard<C, H>>,
+        commitment: Commitment,
+        leader: P,
+        round: Round,
+    ) {
+        if self.reconstructed_blocks.contains_key(&commitment) {
+            return;
+        }
+        let Some(scheme) = self.scheme_provider.scoped(round.epoch()) else {
+            warn!(%commitment, "no scheme for epoch, ignoring external proposal");
+            return;
+        };
+        if scheme.me().is_none() {
+            // If we're not a participant, we won't be receiving any shards for this commitment,
+            // so we can ignore it.
+            return;
+        }
+        let participants = scheme.participants();
+        if participants.index(&leader).is_none() {
+            warn!(?leader, %commitment, "leader update for non-participant, ignoring");
+            return;
+        }
+        if let Some(state) = self.state.get(&commitment) {
+            if state.leader() != &leader {
+                warn!(
+                    existing = ?state.leader(),
+                    ?leader,
+                    %commitment,
+                    "conflicting leader update, ignoring"
+                );
+            }
+            return;
+        }
+
+        let participants_len =
+            u64::try_from(participants.len()).expect("participant count impossibly out of bounds");
+        self.state.insert(
+            commitment,
+            ReconstructionState::new(leader, round, participants_len),
+        );
+        let buffered_progress = self.ingest_buffered_shards(commitment).await;
+        if buffered_progress {
+            self.try_advance(sender, commitment).await;
+        }
+    }
+
+    /// Buffer a shard from a peer until a leader is known.
+    fn buffer_pre_leader_shard(&mut self, peer: P, shard: Shard<C, H>) {
+        let queue = self.peer_buffers.entry(peer).or_default();
+        if queue.len() >= self.peer_buffer_size.get() {
+            let _ = queue.pop_front();
+        }
+        queue.push_back(shard);
+    }
+
+    /// Ingest buffered pre-leader shards for a commitment into active state.
+    async fn ingest_buffered_shards(&mut self, commitment: Commitment) -> bool {
+        let mut buffered_weak = Vec::new();
+        let mut buffered_strong = Vec::new();
+        for (peer, queue) in self.peer_buffers.iter_mut() {
+            let mut i = 0;
+            while i < queue.len() {
+                if queue[i].commitment() != commitment {
+                    i += 1;
+                    continue;
+                }
+                let shard = queue.swap_remove_back(i).expect("index is valid");
+                if shard.is_strong() {
+                    buffered_strong.push((peer.clone(), shard));
+                } else {
+                    buffered_weak.push((peer.clone(), shard));
+                }
+            }
+        }
+        self.peer_buffers.retain(|_, queue| !queue.is_empty());
+
+        let Some(state) = self.state.get_mut(&commitment) else {
+            return false;
+        };
+        let round = state.round();
+        let Some(scheme) = self.scheme_provider.scoped(round.epoch()) else {
+            warn!(%commitment, "no scheme for epoch, dropping buffered shards");
+            return false;
+        };
+
+        // Ingest weak shards first so they populate pending_weak_shards before
+        // the strong shard sets checking_data and triggers batch validation.
+        let mut progressed = false;
+        let ctx = InsertCtx::new(scheme.as_ref(), &self.strategy);
+        for (peer, shard) in buffered_weak.into_iter().chain(buffered_strong) {
+            progressed |= state
+                .on_network_shard(peer, shard, ctx, &mut self.blocker)
+                .await;
+        }
+        progressed
+    }
+
+    /// Cache a block and notify block subscribers waiting on it.
+    fn cache_block(&mut self, block: Arc<CodedBlock<B, C>>) {
+        let commitment = block.commitment();
+        self.reconstructed_blocks
+            .insert(commitment, Arc::clone(&block));
+        self.notify_block_subscribers(block);
+    }
+
+    /// Broadcasts the shards of a [`CodedBlock`] to all participants and caches the block.
+    async fn broadcast_shards<Sr: Sender<PublicKey = P>>(
+        &mut self,
+        sender: &mut WrappedSender<Sr, Shard<C, H>>,
+        round: Round,
+        mut block: CodedBlock<B, C>,
+    ) {
+        let commitment = block.commitment();
+
+        let Some(scheme) = self.scheme_provider.scoped(round.epoch()) else {
+            warn!(%commitment, "no scheme available, cannot broadcast shards");
+            return;
+        };
+        let participants = scheme.participants();
+        let me = scheme.me();
+
+        let shard_count = block.shards(&self.strategy).len();
+        if shard_count != participants.len() {
+            warn!(
+                %commitment,
+                shard_count,
+                participants = participants.len(),
+                "cannot broadcast shards: participant/shard count mismatch"
+            );
+            return;
+        }
+
+        // Broadcast each shard to the corresponding participant.
+        for (index, peer) in participants.iter().enumerate() {
+            if me.is_some_and(|m| m.get() as usize == index) {
+                continue;
+            }
+
+            let Some(shard) = block.shard(index as u16) else {
+                warn!(
+                    %commitment,
+                    index,
+                    "cannot broadcast shards: missing shard for participant index"
+                );
+                return;
+            };
+            let _ = sender
+                .send(Recipients::One(peer.clone()), shard, true)
+                .await;
+        }
+
+        // Cache the block so we don't have to reconstruct it again.
+        let block = Arc::new(block);
+        self.cache_block(block);
+
+        // Local proposals bypass reconstruction, so shard subscribers waiting
+        // for "our valid shard arrived" still need a notification.
+        self.notify_shard_subscribers(commitment);
+
+        debug!(?commitment, "broadcasted shards to participants");
+    }
+
+    /// Broadcasts a [`Shard`] to all participants.
+    async fn broadcast_weak_shard<Sr: Sender<PublicKey = P>>(
+        &mut self,
+        sender: &mut WrappedSender<Sr, Shard<C, H>>,
+        shard: Shard<C, H>,
+    ) {
+        let commitment = shard.commitment();
+        if let Ok(peers) = sender.send(Recipients::All, shard, true).await {
+            debug!(
+                ?commitment,
+                peers = peers.len(),
+                "broadcasted shard to all participants"
+            );
+        }
+    }
+
+    /// Broadcasts any pending weak shard for the given commitment and attempts
+    /// reconstruction. If reconstruction succeeds or fails, the state is cleaned
+    /// up and subscribers are notified.
+    async fn try_advance<Sr: Sender<PublicKey = P>>(
+        &mut self,
+        sender: &mut WrappedSender<Sr, Shard<C, H>>,
+        commitment: Commitment,
+    ) {
+        if let Some(weak_shard) = self
+            .state
+            .get_mut(&commitment)
+            .and_then(|s| s.take_weak_shard())
+        {
+            self.broadcast_weak_shard(sender, weak_shard).await;
+            self.notify_shard_subscribers(commitment);
+        }
+
+        match self.try_reconstruct(commitment) {
+            Ok(Some(block)) => {
+                debug!(
+                    %commitment,
+                    parent = %block.parent(),
+                    height = %block.height(),
+                    "successfully reconstructed block from shards"
+                );
+                let mut pruned_commitments = Vec::new();
+                if let Some(round) = self.state.get(&commitment).map(ReconstructionState::round) {
+                    self.state.retain(|pruned, state| {
+                        let keep = state.round() > round;
+                        if !keep {
+                            pruned_commitments.push(*pruned);
+                        }
+                        keep
+                    });
+                }
+                for pruned in pruned_commitments {
+                    self.drop_subscriptions(pruned);
+                }
+            }
+            Ok(None) => {
+                debug!(%commitment, "not enough checked shards to reconstruct block");
+            }
+            Err(err) => {
+                warn!(%commitment, ?err, "failed to reconstruct block from checked shards");
+                self.state.remove(&commitment);
+                self.drop_subscriptions(commitment);
+                self.metrics.reconstruction_failures_total.inc();
+            }
+        }
+    }
+
+    /// Handles the registry of a shard subscription.
+    fn handle_shard_subscription(&mut self, commitment: Commitment, response: oneshot::Sender<()>) {
+        // Answer immediately if we have our shard or the block has already
+        // been reconstructed (implies that our shard arrived and was verified).
+        let has_shard = self
+            .state
+            .get(&commitment)
+            .is_some_and(|state| state.checking_data().is_some());
+        let block_reconstructed = self.reconstructed_blocks.contains_key(&commitment);
+        if has_shard || block_reconstructed {
+            response.send_lossy(());
+            return;
+        }
+
+        self.shard_subscriptions
+            .entry(commitment)
+            .or_default()
+            .push(response);
+    }
+
+    /// Handles the registry of a block subscription.
+    fn handle_block_subscription(
+        &mut self,
+        key: BlockSubscriptionKey<B::Digest>,
+        response: oneshot::Sender<Arc<CodedBlock<B, C>>>,
+    ) {
+        let block = match key {
+            BlockSubscriptionKey::Commitment(commitment) => {
+                self.reconstructed_blocks.get(&commitment)
+            }
+            BlockSubscriptionKey::Digest(digest) => self
+                .reconstructed_blocks
+                .iter()
+                .find_map(|(_, block)| (block.digest() == digest).then_some(block)),
+        };
+
+        // Answer immediately if we have the block cached.
+        if let Some(block) = block {
+            response.send_lossy(Arc::clone(block));
+            return;
+        }
+
+        self.block_subscriptions
+            .entry(key)
+            .or_default()
+            .push(response);
+    }
+
+    /// Notifies and cleans up any subscriptions for a valid shard.
+    fn notify_shard_subscribers(&mut self, commitment: Commitment) {
+        if let Some(mut subscribers) = self.shard_subscriptions.remove(&commitment) {
+            for subscriber in subscribers.drain(..) {
+                subscriber.send_lossy(());
+            }
+        }
+    }
+
+    /// Notifies and cleans up any subscriptions for a reconstructed block.
+    fn notify_block_subscribers(&mut self, block: Arc<CodedBlock<B, C>>) {
+        let commitment = block.commitment();
+        let digest = block.digest();
+
+        // Notify by-commitment subscribers.
+        if let Some(mut subscribers) = self
+            .block_subscriptions
+            .remove(&BlockSubscriptionKey::Commitment(commitment))
+        {
+            for subscriber in subscribers.drain(..) {
+                subscriber.send_lossy(Arc::clone(&block));
+            }
+        }
+
+        // Notify by-digest subscribers.
+        if let Some(mut subscribers) = self
+            .block_subscriptions
+            .remove(&BlockSubscriptionKey::Digest(digest))
+        {
+            for subscriber in subscribers.drain(..) {
+                subscriber.send_lossy(Arc::clone(&block));
+            }
+        }
+    }
+
+    /// Drops all subscriptions associated with a commitment.
+    ///
+    /// Removing these entries drops all senders, causing receivers to resolve
+    /// with cancellation (`RecvError`) instead of hanging indefinitely.
+    fn drop_subscriptions(&mut self, commitment: Commitment) {
+        self.shard_subscriptions.remove(&commitment);
+        self.block_subscriptions
+            .remove(&BlockSubscriptionKey::Commitment(commitment));
+        self.block_subscriptions
+            .remove(&BlockSubscriptionKey::Digest(
+                commitment.block::<B::Digest>(),
+            ));
+    }
+
+    /// Prunes all blocks in the reconstructed block cache that are older than the block
+    /// with the given commitment. Also cleans up stale reconstruction state
+    /// and subscriptions.
+    fn prune(&mut self, min: Commitment) {
+        if let Some(height) = self.reconstructed_blocks.get(&min).map(|b| b.height()) {
+            self.reconstructed_blocks
+                .retain(|_, block| block.height() > height);
+        }
+
+        // Always clear direct state/subscriptions for the pruned commitment.
+        // This avoids dangling waiters when prune is called for a commitment
+        // that was never reconstructed locally.
+        self.drop_subscriptions(min);
+        let Some(round) = self.state.remove(&min).map(|state| state.round()) else {
+            return;
+        };
+
+        let mut pruned_commitments = Vec::new();
+        self.state.retain(|c, s| {
+            let keep = s.round() > round;
+            if !keep {
+                pruned_commitments.push(*c);
+            }
+            keep
+        });
+        for pruned in pruned_commitments {
+            self.drop_subscriptions(pruned);
+        }
+    }
+}
+
+/// Erasure coded block reconstruction state machine.
+enum ReconstructionState<P, C, H>
+where
+    P: PublicKey,
+    C: CodingScheme,
+    H: Hasher,
+{
+    /// Stage 1: leader known; buffer weak shards and optionally hold checking
+    /// data from a verified strong shard. Transitions to `Ready` when quorum
+    /// is met and batch validation succeeds.
+    AwaitingQuorum(AwaitingQuorumState<P, C, H>),
+    /// Stage 2: batch validation passed; checked shards are available for
+    /// reconstruction.
+    Ready(ReadyState<P, C, H>),
+}
+
+/// State shared across all reconstruction phases.
+struct CommonState<P, C, H>
+where
+    P: PublicKey,
+    C: CodingScheme,
+    H: Hasher,
+{
+    /// The leader associated with this reconstruction state.
+    leader: P,
+    /// Our validated weak shard, ready to broadcast to other participants.
+    our_weak_shard: Option<Shard<C, H>>,
+    /// Shards that have been verified and are ready to contribute to reconstruction.
+    checked_shards: Vec<C::CheckedShard>,
+    /// Bitmap tracking which participant indices have contributed a valid shard.
+    contributed: BitMap,
+    /// The round for which this commitment was externally proposed.
+    round: Round,
+    /// The strong shard data received from the leader, retained for equivocation detection.
+    received_strong: Option<C::StrongShard>,
+}
+
+/// Phase data for `ReconstructionState::AwaitingQuorum`.
+///
+/// In this phase, the leader is known. Weak shards are buffered until enough
+/// shards (strong + pending weak) are available to attempt batch validation.
+/// `checking_data` is populated once the leader's strong shard is verified via
+/// `C::weaken`.
+struct AwaitingQuorumState<P, C, H>
+where
+    P: PublicKey,
+    C: CodingScheme,
+    H: Hasher,
+{
+    common: CommonState<P, C, H>,
+    pending_weak_shards: BTreeMap<P, WeakShard<C>>,
+    checking_data: Option<C::CheckingData>,
+}
+
+/// Phase data for `ReconstructionState::Ready`.
+///
+/// Batch validation has passed. Checked shards are available for
+/// reconstruction.
+struct ReadyState<P, C, H>
+where
+    P: PublicKey,
+    C: CodingScheme,
+    H: Hasher,
+{
+    common: CommonState<P, C, H>,
+    checking_data: C::CheckingData,
+}
+
+/// Parsed strong shard payload used by internal state-machine handlers.
+struct StrongShard<C>
+where
+    C: CodingScheme,
+{
+    commitment: Commitment,
+    index: u16,
+    data: C::StrongShard,
+}
+
+/// Parsed weak shard payload used by internal state-machine handlers.
+struct WeakShard<C>
+where
+    C: CodingScheme,
+{
+    index: u16,
+    data: C::WeakShard,
+}
+
+impl<P, C, H> CommonState<P, C, H>
+where
+    P: PublicKey,
+    C: CodingScheme,
+    H: Hasher,
+{
+    /// Create a new empty common state for the provided leader and round.
+    fn new(leader: P, round: Round, participants_len: u64) -> Self {
+        Self {
+            leader,
+            our_weak_shard: None,
+            checked_shards: Vec::new(),
+            contributed: BitMap::zeroes(participants_len),
+            round,
+            received_strong: None,
+        }
+    }
+}
+
+impl<P, C, H> AwaitingQuorumState<P, C, H>
+where
+    P: PublicKey,
+    C: CodingScheme,
+    H: Hasher,
+{
+    /// Verify the leader's strong shard and store checking data.
+    ///
+    /// Returns `false` if verification fails (sender is blocked), `true` on
+    /// success. Does not transition state; the caller should invoke
+    /// `try_transition` after this returns `true`.
+    async fn verify_strong_shard(
+        &mut self,
+        sender: P,
+        shard: StrongShard<C>,
+        blocker: &mut impl Blocker<PublicKey = P>,
+    ) -> bool {
+        let StrongShard {
+            commitment,
+            index,
+            data,
+        } = shard;
+        let received_strong = data.clone();
+        let Ok((checking_data, checked, weak_shard_data)) =
+            C::weaken(&commitment.config(), &commitment.root(), index, data)
+        else {
+            warn!(?sender, "invalid strong shard received, blocking peer");
+            blocker.block(sender).await;
+            return false;
+        };
+
+        // Only persist the strong shard (for later equivocation detection) after
+        // it has passed `C::weaken` verification.
+        self.common.received_strong = Some(received_strong);
+        self.common.contributed.set(u64::from(index), true);
+        self.common.checked_shards.push(checked);
+        self.common.our_weak_shard = Some(Shard::new(
+            commitment,
+            index,
+            DistributionShard::Weak(weak_shard_data),
+        ));
+        self.checking_data = Some(checking_data);
+        true
+    }
+
+    /// Check whether quorum is met and, if so, batch-validate all pending weak
+    /// shards in parallel. Returns `Some(ReadyState)` on successful transition.
+    async fn try_transition(
+        &mut self,
+        commitment: Commitment,
+        participants_len: u64,
+        strategy: &impl Strategy,
+        blocker: &mut impl Blocker<PublicKey = P>,
+    ) -> Option<ReadyState<P, C, H>> {
+        self.checking_data.as_ref()?;
+        let minimum = usize::from(commitment.config().minimum_shards.get());
+        if self.common.checked_shards.len() + self.pending_weak_shards.len() < minimum {
+            return None;
+        }
+
+        // Batch-validate all pending weak shards in parallel.
+        let pending = std::mem::take(&mut self.pending_weak_shards);
+        let checking_data = self.checking_data.as_ref().unwrap();
+        let (new_checked, to_block) =
+            strategy.map_partition_collect_vec(pending, |(peer, shard)| {
+                let checked = C::check(
+                    &commitment.config(),
+                    &commitment.root(),
+                    checking_data,
+                    shard.index,
+                    shard.data,
+                );
+                (peer, checked.ok())
+            });
+
+        for peer in to_block {
+            warn!(?peer, "invalid shard received, blocking peer");
+            blocker.block(peer).await;
+        }
+        self.common.checked_shards.extend(new_checked);
+
+        // After validation, some may have failed; recheck threshold.
+        if self.common.checked_shards.len() < minimum {
+            return None;
+        }
+
+        // Transition to Ready.
+        let checking_data = self.checking_data.take().unwrap();
+        let round = self.common.round;
+        let leader = self.common.leader.clone();
+        let common = std::mem::replace(
+            &mut self.common,
+            CommonState::new(leader, round, participants_len),
+        );
+        Some(ReadyState {
+            common,
+            checking_data,
+        })
+    }
+}
+
+/// Context required for processing incoming network shards.
+struct InsertCtx<'a, Sch, S>
+where
+    Sch: CertificateScheme,
+    S: Strategy,
+{
+    scheme: &'a Sch,
+    strategy: &'a S,
+    participants_len: u64,
+}
+
+impl<Sch: CertificateScheme, S: Strategy> Clone for InsertCtx<'_, Sch, S> {
+    fn clone(&self) -> Self {
+        *self
+    }
+}
+
+impl<Sch: CertificateScheme, S: Strategy> Copy for InsertCtx<'_, Sch, S> {}
+
+impl<'a, Sch: CertificateScheme, S: Strategy> InsertCtx<'a, Sch, S> {
+    fn new(scheme: &'a Sch, strategy: &'a S) -> Self {
+        let participants_len = u64::try_from(scheme.participants().len())
+            .expect("participant count impossibly out of bounds");
+        Self {
+            scheme,
+            strategy,
+            participants_len,
+        }
+    }
+}
+
+impl<P, C, H> ReconstructionState<P, C, H>
+where
+    P: PublicKey,
+    C: CodingScheme,
+    H: Hasher,
+{
+    /// Create an initial reconstruction state for a commitment.
+    fn new(leader: P, round: Round, participants_len: u64) -> Self {
+        Self::AwaitingQuorum(AwaitingQuorumState {
+            common: CommonState::new(leader, round, participants_len),
+            pending_weak_shards: BTreeMap::new(),
+            checking_data: None,
+        })
+    }
+
+    /// Access common state shared across all phases.
+    const fn common(&self) -> &CommonState<P, C, H> {
+        match self {
+            Self::AwaitingQuorum(state) => &state.common,
+            Self::Ready(state) => &state.common,
+        }
+    }
+
+    /// Mutably access common state shared across all phases.
+    const fn common_mut(&mut self) -> &mut CommonState<P, C, H> {
+        match self {
+            Self::AwaitingQuorum(state) => &mut state.common,
+            Self::Ready(state) => &mut state.common,
+        }
+    }
+
+    /// Return the leader associated with this state.
+    const fn leader(&self) -> &P {
+        &self.common().leader
+    }
+
+    /// Returns checking data when available.
+    ///
+    /// In `AwaitingQuorum`, this is `Some` once the leader's strong shard has
+    /// been verified. In `Ready`, it is always `Some`.
+    const fn checking_data(&self) -> Option<&C::CheckingData> {
+        match self {
+            Self::AwaitingQuorum(state) => state.checking_data.as_ref(),
+            Self::Ready(state) => Some(&state.checking_data),
+        }
+    }
+
+    /// Return the proposal round associated with this state.
+    const fn round(&self) -> Round {
+        self.common().round
+    }
+
+    /// Returns all verified shards accumulated for reconstruction.
+    ///
+    /// This slice grows as valid strong/weak shards are accepted.
+    const fn checked_shards(&self) -> &[C::CheckedShard] {
+        self.common().checked_shards.as_slice()
+    }
+
+    /// Takes the validated [`Shard`] for broadcasting to other participants.
+    /// Returns [`None`] if we haven't validated our own shard yet.
+    const fn take_weak_shard(&mut self) -> Option<Shard<C, H>> {
+        self.common_mut().our_weak_shard.take()
+    }
+
+    /// Inserts a [`Shard`] into the state.
+    ///
+    /// ## Peer Blocking Rules
+    ///
+    /// The `sender` may be blocked via the provided [`Blocker`] if any of the following rules are violated:
+    ///
+    /// Strong shards (`CodingScheme::StrongShard`):
+    /// - MUST be sent by a participant.
+    /// - MUST correspond to self's index (self must be a participant).
+    /// - MUST be sent by the leader (when the leader is known). Non-leader senders
+    ///   are blocked.
+    /// - The leader may only send ONE strong shard. Sending a second strong shard
+    ///   with different data (equivocation) results in blocking the sender. Exact
+    ///   duplicates are silently ignored.
+    /// - MUST pass cryptographic verification via [`CodingScheme::weaken`].
+    /// - When leader is unknown, buffering happens at the engine level in
+    ///   bounded pre-leader queues until [`Discovered`](super::Message::Discovered)
+    ///   creates a reconstruction state for this commitment.
+    ///
+    /// Weak shards (`CodingScheme::WeakShard`):
+    /// - MUST be sent by a participant.
+    /// - MUST be sent by the participant whose index matches the shard index.
+    /// - MUST pass cryptographic verification via [`CodingScheme::check`].
+    /// - Each participant may only contribute ONE weak shard per commitment.
+    ///   Sending a second weak shard with different data (equivocation) results
+    ///   in blocking the sender. Exact duplicates are silently ignored.
+    /// - Weak shards that arrive after the state has transitioned to `Ready`
+    ///   (i.e., batch validation has already passed) are silently discarded.
+    ///   The sender's contribution slot is still consumed, preventing future
+    ///   submissions from the same participant.
+    ///
+    /// Handle an incoming network shard.
+    ///
+    /// Returns `true` only when the shard caused state progress (buffered,
+    /// validated, or transitioned), and `false` when rejected/blocked.
+    async fn on_network_shard<Sch, S, X>(
+        &mut self,
+        sender: P,
+        shard: Shard<C, H>,
+        ctx: InsertCtx<'_, Sch, S>,
+        blocker: &mut X,
+    ) -> bool
+    where
+        Sch: CertificateScheme<PublicKey = P>,
+        S: Strategy,
+        X: Blocker<PublicKey = P>,
+    {
+        let Some(sender_index) = ctx.scheme.participants().index(&sender) else {
+            warn!(?sender, "shard sent by non-participant, blocking peer");
+            blocker.block(sender).await;
+            return false;
+        };
+        let commitment = shard.commitment();
+        let index = shard.index();
+
+        let progressed = match shard.into_inner() {
+            DistributionShard::Strong(data) => {
+                let strong = StrongShard {
+                    commitment,
+                    index,
+                    data,
+                };
+                self.insert_strong_shard(ctx.scheme.me().as_ref(), sender, strong, blocker)
+                    .await
+            }
+            DistributionShard::Weak(data) => {
+                let weak = WeakShard { index, data };
+                self.insert_weak_shard(sender, sender_index, weak, blocker)
+                    .await
+            }
+        };
+
+        if progressed {
+            if let Self::AwaitingQuorum(state) = self {
+                if let Some(ready) = state
+                    .try_transition(commitment, ctx.participants_len, ctx.strategy, blocker)
+                    .await
+                {
+                    *self = Self::Ready(ready);
+                }
+            }
+        }
+
+        progressed
+    }
+
+    /// Insert a strong shard according to the current phase.
+    ///
+    /// Returns `true` only when this progresses reconstruction state.
+    async fn insert_strong_shard(
+        &mut self,
+        me: Option<&Participant>,
+        sender: P,
+        shard: StrongShard<C>,
+        blocker: &mut impl Blocker<PublicKey = P>,
+    ) -> bool {
+        let Some(me) = me else {
+            warn!(
+                ?sender,
+                "strong shard sent to non-participant, blocking peer"
+            );
+            blocker.block(sender).await;
+            return false;
+        };
+
+        let expected_index: u16 = me
+            .get()
+            .try_into()
+            .expect("participant index impossibly out of bounds");
+        if shard.index != expected_index {
+            warn!(
+                ?sender,
+                shard_index = shard.index,
+                expected_index = me.get() as usize,
+                "strong shard index does not match self index, blocking peer"
+            );
+            blocker.block(sender).await;
+            return false;
+        }
+
+        let common = self.common();
+        if sender != common.leader {
+            warn!(
+                ?sender,
+                leader = ?common.leader,
+                "strong shard from non-leader, blocking peer"
+            );
+            blocker.block(sender).await;
+            return false;
+        }
+        if let Some(received_strong) = common.received_strong.as_ref() {
+            if received_strong != &shard.data {
+                warn!(
+                    ?sender,
+                    "strong shard equivocation from leader, blocking peer"
+                );
+                blocker.block(sender).await;
+            }
+            return false;
+        }
+
+        match self {
+            Self::AwaitingQuorum(state) => state.verify_strong_shard(sender, shard, blocker).await,
+            Self::Ready(_) => false,
+        }
+    }
+
+    /// Insert a weak shard according to the current phase.
+    ///
+    /// Returns `true` only when this progresses reconstruction state.
+    async fn insert_weak_shard(
+        &mut self,
+        sender: P,
+        sender_index: Participant,
+        shard: WeakShard<C>,
+        blocker: &mut impl Blocker<PublicKey = P>,
+    ) -> bool {
+        let expected_index: u16 = sender_index
+            .get()
+            .try_into()
+            .expect("participant index impossibly out of bounds");
+        if shard.index != expected_index {
+            warn!(
+                ?sender,
+                shard_index = shard.index,
+                expected_index = sender_index.get() as usize,
+                "weak shard index does not match participant index, blocking peer"
+            );
+            blocker.block(sender).await;
+            return false;
+        }
+
+        if self.common().contributed.get(u64::from(sender_index.get())) {
+            let equivocated = matches!(
+                self,
+                Self::AwaitingQuorum(state)
+                    if state.pending_weak_shards.get(&sender).is_some_and(|existing| existing.data != shard.data)
+            );
+            if equivocated {
+                warn!(
+                    ?sender,
+                    "duplicate weak shard with different data, blocking peer"
+                );
+                blocker.block(sender).await;
+            }
+            return false;
+        }
+        self.common_mut()
+            .contributed
+            .set(u64::from(sender_index.get()), true);
+
+        match self {
+            Self::AwaitingQuorum(state) => {
+                state.pending_weak_shards.insert(sender, shard);
+                true
+            }
+            Self::Ready(_) => false,
+        }
+    }
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+    use crate::{
+        marshal::{
+            coding::types::coding_config_for_participants, mocks::block::Block as MockBlock,
+        },
+        types::{Height, View},
+    };
+    use bytes::Bytes;
+    use commonware_codec::Encode;
+    use commonware_coding::{CodecConfig, Config as CodingConfig, ReedSolomon, Zoda};
+    use commonware_cryptography::{
+        certificate::Subject,
+        ed25519::{PrivateKey, PublicKey},
+        impl_certificate_ed25519,
+        sha256::Digest as Sha256Digest,
+        Committable, Digest, Sha256, Signer,
+    };
+    use commonware_macros::{select, test_traced};
+    use commonware_p2p::simulated::{self, Control, Link, Oracle};
+    use commonware_parallel::Sequential;
+    use commonware_runtime::{deterministic, Quota, Runner};
+    use commonware_utils::{
+        channel::oneshot::error::TryRecvError, ordered::Set, NZUsize, Participant,
+    };
+    use std::{future::Future, marker::PhantomData, num::NonZeroU32, time::Duration};
+
+    #[derive(Clone, Debug)]
+    pub struct TestSubject {
+        pub message: Bytes,
+    }
+
+    impl Subject for TestSubject {
+        type Namespace = Vec<u8>;
+
+        fn namespace<'a>(&self, derived: &'a Self::Namespace) -> &'a [u8] {
+            derived
+        }
+
+        fn message(&self) -> Bytes {
+            self.message.clone()
+        }
+    }
+
+    impl_certificate_ed25519!(TestSubject, Vec<u8>);
+
+    const SCHEME_NAMESPACE: &[u8] = b"_COMMONWARE_SHARD_ENGINE_TEST";
+
+    /// The max size of a shard sent over the wire.
+    const MAX_SHARD_SIZE: usize = 1024 * 1024; // 1 MiB
+
+    /// The default link configuration for tests.
+    const DEFAULT_LINK: Link = Link {
+        latency: Duration::from_millis(50),
+        jitter: Duration::ZERO,
+        success_rate: 1.0,
+    };
+
+    /// Rate limit quota for tests (effectively unlimited).
+    const TEST_QUOTA: Quota = Quota::per_second(NonZeroU32::MAX);
+
+    /// The parallelization strategy used for tests.
+    const STRATEGY: Sequential = Sequential;
+
+    /// A scheme provider that maps each epoch to a potentially different scheme.
+    ///
+    /// For most tests only epoch 0 is registered, matching the previous
+    /// `ConstantProvider` behaviour. Cross-epoch tests register additional
+    /// epochs with different participant sets.
+    #[derive(Clone)]
+    struct MultiEpochProvider {
+        schemes: BTreeMap<Epoch, Arc<Scheme>>,
+    }
+
+    impl MultiEpochProvider {
+        fn single(scheme: Scheme) -> Self {
+            let mut schemes = BTreeMap::new();
+            schemes.insert(Epoch::zero(), Arc::new(scheme));
+            Self { schemes }
+        }
+
+        fn with_epoch(mut self, epoch: Epoch, scheme: Scheme) -> Self {
+            self.schemes.insert(epoch, Arc::new(scheme));
+            self
+        }
+    }
+
+    impl Provider for MultiEpochProvider {
+        type Scope = Epoch;
+        type Scheme = Scheme;
+
+        fn scoped(&self, scope: Epoch) -> Option<Arc<Scheme>> {
+            self.schemes.get(&scope).cloned()
+        }
+    }
+
+    // Type aliases for test convenience.
+    type B = MockBlock<Sha256Digest, ()>;
+    type H = Sha256;
+    type P = PublicKey;
+    type C = ReedSolomon<H>;
+    type X = Control<P, deterministic::Context>;
+    type O = Oracle<P, deterministic::Context>;
+    type Prov = MultiEpochProvider;
+    type NetworkSender = simulated::Sender<P, deterministic::Context>;
+    type ShardEngine<S> = Engine<deterministic::Context, Prov, X, S, H, B, P, Sequential>;
+
+    async fn assert_blocked(oracle: &O, blocker: &P, blocked: &P) {
+        let blocked_peers = oracle.blocked().await.unwrap();
+        let is_blocked = blocked_peers
+            .iter()
+            .any(|(a, b)| a == blocker && b == blocked);
+        assert!(is_blocked, "expected {blocker} to have blocked {blocked}");
+    }
+
+    /// A participant in the test network with its engine mailbox and blocker.
+    struct Peer<S: CodingScheme = C> {
+        /// The peer's public key.
+        public_key: PublicKey,
+        /// The peer's index in the participant set.
+        index: Participant,
+        /// The mailbox for sending messages to the peer's shard engine.
+        mailbox: Mailbox<B, S, P>,
+        /// Raw network sender for injecting messages (e.g., byzantine behavior).
+        sender: NetworkSender,
+    }
+
+    /// Test fixture for setting up multiple participants with shard engines.
+    struct Fixture<S: CodingScheme = C> {
+        /// Number of peers in the test network.
+        num_peers: usize,
+        /// Network link configuration.
+        link: Link,
+        /// Marker for the coding scheme type parameter.
+        _marker: PhantomData<S>,
+    }
+
+    impl<S: CodingScheme> Default for Fixture<S> {
+        fn default() -> Self {
+            Self {
+                num_peers: 4,
+                link: DEFAULT_LINK,
+                _marker: PhantomData,
+            }
+        }
+    }
+
+    impl<S: CodingScheme> Fixture<S> {
+        pub fn start<F: Future<Output = ()>>(
+            self,
+            f: impl FnOnce(Self, deterministic::Context, O, Vec<Peer<S>>, CodingConfig) -> F,
+        ) {
+            let executor = deterministic::Runner::default();
+            executor.start(|context| async move {
+                let (network, oracle) = simulated::Network::<deterministic::Context, P>::new(
+                    context.with_label("network"),
+                    simulated::Config {
+                        max_size: MAX_SHARD_SIZE as u32,
+                        disconnect_on_block: true,
+                        tracked_peer_sets: None,
+                    },
+                );
+                network.start();
+
+                let mut private_keys = (0..self.num_peers)
+                    .map(|i| PrivateKey::from_seed(i as u64))
+                    .collect::<Vec<_>>();
+                private_keys.sort_by_key(|s| s.public_key());
+                let peer_keys: Vec<P> = private_keys.iter().map(|c| c.public_key()).collect();
+
+                let participants: Set<P> = Set::from_iter_dedup(peer_keys.clone());
+
+                let mut registrations = BTreeMap::new();
+                for peer in peer_keys.iter() {
+                    let control = oracle.control(peer.clone());
+                    let (sender, receiver) = control
+                        .register(0, TEST_QUOTA)
+                        .await
+                        .expect("registration should succeed");
+                    registrations.insert(peer.clone(), (control, sender, receiver));
+                }
+                for p1 in peer_keys.iter() {
+                    for p2 in peer_keys.iter() {
+                        if p2 == p1 {
+                            continue;
+                        }
+                        oracle
+                            .add_link(p1.clone(), p2.clone(), self.link.clone())
+                            .await
+                            .expect("link should be added");
+                    }
+                }
+
+                let coding_config =
+                    coding_config_for_participants(u16::try_from(self.num_peers).unwrap());
+
+                let mut peers = Vec::with_capacity(self.num_peers);
+                for (idx, peer_key) in peer_keys.iter().enumerate() {
+                    let (control, sender, receiver) = registrations
+                        .remove(peer_key)
+                        .expect("peer should be registered");
+
+                    let participant = Participant::new(idx as u32);
+                    let engine_context = context.with_label(&format!("peer_{}", idx));
+
+                    let scheme = Scheme::signer(
+                        SCHEME_NAMESPACE,
+                        participants.clone(),
+                        private_keys[idx].clone(),
+                    )
+                    .expect("signer scheme should be created");
+                    let scheme_provider: Prov = MultiEpochProvider::single(scheme);
+
+                    let config = Config {
+                        scheme_provider,
+                        blocker: control.clone(),
+                        shard_codec_cfg: CodecConfig {
+                            maximum_shard_size: MAX_SHARD_SIZE,
+                        },
+                        block_codec_cfg: (),
+                        strategy: STRATEGY,
+                        mailbox_size: 1024,
+                        peer_buffer_size: NZUsize!(64),
+                        background_channel_capacity: 1024,
+                    };
+
+                    let (engine, mailbox) = ShardEngine::new(engine_context, config);
+                    let sender_clone = sender.clone();
+                    engine.start((sender, receiver));
+
+                    peers.push(Peer {
+                        public_key: peer_key.clone(),
+                        index: participant,
+                        mailbox,
+                        sender: sender_clone,
+                    });
+                }
+
+                f(self, context, oracle, peers, coding_config).await;
+            });
+        }
+    }
+
+    #[test_traced]
+    fn test_e2e_broadcast_and_reconstruction() {
+        let fixture = Fixture {
+            num_peers: 10,
+            ..Default::default()
+        };
+
+        fixture.start(|config, context, _, mut peers, coding_config| async move {
+            let inner = B::new::<H>((), Sha256Digest::EMPTY, Height::new(1), 100);
+            let coded_block = CodedBlock::<B, C>::new(inner, coding_config, &STRATEGY);
+            let commitment = coded_block.commitment();
+
+            let leader = peers[0].public_key.clone();
+            let round = Round::new(Epoch::zero(), View::new(1));
+            peers[0].mailbox.proposed(round, coded_block.clone()).await;
+
+            // Inform all peers of the leader so strong shards are processed.
+            for peer in peers[1..].iter_mut() {
+                peer.mailbox
+                    .discovered(commitment, leader.clone(), round)
+                    .await;
+            }
+            context.sleep(config.link.latency).await;
+
+            for peer in peers.iter_mut() {
+                peer.mailbox
+                    .subscribe_shard(commitment)
+                    .await
+                    .await
+                    .expect("shard subscription should complete");
+            }
+            context.sleep(config.link.latency).await;
+
+            for peer in peers.iter_mut() {
+                let reconstructed = peer
+                    .mailbox
+                    .get(commitment)
+                    .await
+                    .expect("block should be reconstructed");
+                assert_eq!(reconstructed.commitment(), commitment);
+                assert_eq!(reconstructed.height(), coded_block.height());
+            }
+        });
+    }
+
+    #[test_traced]
+    fn test_e2e_broadcast_and_reconstruction_zoda() {
+        let fixture = Fixture {
+            num_peers: 10,
+            ..Default::default()
+        };
+
+        fixture.start(|config, context, _, mut peers, coding_config| async move {
+            let inner = B::new::<H>((), Sha256Digest::EMPTY, Height::new(1), 100);
+            let coded_block = CodedBlock::<B, Zoda<H>>::new(inner, coding_config, &STRATEGY);
+            let commitment = coded_block.commitment();
+
+            let leader = peers[0].public_key.clone();
+            let round = Round::new(Epoch::zero(), View::new(1));
+            peers[0].mailbox.proposed(round, coded_block.clone()).await;
+
+            // Inform all peers of the leader so strong shards are processed.
+            for peer in peers[1..].iter_mut() {
+                peer.mailbox
+                    .discovered(commitment, leader.clone(), round)
+                    .await;
+            }
+            context.sleep(config.link.latency).await;
+
+            for peer in peers.iter_mut() {
+                peer.mailbox
+                    .subscribe_shard(commitment)
+                    .await
+                    .await
+                    .expect("shard subscription should complete");
+            }
+            context.sleep(config.link.latency).await;
+
+            for peer in peers.iter_mut() {
+                let reconstructed = peer
+                    .mailbox
+                    .get(commitment)
+                    .await
+                    .expect("block should be reconstructed");
+                assert_eq!(reconstructed.commitment(), commitment);
+                assert_eq!(reconstructed.height(), coded_block.height());
+            }
+        });
+    }
+
+    #[test_traced]
+    fn test_block_subscriptions() {
+        let fixture = Fixture {
+            num_peers: 10,
+            ..Default::default()
+        };
+
+        fixture.start(|config, context, _, mut peers, coding_config| async move {
+            let inner = B::new::<H>((), Sha256Digest::EMPTY, Height::new(1), 100);
+            let coded_block = CodedBlock::<B, C>::new(inner, coding_config, &STRATEGY);
+            let commitment = coded_block.commitment();
+            let digest = coded_block.digest();
+
+            let leader = peers[0].public_key.clone();
+            let round = Round::new(Epoch::zero(), View::new(1));
+
+            // Subscribe before broadcasting.
+            let commitment_sub = peers[1].mailbox.subscribe(commitment).await;
+            let digest_sub = peers[2].mailbox.subscribe_by_digest(digest).await;
+
+            peers[0].mailbox.proposed(round, coded_block.clone()).await;
+
+            // Inform all peers of the leader so strong shards are processed.
+            for peer in peers[1..].iter_mut() {
+                peer.mailbox
+                    .discovered(commitment, leader.clone(), round)
+                    .await;
+            }
+            context.sleep(config.link.latency * 2).await;
+
+            for peer in peers.iter_mut() {
+                peer.mailbox
+                    .subscribe_shard(commitment)
+                    .await
+                    .await
+                    .expect("shard subscription should complete");
+            }
+            context.sleep(config.link.latency).await;
+
+            let block_by_commitment = commitment_sub.await.expect("subscription should resolve");
+            assert_eq!(block_by_commitment.commitment(), commitment);
+            assert_eq!(block_by_commitment.height(), coded_block.height());
+
+            let block_by_digest = digest_sub.await.expect("subscription should resolve");
+            assert_eq!(block_by_digest.commitment(), commitment);
+            assert_eq!(block_by_digest.height(), coded_block.height());
+        });
+    }
+
+    #[test_traced]
+    fn test_proposer_preproposal_subscriptions_resolve_after_local_cache() {
+        let fixture = Fixture {
+            num_peers: 10,
+            ..Default::default()
+        };
+
+        fixture.start(|config, context, _, peers, coding_config| async move {
+            let inner = B::new::<H>((), Sha256Digest::EMPTY, Height::new(1), 100);
+            let coded_block = CodedBlock::<B, C>::new(inner, coding_config, &STRATEGY);
+            let commitment = coded_block.commitment();
+            let digest = coded_block.digest();
+            let round = Round::new(Epoch::zero(), View::new(1));
+
+            // Subscribe on the proposer before it caches the locally proposed block.
+            let shard_sub = peers[0].mailbox.subscribe_shard(commitment).await;
+            let commitment_sub = peers[0].mailbox.subscribe(commitment).await;
+            let digest_sub = peers[0].mailbox.subscribe_by_digest(digest).await;
+
+            peers[0].mailbox.proposed(round, coded_block.clone()).await;
+            context.sleep(config.link.latency).await;
+
+            select! {
+                result = shard_sub => {
+                    result.expect("shard subscription should resolve");
+                },
+                _ = context.sleep(Duration::from_secs(5)) => {
+                    panic!("shard subscription did not resolve after local proposal cache");
+                }
+            }
+
+            let block_by_commitment = select! {
+                result = commitment_sub => {
+                    result.expect("block subscription by commitment should resolve")
+                },
+                _ = context.sleep(Duration::from_secs(5)) => {
+                    panic!("block subscription by commitment did not resolve after local proposal cache");
+                }
+            };
+            assert_eq!(block_by_commitment.commitment(), commitment);
+            assert_eq!(block_by_commitment.height(), coded_block.height());
+
+            let block_by_digest = select! {
+                result = digest_sub => {
+                    result.expect("block subscription by digest should resolve")
+                },
+                _ = context.sleep(Duration::from_secs(5)) => {
+                    panic!("block subscription by digest did not resolve after local proposal cache");
+                }
+            };
+            assert_eq!(block_by_digest.commitment(), commitment);
+            assert_eq!(block_by_digest.height(), coded_block.height());
+        });
+    }
+
+    #[test_traced]
+    fn test_successful_reconstruction_prunes_and_closes_stale_subscriptions() {
+        let fixture: Fixture<C> = Fixture {
+            num_peers: 10,
+            ..Default::default()
+        };
+
+        fixture.start(|config, context, _, mut peers, coding_config| async move {
+            let receiver_idx = 3usize;
+            let receiver_pk = peers[receiver_idx].public_key.clone();
+            let leader = peers[0].public_key.clone();
+
+            // Create an older discovered commitment with subscriptions that should
+            // become stale once a newer round successfully reconstructs.
+            let old_inner = B::new::<H>((), Sha256Digest::EMPTY, Height::new(1), 100);
+            let old_block = CodedBlock::<B, C>::new(old_inner, coding_config, &STRATEGY);
+            let old_commitment = old_block.commitment();
+            let old_digest = old_block.digest();
+            let old_round = Round::new(Epoch::zero(), View::new(1));
+            peers[receiver_idx]
+                .mailbox
+                .discovered(old_commitment, leader.clone(), old_round)
+                .await;
+
+            let mut old_shard_sub = peers[receiver_idx]
+                .mailbox
+                .subscribe_shard(old_commitment)
+                .await;
+            let mut old_commitment_sub =
+                peers[receiver_idx].mailbox.subscribe(old_commitment).await;
+            let mut old_digest_sub = peers[receiver_idx]
+                .mailbox
+                .subscribe_by_digest(old_digest)
+                .await;
+
+            assert!(matches!(old_shard_sub.try_recv(), Err(TryRecvError::Empty)));
+            assert!(matches!(
+                old_commitment_sub.try_recv(),
+                Err(TryRecvError::Empty)
+            ));
+            assert!(matches!(
+                old_digest_sub.try_recv(),
+                Err(TryRecvError::Empty)
+            ));
+
+            // Reconstruct a newer commitment. Successful reconstruction prunes all
+            // states at or below its round.
+            let new_inner = B::new::<H>((), Sha256Digest::EMPTY, Height::new(2), 200);
+            let new_block = CodedBlock::<B, C>::new(new_inner, coding_config, &STRATEGY);
+            let new_commitment = new_block.commitment();
+            let new_round = Round::new(Epoch::zero(), View::new(2));
+            peers[receiver_idx]
+                .mailbox
+                .discovered(new_commitment, leader.clone(), new_round)
+                .await;
+
+            let receiver_shard_idx = peers[receiver_idx].index.get() as u16;
+            let strong = new_block
+                .shard::<H>(receiver_shard_idx)
+                .expect("missing shard");
+            peers[0]
+                .sender
+                .send(Recipients::One(receiver_pk.clone()), strong.encode(), true)
+                .await
+                .expect("send failed");
+
+            for &idx in &[1usize, 2, 4] {
+                let peer_shard_idx = peers[idx].index.get() as u16;
+                let weak = new_block
+                    .shard::<H>(peer_shard_idx)
+                    .expect("missing shard")
+                    .verify_into_weak()
+                    .expect("verify_into_weak failed");
+                peers[idx]
+                    .sender
+                    .send(Recipients::One(receiver_pk.clone()), weak.encode(), true)
+                    .await
+                    .expect("send failed");
+            }
+
+            context.sleep(config.link.latency * 2).await;
+
+            let reconstructed = peers[receiver_idx]
+                .mailbox
+                .get(new_commitment)
+                .await
+                .expect("new block should reconstruct");
+            assert_eq!(reconstructed.commitment(), new_commitment);
+
+            // Stale subscriptions should now be closed, not left hanging.
+            assert!(matches!(
+                old_shard_sub.try_recv(),
+                Err(TryRecvError::Closed)
+            ));
+            assert!(matches!(
+                old_commitment_sub.try_recv(),
+                Err(TryRecvError::Closed)
+            ));
+            assert!(matches!(
+                old_digest_sub.try_recv(),
+                Err(TryRecvError::Closed)
+            ));
+        });
+    }
+
+    #[test_traced]
+    fn test_shard_subscription_rejects_invalid_shard() {
+        let fixture = Fixture::<C>::default();
+        fixture.start(
+            |config, context, oracle, mut peers, coding_config| async move {
+                // peers[0] = byzantine
+                // peers[1] = honest proposer
+                // peers[2] = receiver
+
+                let inner = B::new::<H>((), Sha256Digest::EMPTY, Height::new(1), 100);
+                let coded_block = CodedBlock::<B, C>::new(inner, coding_config, &STRATEGY);
+                let commitment = coded_block.commitment();
+                let receiver_index = peers[2].index.get() as u16;
+
+                let valid_shard = coded_block
+                    .shard::<H>(receiver_index)
+                    .expect("missing shard");
+
+                // corrupt the shard's index
+                let mut invalid_shard = valid_shard.clone();
+                invalid_shard.index = 0;
+
+                // Receiver subscribes to their shard and learns the leader.
+                let receiver_pk = peers[2].public_key.clone();
+                let leader = peers[1].public_key.clone();
+                peers[2]
+                    .mailbox
+                    .discovered(commitment, leader, Round::new(Epoch::zero(), View::new(1)))
+                    .await;
+                let mut shard_sub = peers[2].mailbox.subscribe_shard(commitment).await;
+
+                // Byzantine peer sends the invalid shard.
+                let invalid_bytes = invalid_shard.encode();
+                peers[0]
+                    .sender
+                    .send(Recipients::One(receiver_pk.clone()), invalid_bytes, true)
+                    .await
+                    .expect("send failed");
+
+                context.sleep(config.link.latency * 2).await;
+
+                assert!(
+                    matches!(shard_sub.try_recv(), Err(TryRecvError::Empty)),
+                    "subscription should not resolve from invalid shard"
+                );
+                assert_blocked(&oracle, &peers[2].public_key, &peers[0].public_key).await;
+
+                // Honest proposer sends the valid shard.
+                let valid_bytes = valid_shard.encode();
+                peers[1]
+                    .sender
+                    .send(Recipients::One(receiver_pk), valid_bytes, true)
+                    .await
+                    .expect("send failed");
+                context.sleep(config.link.latency * 2).await;
+
+                // Subscription should now resolve.
+                select! {
+                    _ = shard_sub => {},
+                    _ = context.sleep(Duration::from_secs(5)) => {
+                        panic!("subscription did not complete after valid shard arrival");
+                    },
+                };
+            },
+        );
+    }
+
+    #[test_traced]
+    fn test_durable_prunes_reconstructed_blocks() {
+        let fixture = Fixture::<C>::default();
+        fixture.start(|_, context, _, mut peers, coding_config| async move {
+            // Create 3 blocks at heights 1, 2, 3.
+            let block1 = CodedBlock::<B, C>::new(
+                B::new::<H>((), Sha256Digest::EMPTY, Height::new(1), 100),
+                coding_config,
+                &STRATEGY,
+            );
+            let block2 = CodedBlock::<B, C>::new(
+                B::new::<H>((), Sha256Digest::EMPTY, Height::new(2), 100),
+                coding_config,
+                &STRATEGY,
+            );
+            let block3 = CodedBlock::<B, C>::new(
+                B::new::<H>((), Sha256Digest::EMPTY, Height::new(3), 100),
+                coding_config,
+                &STRATEGY,
+            );
+            let commitment1 = block1.commitment();
+            let commitment2 = block2.commitment();
+            let commitment3 = block3.commitment();
+
+            // Cache all blocks via `proposed`.
+            let peer = &mut peers[0];
+            let round = Round::new(Epoch::zero(), View::new(1));
+            peer.mailbox.proposed(round, block1).await;
+            peer.mailbox.proposed(round, block2).await;
+            peer.mailbox.proposed(round, block3).await;
+            context.sleep(Duration::from_millis(10)).await;
+
+            // Verify all blocks are in the cache.
+            assert!(
+                peer.mailbox.get(commitment1).await.is_some(),
+                "block1 should be cached"
+            );
+            assert!(
+                peer.mailbox.get(commitment2).await.is_some(),
+                "block2 should be cached"
+            );
+            assert!(
+                peer.mailbox.get(commitment3).await.is_some(),
+                "block3 should be cached"
+            );
+
+            // Prune at height 2 (blocks with height <= 2 should be removed).
+            peer.mailbox.prune(commitment2).await;
+            context.sleep(Duration::from_millis(10)).await;
+
+            // Blocks at heights 1 and 2 should be pruned.
+            assert!(
+                peer.mailbox.get(commitment1).await.is_none(),
+                "block1 should be pruned"
+            );
+            assert!(
+                peer.mailbox.get(commitment2).await.is_none(),
+                "block2 should be pruned"
+            );
+
+            // Block at height 3 should still be cached.
+            assert!(
+                peer.mailbox.get(commitment3).await.is_some(),
+                "block3 should still be cached"
+            );
+        });
+    }
+
+    #[test_traced]
+    fn test_duplicate_leader_strong_shard_ignored() {
+        let fixture = Fixture::<C>::default();
+        fixture.start(
+            |config, context, oracle, mut peers, coding_config| async move {
+                let inner = B::new::<H>((), Sha256Digest::EMPTY, Height::new(1), 100);
+                let coded_block = CodedBlock::<B, C>::new(inner, coding_config, &STRATEGY);
+                let commitment = coded_block.commitment();
+
+                // Get peer 2's strong shard.
+                let peer2_index = peers[2].index.get() as u16;
+                let peer2_strong_shard =
+                    coded_block.shard::<H>(peer2_index).expect("missing shard");
+                let strong_bytes = peer2_strong_shard.encode();
+
+                let peer2_pk = peers[2].public_key.clone();
+                let leader = peers[0].public_key.clone();
+
+                // Inform peer 2 that peer 0 is the leader.
+                peers[2]
+                    .mailbox
+                    .discovered(commitment, leader, Round::new(Epoch::zero(), View::new(1)))
+                    .await;
+
+                // Send peer 2 their strong shard from peer 0 (leader, first time - should succeed).
+                peers[0]
+                    .sender
+                    .send(
+                        Recipients::One(peer2_pk.clone()),
+                        strong_bytes.clone(),
+                        true,
+                    )
+                    .await
+                    .expect("send failed");
+                context.sleep(config.link.latency * 2).await;
+
+                // Send the same strong shard again from peer 0 (leader duplicate - ignored).
+                peers[0]
+                    .sender
+                    .send(Recipients::One(peer2_pk), strong_bytes, true)
+                    .await
+                    .expect("send failed");
+                context.sleep(config.link.latency * 2).await;
+
+                // The leader should NOT be blocked for sending an identical duplicate.
+                let blocked_peers = oracle.blocked().await.unwrap();
+                let is_blocked = blocked_peers
+                    .iter()
+                    .any(|(a, b)| a == &peers[2].public_key && b == &peers[0].public_key);
+                assert!(
+                    !is_blocked,
+                    "leader should not be blocked for duplicate strong shard"
+                );
+            },
+        );
+    }
+
+    #[test_traced]
+    fn test_equivocating_leader_strong_shard_blocks_peer() {
+        let fixture = Fixture::<C>::default();
+        fixture.start(
+            |config, context, oracle, mut peers, coding_config| async move {
+                let inner1 = B::new::<H>((), Sha256Digest::EMPTY, Height::new(1), 100);
+                let coded_block1 = CodedBlock::<B, C>::new(inner1, coding_config, &STRATEGY);
+                let commitment = coded_block1.commitment();
+
+                // Create a second block with different payload to get different shard data.
+                let inner2 = B::new::<H>((), Sha256Digest::EMPTY, Height::new(1), 200);
+                let coded_block2 = CodedBlock::<B, C>::new(inner2, coding_config, &STRATEGY);
+
+                // Get peer 2's strong shard from both blocks.
+                let peer2_index = peers[2].index.get() as u16;
+                let strong_bytes1 = coded_block1
+                    .shard::<H>(peer2_index)
+                    .expect("missing shard")
+                    .encode();
+                let mut equivocating_shard =
+                    coded_block2.shard::<H>(peer2_index).expect("missing shard");
+                // Override the commitment so it targets the same reconstruction state.
+                equivocating_shard.commitment = commitment;
+                let strong_bytes2 = equivocating_shard.encode();
+
+                let peer2_pk = peers[2].public_key.clone();
+                let leader = peers[0].public_key.clone();
+
+                // Inform peer 2 that peer 0 is the leader.
+                peers[2]
+                    .mailbox
+                    .discovered(commitment, leader, Round::new(Epoch::zero(), View::new(1)))
+                    .await;
+
+                // Send peer 2 their strong shard from the leader (first time - succeeds).
+                peers[0]
+                    .sender
+                    .send(Recipients::One(peer2_pk.clone()), strong_bytes1, true)
+                    .await
+                    .expect("send failed");
+                context.sleep(config.link.latency * 2).await;
+
+                // Send a different strong shard from the leader (equivocation - should block).
+                peers[0]
+                    .sender
+                    .send(Recipients::One(peer2_pk), strong_bytes2, true)
+                    .await
+                    .expect("send failed");
+                context.sleep(config.link.latency * 2).await;
+
+                // Peer 2 should have blocked the leader for equivocation.
+                assert_blocked(&oracle, &peers[2].public_key, &peers[0].public_key).await;
+            },
+        );
+    }
+
+    #[test_traced]
+    fn test_non_leader_strong_shard_blocked() {
+        // Test that a non-leader sending a strong shard is blocked.
+        let fixture = Fixture::<C>::default();
+        fixture.start(
+            |config, context, oracle, mut peers, coding_config| async move {
+                let inner = B::new::<H>((), Sha256Digest::EMPTY, Height::new(1), 100);
+                let coded_block = CodedBlock::<B, C>::new(inner, coding_config, &STRATEGY);
+                let commitment = coded_block.commitment();
+
+                // Get peer 2's strong shard.
+                let peer2_index = peers[2].index.get() as u16;
+                let peer2_strong_shard =
+                    coded_block.shard::<H>(peer2_index).expect("missing shard");
+                let strong_bytes = peer2_strong_shard.encode();
+
+                let peer2_pk = peers[2].public_key.clone();
+                let leader = peers[0].public_key.clone();
+
+                // Inform peer 2 that peer 0 is the leader.
+                peers[2]
+                    .mailbox
+                    .discovered(commitment, leader, Round::new(Epoch::zero(), View::new(1)))
+                    .await;
+
+                // Peer 1 (not the leader) sends peer 2 their strong shard.
+                peers[1]
+                    .sender
+                    .send(Recipients::One(peer2_pk), strong_bytes, true)
+                    .await
+                    .expect("send failed");
+                context.sleep(config.link.latency * 2).await;
+
+                // Peer 1 should be blocked by peer 2 for being a non-leader.
+                assert_blocked(&oracle, &peers[2].public_key, &peers[1].public_key).await;
+            },
+        );
+    }
+
+    #[test_traced]
+    fn test_buffered_non_leader_blocked_on_leader_arrival() {
+        // Test that when a non-leader's strong shard is buffered (leader unknown)
+        // and then the leader arrives, the non-leader is blocked.
+        let fixture = Fixture::<C>::default();
+        fixture.start(
+            |config, context, oracle, mut peers, coding_config| async move {
+                let inner = B::new::<H>((), Sha256Digest::EMPTY, Height::new(1), 100);
+                let coded_block = CodedBlock::<B, C>::new(inner, coding_config, &STRATEGY);
+                let commitment = coded_block.commitment();
+
+                // Get peer 2's strong shard.
+                let peer2_index = peers[2].index.get() as u16;
+                let peer2_strong_shard =
+                    coded_block.shard::<H>(peer2_index).expect("missing shard");
+                let strong_bytes = peer2_strong_shard.encode();
+
+                let peer2_pk = peers[2].public_key.clone();
+
+                // Peer 1 sends the strong shard before the leader is known (buffered).
+                peers[1]
+                    .sender
+                    .send(Recipients::One(peer2_pk), strong_bytes, true)
+                    .await
+                    .expect("send failed");
+                context.sleep(config.link.latency * 2).await;
+
+                // Nobody should be blocked yet (shard is buffered, leader unknown).
+                let blocked = oracle.blocked().await.unwrap();
+                assert!(
+                    blocked.is_empty(),
+                    "no peers should be blocked while leader is unknown"
+                );
+
+                // Now inform peer 2 that peer 0 is the leader.
+                // This drains the buffer: peer 1's shard is from a non-leader, so
+                // peer 1 should be blocked.
+                let leader = peers[0].public_key.clone();
+                peers[2]
+                    .mailbox
+                    .discovered(commitment, leader, Round::new(Epoch::zero(), View::new(1)))
+                    .await;
+                context.sleep(Duration::from_millis(10)).await;
+
+                assert_blocked(&oracle, &peers[2].public_key, &peers[1].public_key).await;
+            },
+        );
+    }
+
+    #[test_traced]
+    fn test_conflicting_external_proposed_ignored() {
+        let fixture = Fixture::<C>::default();
+        fixture.start(
+            |config, context, oracle, mut peers, coding_config| async move {
+                let inner = B::new::<H>((), Sha256Digest::EMPTY, Height::new(1), 100);
+                let coded_block = CodedBlock::<B, C>::new(inner, coding_config, &STRATEGY);
+                let commitment = coded_block.commitment();
+
+                // Get peer 2's strong shard.
+                let peer2_index = peers[2].index.get() as u16;
+                let peer2_strong_shard =
+                    coded_block.shard::<H>(peer2_index).expect("missing shard");
+                let strong_bytes = peer2_strong_shard.encode();
+
+                let peer2_pk = peers[2].public_key.clone();
+                let leader_a = peers[0].public_key.clone();
+                let leader_b = peers[1].public_key.clone();
+
+                // Subscribe before shards arrive so we can verify acceptance.
+                let shard_sub = peers[2].mailbox.subscribe_shard(commitment).await;
+
+                // First leader update should stick.
+                peers[2]
+                    .mailbox
+                    .discovered(
+                        commitment,
+                        leader_a.clone(),
+                        Round::new(Epoch::zero(), View::new(1)),
+                    )
+                    .await;
+                // Conflicting update should be ignored.
+                peers[2]
+                    .mailbox
+                    .discovered(
+                        commitment,
+                        leader_b,
+                        Round::new(Epoch::zero(), View::new(1)),
+                    )
+                    .await;
+
+                // Original leader sends strong shard; this should still be accepted.
+                peers[0]
+                    .sender
+                    .send(
+                        Recipients::One(peer2_pk.clone()),
+                        strong_bytes.clone(),
+                        true,
+                    )
+                    .await
+                    .expect("send failed");
+                context.sleep(config.link.latency * 2).await;
+
+                // Subscription should resolve from accepted strong shard.
+                select! {
+                    _ = shard_sub => {},
+                    _ = context.sleep(Duration::from_secs(5)) => {
+                        panic!(
+                            "subscription did not complete after strong shard from original leader"
+                        );
+                    },
+                };
+
+                // The conflicting leader should still be treated as non-leader and blocked.
+                peers[1]
+                    .sender
+                    .send(Recipients::One(peer2_pk), strong_bytes, true)
+                    .await
+                    .expect("send failed");
+                context.sleep(config.link.latency * 2).await;
+
+                assert_blocked(&oracle, &peers[2].public_key, &peers[1].public_key).await;
+
+                // Original leader should not be blocked.
+                let blocked_peers = oracle.blocked().await.unwrap();
+                let leader_a_blocked = blocked_peers
+                    .iter()
+                    .any(|(a, b)| a == &peers[2].public_key && b == &leader_a);
+                assert!(
+                    !leader_a_blocked,
+                    "original leader should not be blocked after conflicting leader update"
+                );
+            },
+        );
+    }
+
+    #[test_traced]
+    fn test_non_participant_external_proposed_ignored() {
+        let fixture = Fixture::<C>::default();
+        fixture.start(
+            |config, context, oracle, mut peers, coding_config| async move {
+                let inner = B::new::<H>((), Sha256Digest::EMPTY, Height::new(1), 100);
+                let coded_block = CodedBlock::<B, C>::new(inner, coding_config, &STRATEGY);
+                let commitment = coded_block.commitment();
+
+                // Get peer 2's strong shard.
+                let peer2_index = peers[2].index.get() as u16;
+                let peer2_strong_shard =
+                    coded_block.shard::<H>(peer2_index).expect("missing shard");
+                let strong_bytes = peer2_strong_shard.encode();
+
+                let peer2_pk = peers[2].public_key.clone();
+                let leader = peers[0].public_key.clone();
+                let non_participant_leader = PrivateKey::from_seed(10_000).public_key();
+
+                // Subscribe before shards arrive.
+                let shard_sub = peers[2].mailbox.subscribe_shard(commitment).await;
+
+                // A non-participant leader update should be ignored.
+                peers[2]
+                    .mailbox
+                    .discovered(
+                        commitment,
+                        non_participant_leader,
+                        Round::new(Epoch::zero(), View::new(1)),
+                    )
+                    .await;
+
+                // Leader unknown path: this strong shard should be buffered, not blocked.
+                peers[0]
+                    .sender
+                    .send(
+                        Recipients::One(peer2_pk.clone()),
+                        strong_bytes.clone(),
+                        true,
+                    )
+                    .await
+                    .expect("send failed");
+                context.sleep(config.link.latency * 2).await;
+
+                let blocked = oracle.blocked().await.unwrap();
+                let leader_blocked = blocked
+                    .iter()
+                    .any(|(a, b)| a == &peers[2].public_key && b == &leader);
+                assert!(
+                    !leader_blocked,
+                    "leader should not be blocked when non-participant update is ignored"
+                );
+
+                // A valid leader update should then process buffered shards and resolve subscription.
+                peers[2]
+                    .mailbox
+                    .discovered(commitment, leader, Round::new(Epoch::zero(), View::new(1)))
+                    .await;
+                context.sleep(config.link.latency * 2).await;
+
+                select! {
+                    _ = shard_sub => {},
+                    _ = context.sleep(Duration::from_secs(5)) => {
+                        panic!("subscription did not complete after valid leader update");
+                    },
+                };
+            },
+        );
+    }
+
+    #[test_traced]
+    fn test_shard_from_non_participant_blocks_peer() {
+        let fixture = Fixture::<C>::default();
+        fixture.start(|config, context, oracle, peers, coding_config| async move {
+            let inner = B::new::<H>((), Sha256Digest::EMPTY, Height::new(1), 100);
+            let coded_block = CodedBlock::<B, C>::new(inner, coding_config, &STRATEGY);
+            let commitment = coded_block.commitment();
+
+            let leader = peers[0].public_key.clone();
+            let receiver_pk = peers[2].public_key.clone();
+
+            let non_participant_key = PrivateKey::from_seed(10_000);
+            let non_participant_pk = non_participant_key.public_key();
+
+            let non_participant_control = oracle.control(non_participant_pk.clone());
+            let (mut non_participant_sender, _non_participant_receiver) = non_participant_control
+                .register(0, TEST_QUOTA)
+                .await
+                .expect("registration should succeed");
+            oracle
+                .add_link(
+                    non_participant_pk.clone(),
+                    receiver_pk.clone(),
+                    DEFAULT_LINK,
+                )
+                .await
+                .expect("link should be added");
+
+            peers[2]
+                .mailbox
+                .discovered(commitment, leader, Round::new(Epoch::zero(), View::new(1)))
+                .await;
+
+            let peer2_index = peers[2].index.get() as u16;
+            let strong_shard = coded_block.shard::<H>(peer2_index).expect("missing shard");
+            let weak_shard = strong_shard
+                .verify_into_weak()
+                .expect("verify_into_weak failed");
+            let weak_bytes = weak_shard.encode();
+
+            non_participant_sender
+                .send(Recipients::One(receiver_pk), weak_bytes, true)
+                .await
+                .expect("send failed");
+            context.sleep(config.link.latency * 2).await;
+
+            assert_blocked(&oracle, &peers[2].public_key, &non_participant_pk).await;
+        });
+    }
+
+    #[test_traced]
+    fn test_buffered_shard_from_non_participant_blocks_peer() {
+        let fixture = Fixture::<C>::default();
+        fixture.start(|config, context, oracle, peers, coding_config| async move {
+            let inner = B::new::<H>((), Sha256Digest::EMPTY, Height::new(1), 100);
+            let coded_block = CodedBlock::<B, C>::new(inner, coding_config, &STRATEGY);
+            let commitment = coded_block.commitment();
+
+            let leader = peers[0].public_key.clone();
+            let receiver_pk = peers[2].public_key.clone();
+
+            let non_participant_key = PrivateKey::from_seed(10_000);
+            let non_participant_pk = non_participant_key.public_key();
+
+            let non_participant_control = oracle.control(non_participant_pk.clone());
+            let (mut non_participant_sender, _non_participant_receiver) = non_participant_control
+                .register(0, TEST_QUOTA)
+                .await
+                .expect("registration should succeed");
+            oracle
+                .add_link(
+                    non_participant_pk.clone(),
+                    receiver_pk.clone(),
+                    DEFAULT_LINK,
+                )
+                .await
+                .expect("link should be added");
+
+            let peer2_index = peers[2].index.get() as u16;
+            let strong_shard = coded_block.shard::<H>(peer2_index).expect("missing shard");
+            let weak_shard = strong_shard
+                .verify_into_weak()
+                .expect("verify_into_weak failed");
+            let weak_bytes = weak_shard.encode();
+
+            non_participant_sender
+                .send(Recipients::One(receiver_pk), weak_bytes, true)
+                .await
+                .expect("send failed");
+            context.sleep(config.link.latency * 2).await;
+
+            peers[2]
+                .mailbox
+                .discovered(commitment, leader, Round::new(Epoch::zero(), View::new(1)))
+                .await;
+            context.sleep(config.link.latency * 2).await;
+
+            assert_blocked(&oracle, &peers[2].public_key, &non_participant_pk).await;
+        });
+    }
+
+    #[test_traced]
+    fn test_duplicate_weak_shard_ignored() {
+        // Use 10 peers so minimum_shards=4, giving us time to send duplicate before reconstruction.
+        let fixture: Fixture<C> = Fixture {
+            num_peers: 10,
+            ..Default::default()
+        };
+
+        fixture.start(
+            |config, context, oracle, mut peers, coding_config| async move {
+                let inner = B::new::<H>((), Sha256Digest::EMPTY, Height::new(1), 100);
+                let coded_block = CodedBlock::<B, C>::new(inner, coding_config, &STRATEGY);
+
+                // Get peer 2's strong shard (to initialize their checking_data).
+                let peer2_index = peers[2].index.get() as u16;
+                let peer2_strong_shard =
+                    coded_block.shard::<H>(peer2_index).expect("missing shard");
+
+                // Get peer 1's weak shard.
+                let peer1_index = peers[1].index.get() as u16;
+                let peer1_strong_shard =
+                    coded_block.shard::<H>(peer1_index).expect("missing shard");
+                let peer1_weak_shard = peer1_strong_shard
+                    .verify_into_weak()
+                    .expect("verify_into_weak failed");
+
+                let peer2_pk = peers[2].public_key.clone();
+                let leader = peers[0].public_key.clone();
+
+                // Inform peer 2 of the leader.
+                peers[2]
+                    .mailbox
+                    .discovered(
+                        coded_block.commitment(),
+                        leader,
+                        Round::new(Epoch::zero(), View::new(1)),
+                    )
+                    .await;
+
+                // Send peer 2 their strong shard (initializes checking_data, 1 checked shard).
+                let strong_bytes = peer2_strong_shard.encode();
+                peers[0]
+                    .sender
+                    .send(Recipients::One(peer2_pk.clone()), strong_bytes, true)
+                    .await
+                    .expect("send failed");
+                context.sleep(config.link.latency * 2).await;
+
+                // Send peer 1's weak shard to peer 2 (first time - should succeed, 2 checked shards).
+                let weak_shard_bytes = peer1_weak_shard.encode();
+                peers[1]
+                    .sender
+                    .send(
+                        Recipients::One(peer2_pk.clone()),
+                        weak_shard_bytes.clone(),
+                        true,
+                    )
+                    .await
+                    .expect("send failed");
+                context.sleep(config.link.latency * 2).await;
+
+                // Send the same weak shard again (exact duplicate - should be ignored, not blocked).
+                // With 10 peers, minimum_shards=4, so we haven't reconstructed yet.
+                peers[1]
+                    .sender
+                    .send(Recipients::One(peer2_pk), weak_shard_bytes, true)
+                    .await
+                    .expect("send failed");
+                context.sleep(config.link.latency * 2).await;
+
+                // Peer 1 should NOT be blocked for sending an identical duplicate.
+                let blocked_peers = oracle.blocked().await.unwrap();
+                let is_blocked = blocked_peers
+                    .iter()
+                    .any(|(a, b)| a == &peers[2].public_key && b == &peers[1].public_key);
+                assert!(
+                    !is_blocked,
+                    "peer should not be blocked for exact duplicate weak shard"
+                );
+            },
+        );
+    }
+
+    #[test_traced]
+    fn test_equivocating_weak_shard_blocks_peer() {
+        // Use 10 peers so minimum_shards=4, giving us time to send equivocating shard.
+        let fixture: Fixture<C> = Fixture {
+            num_peers: 10,
+            ..Default::default()
+        };
+
+        fixture.start(
+            |config, context, oracle, mut peers, coding_config| async move {
+                let inner1 = B::new::<H>((), Sha256Digest::EMPTY, Height::new(1), 100);
+                let coded_block1 = CodedBlock::<B, C>::new(inner1, coding_config, &STRATEGY);
+
+                // Create a second block with different payload to get different shard data.
+                let inner2 = B::new::<H>((), Sha256Digest::EMPTY, Height::new(1), 200);
+                let coded_block2 = CodedBlock::<B, C>::new(inner2, coding_config, &STRATEGY);
+
+                // Get peer 2's strong shard from block 1 (to initialize their checking_data).
+                let peer2_index = peers[2].index.get() as u16;
+                let peer2_strong_shard =
+                    coded_block1.shard::<H>(peer2_index).expect("missing shard");
+
+                // Get peer 1's weak shard from block 1.
+                let peer1_index = peers[1].index.get() as u16;
+                let peer1_strong_shard =
+                    coded_block1.shard::<H>(peer1_index).expect("missing shard");
+                let peer1_weak_shard = peer1_strong_shard
+                    .verify_into_weak()
+                    .expect("verify_into_weak failed");
+
+                // Get peer 1's weak shard from block 2 (different data, same index).
+                let peer1_strong_shard2 =
+                    coded_block2.shard::<H>(peer1_index).expect("missing shard");
+                let mut peer1_equivocating_shard = peer1_strong_shard2
+                    .verify_into_weak()
+                    .expect("verify_into_weak failed");
+                // Override the commitment to match block 1 so the shard targets
+                // the same reconstruction state.
+                peer1_equivocating_shard.commitment = coded_block1.commitment();
+
+                let peer2_pk = peers[2].public_key.clone();
+                let leader = peers[0].public_key.clone();
+
+                // Inform peer 2 of the leader.
+                peers[2]
+                    .mailbox
+                    .discovered(
+                        coded_block1.commitment(),
+                        leader,
+                        Round::new(Epoch::zero(), View::new(1)),
+                    )
+                    .await;
+
+                // Send peer 2 their strong shard (initializes checking_data).
+                let strong_bytes = peer2_strong_shard.encode();
+                peers[0]
+                    .sender
+                    .send(Recipients::One(peer2_pk.clone()), strong_bytes, true)
+                    .await
+                    .expect("send failed");
+                context.sleep(config.link.latency * 2).await;
+
+                // Send peer 1's valid weak shard to peer 2 (first time - succeeds).
+                let weak_shard_bytes = peer1_weak_shard.encode();
+                peers[1]
+                    .sender
+                    .send(Recipients::One(peer2_pk.clone()), weak_shard_bytes, true)
+                    .await
+                    .expect("send failed");
+                context.sleep(config.link.latency * 2).await;
+
+                // Send a different weak shard from peer 1 (equivocation - should block).
+                let equivocating_bytes = peer1_equivocating_shard.encode();
+                peers[1]
+                    .sender
+                    .send(Recipients::One(peer2_pk), equivocating_bytes, true)
+                    .await
+                    .expect("send failed");
+                context.sleep(config.link.latency * 2).await;
+
+                // Peer 2 should have blocked peer 1 for equivocation.
+                assert_blocked(&oracle, &peers[2].public_key, &peers[1].public_key).await;
+            },
+        );
+    }
+
+    #[test_traced]
+    fn test_reconstruction_states_pruned_at_or_below_reconstructed_view() {
+        // Use 10 peers so minimum_shards=4.
+        let fixture: Fixture<C> = Fixture {
+            num_peers: 10,
+            ..Default::default()
+        };
+
+        fixture.start(
+            |config, context, oracle, mut peers, coding_config| async move {
+                // Commitment A at lower view (1).
+                let block_a = CodedBlock::<B, C>::new(
+                    B::new::<H>((), Sha256Digest::EMPTY, Height::new(1), 100),
+                    coding_config,
+                    &STRATEGY,
+                );
+                let commitment_a = block_a.commitment();
+
+                // Commitment B at higher view (2), which we will reconstruct.
+                let block_b = CodedBlock::<B, C>::new(
+                    B::new::<H>((), Sha256Digest::EMPTY, Height::new(2), 200),
+                    coding_config,
+                    &STRATEGY,
+                );
+                let commitment_b = block_b.commitment();
+
+                let peer2_pk = peers[2].public_key.clone();
+                let leader = peers[0].public_key.clone();
+
+                // Create state for A and ingest one weak shard from peer1.
+                peers[2]
+                    .mailbox
+                    .discovered(
+                        commitment_a,
+                        leader.clone(),
+                        Round::new(Epoch::zero(), View::new(1)),
+                    )
+                    .await;
+                let peer1_strong_a = block_a
+                    .shard::<H>(peers[1].index.get() as u16)
+                    .expect("missing shard");
+                let weak_a = peer1_strong_a
+                    .verify_into_weak()
+                    .expect("verify_into_weak failed")
+                    .encode();
+                peers[1]
+                    .sender
+                    .send(Recipients::One(peer2_pk.clone()), weak_a.clone(), true)
+                    .await
+                    .expect("send failed");
+                context.sleep(config.link.latency * 2).await;
+
+                // Create/reconstruct B at higher view.
+                peers[2]
+                    .mailbox
+                    .discovered(
+                        commitment_b,
+                        leader,
+                        Round::new(Epoch::zero(), View::new(2)),
+                    )
+                    .await;
+                // Strong shard for peer2 from leader.
+                let strong_b = block_b
+                    .shard::<H>(peers[2].index.get() as u16)
+                    .expect("missing shard")
+                    .encode();
+                peers[0]
+                    .sender
+                    .send(Recipients::One(peer2_pk.clone()), strong_b, true)
+                    .await
+                    .expect("send failed");
+
+                // Three weak shards for minimum threshold (4 total with strong).
+                for i in [1usize, 3usize, 4usize] {
+                    let weak = block_b
+                        .shard::<H>(peers[i].index.get() as u16)
+                        .expect("missing shard")
+                        .verify_into_weak()
+                        .expect("verify_into_weak failed")
+                        .encode();
+                    peers[i]
+                        .sender
+                        .send(Recipients::One(peer2_pk.clone()), weak, true)
+                        .await
+                        .expect("send failed");
+                }
+                context.sleep(config.link.latency * 4).await;
+
+                // B should reconstruct.
+                let reconstructed = peers[2]
+                    .mailbox
+                    .get(commitment_b)
+                    .await
+                    .expect("block B should reconstruct");
+                assert_eq!(reconstructed.commitment(), commitment_b);
+
+                // A state should be pruned (at/below reconstructed view). Sending the same
+                // weak shard for A again should NOT be treated as duplicate.
+                peers[1]
+                    .sender
+                    .send(Recipients::One(peer2_pk), weak_a, true)
+                    .await
+                    .expect("send failed");
+                context.sleep(config.link.latency * 2).await;
+
+                let blocked = oracle.blocked().await.unwrap();
+                let blocked_peer1 = blocked
+                    .iter()
+                    .any(|(a, b)| a == &peers[2].public_key && b == &peers[1].public_key);
+                assert!(
+                    !blocked_peer1,
+                    "peer1 should not be blocked after lower-view state was pruned"
+                );
+            },
+        );
+    }
+
+    #[test_traced]
+    fn test_drain_pending_validates_weak_shards_after_strong_shard() {
+        // Test that weak shards arriving BEFORE the strong shard are validated
+        // via drain_pending once the strong shard arrives, enabling reconstruction.
+        //
+        // With 10 peers: minimum_shards = (10-1)/3 + 1 = 4
+        // We send 3 pending weak shards + 1 strong shard = 4 shards -> reconstruction.
+        let fixture: Fixture<C> = Fixture {
+            num_peers: 10,
+            ..Default::default()
+        };
+
+        fixture.start(
+            |config, context, oracle, mut peers, coding_config| async move {
+                let inner = B::new::<H>((), Sha256Digest::EMPTY, Height::new(1), 100);
+                let coded_block = CodedBlock::<B, C>::new(inner, coding_config, &STRATEGY);
+                let commitment = coded_block.commitment();
+
+                // Get peer 3's strong shard.
+                let peer3_index = peers[3].index.get() as u16;
+                let peer3_strong_shard =
+                    coded_block.shard::<H>(peer3_index).expect("missing shard");
+
+                // Get weak shards from peers 0, 1, and 2 (3 total to meet minimum_shards=4).
+                let weak_shards: Vec<_> = [0, 1, 2]
+                    .iter()
+                    .map(|&i| {
+                        coded_block
+                            .shard::<H>(peers[i].index.get() as u16)
+                            .expect("missing shard")
+                            .verify_into_weak()
+                            .expect("verify_into_weak failed")
+                    })
+                    .collect();
+
+                let peer3_pk = peers[3].public_key.clone();
+
+                // Send weak shards to peer 3 BEFORE their strong shard arrives.
+                // These will be stored in pending_weak_shards since there's no checking data yet.
+                for (i, weak_shard) in weak_shards.iter().enumerate() {
+                    let sender_idx = [0, 1, 2][i];
+                    let weak_shard_bytes = weak_shard.encode();
+                    peers[sender_idx]
+                        .sender
+                        .send(Recipients::One(peer3_pk.clone()), weak_shard_bytes, true)
+                        .await
+                        .expect("send failed");
+                }
+
+                context.sleep(config.link.latency * 2).await;
+
+                // Block should not be reconstructed yet (no checking data from strong shard).
+                let block = peers[3].mailbox.get(commitment).await;
+                assert!(block.is_none(), "block should not be reconstructed yet");
+
+                // Inform peer 3 that peer 2 is the leader.
+                let leader = peers[2].public_key.clone();
+                peers[3]
+                    .mailbox
+                    .discovered(commitment, leader, Round::new(Epoch::zero(), View::new(1)))
+                    .await;
+
+                // Now send peer 2's strong shard. This should:
+                // 1. Provide checking data
+                // 2. Trigger drain_pending which validates the 3 pending weak shards
+                // 3. With 4 checked shards (1 strong + 3 from pending), trigger reconstruction
+                let strong_bytes = peer3_strong_shard.encode();
+                peers[2]
+                    .sender
+                    .send(Recipients::One(peer3_pk), strong_bytes, true)
+                    .await
+                    .expect("send failed");
+
+                context.sleep(config.link.latency * 2).await;
+
+                // No peers should be blocked (all weak shards were valid).
+                let blocked = oracle.blocked().await.unwrap();
+                assert!(
+                    blocked.is_empty(),
+                    "no peers should be blocked for valid pending weak shards"
+                );
+
+                // Block should now be reconstructed (4 checked shards >= minimum_shards).
+                let block = peers[3].mailbox.get(commitment).await;
+                assert!(
+                    block.is_some(),
+                    "block should be reconstructed after drain_pending"
+                );
+
+                // Verify the reconstructed block has the correct commitment.
+                let reconstructed = block.unwrap();
+                assert_eq!(
+                    reconstructed.commitment(),
+                    commitment,
+                    "reconstructed block should have correct commitment"
+                );
+            },
+        );
+    }
+
+    #[test_traced]
+    fn test_pre_leader_shards_buffered_until_external_proposed() {
+        // Test that shards received before leader announcement do not progress
+        // reconstruction until Discovered is delivered.
+        let fixture: Fixture<C> = Fixture {
+            num_peers: 10,
+            ..Default::default()
+        };
+
+        fixture.start(
+            |config, context, oracle, mut peers, coding_config| async move {
+                let inner = B::new::<H>((), Sha256Digest::EMPTY, Height::new(1), 100);
+                let coded_block = CodedBlock::<B, C>::new(inner, coding_config, &STRATEGY);
+                let commitment = coded_block.commitment();
+
+                let receiver_idx = 3usize;
+                let receiver_pk = peers[receiver_idx].public_key.clone();
+                let leader = peers[0].public_key.clone();
+
+                // Subscribe before any shards arrive.
+                let mut shard_sub = peers[receiver_idx]
+                    .mailbox
+                    .subscribe_shard(commitment)
+                    .await;
+
+                // Send one strong shard from the eventual leader and three weak shards,
+                // all before leader announcement.
+                let strong = coded_block
+                    .shard::<H>(peers[receiver_idx].index.get() as u16)
+                    .expect("missing shard")
+                    .encode();
+                peers[0]
+                    .sender
+                    .send(Recipients::One(receiver_pk.clone()), strong, true)
+                    .await
+                    .expect("send failed");
+
+                for i in [1usize, 2usize, 4usize] {
+                    let weak = coded_block
+                        .shard::<H>(peers[i].index.get() as u16)
+                        .expect("missing shard")
+                        .verify_into_weak()
+                        .expect("verify_into_weak failed")
+                        .encode();
+                    peers[i]
+                        .sender
+                        .send(Recipients::One(receiver_pk.clone()), weak, true)
+                        .await
+                        .expect("send failed");
+                }
+
+                context.sleep(config.link.latency * 2).await;
+
+                // No leader yet: shard subscription should still be pending and block unavailable.
+                assert!(
+                    matches!(shard_sub.try_recv(), Err(TryRecvError::Empty)),
+                    "shard subscription should not resolve before leader announcement"
+                );
+                assert!(
+                    peers[receiver_idx].mailbox.get(commitment).await.is_none(),
+                    "block should not reconstruct before leader announcement"
+                );
+
+                // Announce leader, which drains buffered shards and should progress immediately.
+                peers[receiver_idx]
+                    .mailbox
+                    .discovered(commitment, leader, Round::new(Epoch::zero(), View::new(1)))
+                    .await;
+
+                select! {
+                    _ = shard_sub => {},
+                    _ = context.sleep(Duration::from_secs(5)) => {
+                        panic!("shard subscription did not resolve after leader announcement");
+                    },
+                }
+
+                context.sleep(config.link.latency * 2).await;
+                assert!(
+                    peers[receiver_idx].mailbox.get(commitment).await.is_some(),
+                    "block should reconstruct after buffered shards are ingested"
+                );
+
+                // All shards were valid and from participants.
+                assert!(
+                    oracle.blocked().await.unwrap().is_empty(),
+                    "no peers should be blocked for valid buffered shards"
+                );
+            },
+        );
+    }
+
+    #[test_traced]
+    fn test_post_leader_shards_processed_immediately() {
+        // Test that shards arriving after leader announcement are processed
+        // without waiting for any extra trigger.
+        let fixture: Fixture<C> = Fixture {
+            num_peers: 10,
+            ..Default::default()
+        };
+
+        fixture.start(
+            |config, context, oracle, mut peers, coding_config| async move {
+                let inner = B::new::<H>((), Sha256Digest::EMPTY, Height::new(1), 100);
+                let coded_block = CodedBlock::<B, C>::new(inner, coding_config, &STRATEGY);
+                let commitment = coded_block.commitment();
+
+                let receiver_idx = 3usize;
+                let receiver_pk = peers[receiver_idx].public_key.clone();
+                let leader = peers[0].public_key.clone();
+
+                let shard_sub = peers[receiver_idx]
+                    .mailbox
+                    .subscribe_shard(commitment)
+                    .await;
+                peers[receiver_idx]
+                    .mailbox
+                    .discovered(
+                        commitment,
+                        leader.clone(),
+                        Round::new(Epoch::zero(), View::new(1)),
+                    )
+                    .await;
+
+                // Send leader strong shard after leader is known.
+                let strong = coded_block
+                    .shard::<H>(peers[receiver_idx].index.get() as u16)
+                    .expect("missing shard")
+                    .encode();
+                peers[0]
+                    .sender
+                    .send(Recipients::One(receiver_pk.clone()), strong, true)
+                    .await
+                    .expect("send failed");
+
+                // Subscription should resolve from the strong shard.
+                select! {
+                    _ = shard_sub => {},
+                    _ = context.sleep(Duration::from_secs(5)) => {
+                        panic!("shard subscription did not resolve after post-leader strong shard");
+                    },
+                }
+
+                // Send enough weak shards after leader known to reconstruct.
+                for i in [1usize, 2usize, 4usize] {
+                    let weak = coded_block
+                        .shard::<H>(peers[i].index.get() as u16)
+                        .expect("missing shard")
+                        .verify_into_weak()
+                        .expect("verify_into_weak failed")
+                        .encode();
+                    peers[i]
+                        .sender
+                        .send(Recipients::One(receiver_pk.clone()), weak, true)
+                        .await
+                        .expect("send failed");
+                }
+
+                context.sleep(config.link.latency * 2).await;
+                let reconstructed = peers[receiver_idx]
+                    .mailbox
+                    .get(commitment)
+                    .await
+                    .expect("block should reconstruct from post-leader shards");
+                assert_eq!(reconstructed.commitment(), commitment);
+
+                assert!(
+                    oracle.blocked().await.unwrap().is_empty(),
+                    "no peers should be blocked for valid post-leader shards"
+                );
+            },
+        );
+    }
+
+    #[test_traced]
+    fn test_invalid_shard_codec_blocks_peer() {
+        // Test that receiving an invalid shard (codec failure) blocks the sender.
+        let fixture: Fixture<C> = Fixture {
+            num_peers: 4,
+            ..Default::default()
+        };
+
+        fixture.start(
+            |config, context, oracle, mut peers, _coding_config| async move {
+                let peer0_pk = peers[0].public_key.clone();
+                let peer1_pk = peers[1].public_key.clone();
+
+                // Send garbage bytes that will fail codec decoding.
+                let garbage = Bytes::from(vec![0xFF, 0xFE, 0xFD, 0xFC, 0xFB]);
+                peers[1]
+                    .sender
+                    .send(Recipients::One(peer0_pk.clone()), garbage, true)
+                    .await
+                    .expect("send failed");
+
+                context.sleep(config.link.latency * 2).await;
+
+                // Peer 1 should be blocked by peer 0 for sending invalid shard.
+                assert_blocked(&oracle, &peer0_pk, &peer1_pk).await;
+            },
+        );
+    }
+
+    #[test_traced]
+    fn test_duplicate_buffered_strong_shard_does_not_block_before_leader() {
+        // Test that duplicate strong shards before leader announcement are
+        // buffered and do not immediately block the sender.
+        let fixture: Fixture<C> = Fixture {
+            ..Default::default()
+        };
+
+        fixture.start(
+            |config, context, oracle, mut peers, coding_config| async move {
+                let inner = B::new::<H>((), Sha256Digest::EMPTY, Height::new(1), 100);
+                let coded_block = CodedBlock::<B, C>::new(inner, coding_config, &STRATEGY);
+
+                // Get peer 2's strong shard.
+                let peer2_index = peers[2].index.get() as u16;
+                let peer2_strong_shard =
+                    coded_block.shard::<H>(peer2_index).expect("missing shard");
+                let strong_bytes = peer2_strong_shard.encode();
+
+                let peer2_pk = peers[2].public_key.clone();
+
+                // Do NOT set a leader — shards should be buffered.
+
+                // Peer 1 sends the strong shard to peer 2 (buffered, leader unknown).
+                peers[1]
+                    .sender
+                    .send(
+                        Recipients::One(peer2_pk.clone()),
+                        strong_bytes.clone(),
+                        true,
+                    )
+                    .await
+                    .expect("send failed");
+                context.sleep(config.link.latency * 2).await;
+
+                // No one should be blocked yet.
+                let blocked = oracle.blocked().await.unwrap();
+                assert!(blocked.is_empty(), "no peers should be blocked yet");
+
+                // Peer 1 sends the same strong shard AGAIN (duplicate while leader unknown).
+                peers[1]
+                    .sender
+                    .send(Recipients::One(peer2_pk), strong_bytes, true)
+                    .await
+                    .expect("send failed");
+                context.sleep(config.link.latency * 2).await;
+
+                // Still no blocking before a leader is known.
+                let blocked = oracle.blocked().await.unwrap();
+                assert!(
+                    blocked.is_empty(),
+                    "no peers should be blocked before leader"
+                );
+            },
+        );
+    }
+
+    #[test_traced]
+    fn test_invalid_strong_shard_crypto_blocks_leader() {
+        // Test that a strong shard failing cryptographic verification (C::weaken)
+        // results in the leader being blocked.
+        let fixture: Fixture<C> = Fixture {
+            ..Default::default()
+        };
+
+        fixture.start(
+            |config, context, oracle, mut peers, coding_config| async move {
+                // Create two different blocks — shard from block2 won't verify
+                // against commitment from block1.
+                let inner1 = B::new::<H>((), Sha256Digest::EMPTY, Height::new(1), 100);
+                let coded_block1 = CodedBlock::<B, C>::new(inner1, coding_config, &STRATEGY);
+                let commitment1 = coded_block1.commitment();
+
+                let inner2 = B::new::<H>((), Sha256Digest::EMPTY, Height::new(2), 200);
+                let coded_block2 = CodedBlock::<B, C>::new(inner2, coding_config, &STRATEGY);
+
+                // Get peer 2's strong shard from block2, but re-wrap it with
+                // block1's commitment so it fails C::weaken.
+                let peer2_index = peers[2].index.get() as u16;
+                let mut wrong_shard = coded_block2.shard::<H>(peer2_index).expect("missing shard");
+                wrong_shard.commitment = commitment1;
+                let wrong_bytes = wrong_shard.encode();
+
+                let peer2_pk = peers[2].public_key.clone();
+                let leader = peers[0].public_key.clone();
+
+                // Inform peer 2 that peer 0 is the leader.
+                peers[2]
+                    .mailbox
+                    .discovered(commitment1, leader, Round::new(Epoch::zero(), View::new(1)))
+                    .await;
+
+                // Leader (peer 0) sends the invalid strong shard.
+                peers[0]
+                    .sender
+                    .send(Recipients::One(peer2_pk), wrong_bytes, true)
+                    .await
+                    .expect("send failed");
+                context.sleep(config.link.latency * 2).await;
+
+                // Peer 0 (leader) should be blocked for invalid crypto.
+                assert_blocked(&oracle, &peers[2].public_key, &peers[0].public_key).await;
+            },
+        );
+    }
+
+    #[test_traced]
+    fn test_weak_shard_index_mismatch_blocks_peer() {
+        // Test that a weak shard whose shard index doesn't match the sender's
+        // participant index results in blocking the sender.
+        let fixture: Fixture<C> = Fixture {
+            num_peers: 10,
+            ..Default::default()
+        };
+
+        fixture.start(
+            |config, context, oracle, mut peers, coding_config| async move {
+                let inner = B::new::<H>((), Sha256Digest::EMPTY, Height::new(1), 100);
+                let coded_block = CodedBlock::<B, C>::new(inner, coding_config, &STRATEGY);
+                let commitment = coded_block.commitment();
+
+                // Get peer 2's strong shard so peer 3 can validate weak shards.
+                let peer3_index = peers[3].index.get() as u16;
+                let peer3_strong_shard =
+                    coded_block.shard::<H>(peer3_index).expect("missing shard");
+
+                // Get peer 1's valid weak shard, then change the index to peer 4's index.
+                let peer1_index = peers[1].index.get() as u16;
+                let mut wrong_index_weak_shard = coded_block
+                    .shard::<H>(peer1_index)
+                    .expect("missing shard")
+                    .verify_into_weak()
+                    .expect("verify_into_weak failed");
+                // Mutate the index so it doesn't match sender (peer 1).
+                wrong_index_weak_shard.index = peers[4].index.get() as u16;
+                let wrong_bytes = wrong_index_weak_shard.encode();
+
+                let peer3_pk = peers[3].public_key.clone();
+                let leader = peers[0].public_key.clone();
+
+                // Inform peer 3 of the leader and send them the strong shard.
+                peers[3]
+                    .mailbox
+                    .discovered(commitment, leader, Round::new(Epoch::zero(), View::new(1)))
+                    .await;
+                let strong_bytes = peer3_strong_shard.encode();
+                peers[0]
+                    .sender
+                    .send(Recipients::One(peer3_pk.clone()), strong_bytes, true)
+                    .await
+                    .expect("send failed");
+                context.sleep(config.link.latency * 2).await;
+
+                // Peer 1 sends a weak shard with a mismatched index to peer 3.
+                peers[1]
+                    .sender
+                    .send(Recipients::One(peer3_pk), wrong_bytes, true)
+                    .await
+                    .expect("send failed");
+                context.sleep(config.link.latency * 2).await;
+
+                // Peer 1 should be blocked for weak shard index mismatch.
+                assert_blocked(&oracle, &peers[3].public_key, &peers[1].public_key).await;
+            },
+        );
+    }
+
+    #[test_traced]
+    fn test_invalid_weak_shard_crypto_blocks_peer() {
+        // Test that a weak shard failing cryptographic verification (C::check)
+        // results in blocking the sender once batch validation fires at quorum.
+        let fixture: Fixture<C> = Fixture {
+            num_peers: 10,
+            ..Default::default()
+        };
+
+        fixture.start(
+            |config, context, oracle, mut peers, coding_config| async move {
+                // Create two different blocks.
+                let inner1 = B::new::<H>((), Sha256Digest::EMPTY, Height::new(1), 100);
+                let coded_block1 = CodedBlock::<B, C>::new(inner1, coding_config, &STRATEGY);
+                let commitment1 = coded_block1.commitment();
+
+                let inner2 = B::new::<H>((), Sha256Digest::EMPTY, Height::new(2), 200);
+                let coded_block2 = CodedBlock::<B, C>::new(inner2, coding_config, &STRATEGY);
+
+                // Get peer 3's strong shard from block1 (valid).
+                let peer3_index = peers[3].index.get() as u16;
+                let peer3_strong_shard =
+                    coded_block1.shard::<H>(peer3_index).expect("missing shard");
+
+                // Get peer 1's weak shard from block2, but re-wrap with block1's
+                // commitment so C::check fails.
+                let peer1_index = peers[1].index.get() as u16;
+                let mut wrong_weak_shard = coded_block2
+                    .shard::<H>(peer1_index)
+                    .expect("missing shard")
+                    .verify_into_weak()
+                    .expect("verify_into_weak failed");
+                wrong_weak_shard.commitment = commitment1;
+                let wrong_bytes = wrong_weak_shard.encode();
+
+                let peer3_pk = peers[3].public_key.clone();
+                let leader = peers[0].public_key.clone();
+
+                // Inform peer 3 of the leader and send the valid strong shard.
+                peers[3]
+                    .mailbox
+                    .discovered(commitment1, leader, Round::new(Epoch::zero(), View::new(1)))
+                    .await;
+                let strong_bytes = peer3_strong_shard.encode();
+                peers[0]
+                    .sender
+                    .send(Recipients::One(peer3_pk.clone()), strong_bytes, true)
+                    .await
+                    .expect("send failed");
+                context.sleep(config.link.latency * 2).await;
+
+                // Peer 1 sends the invalid weak shard.
+                peers[1]
+                    .sender
+                    .send(Recipients::One(peer3_pk.clone()), wrong_bytes, true)
+                    .await
+                    .expect("send failed");
+                context.sleep(config.link.latency * 2).await;
+
+                // No block yet: batch validation deferred until quorum.
+                // Send valid weak shards from peers 2 and 4 to reach quorum
+                // (minimum_shards = 4: 1 strong + 3 pending weak).
+                for &idx in &[2, 4] {
+                    let peer_index = peers[idx].index.get() as u16;
+                    let weak = coded_block1
+                        .shard::<H>(peer_index)
+                        .expect("missing shard")
+                        .verify_into_weak()
+                        .expect("verify_into_weak failed");
+                    let bytes = weak.encode();
+                    peers[idx]
+                        .sender
+                        .send(Recipients::One(peer3_pk.clone()), bytes, true)
+                        .await
+                        .expect("send failed");
+                }
+                context.sleep(config.link.latency * 2).await;
+
+                // Peer 1 should be blocked for invalid weak shard crypto.
+                assert_blocked(&oracle, &peers[3].public_key, &peers[1].public_key).await;
+            },
+        );
+    }
+
+    #[test_traced]
+    fn test_reconstruction_recovers_after_quorum_with_one_invalid_weak_shard() {
+        // With 10 peers, minimum_shards=4.
+        // Contribute exactly 4 shards first (1 strong + 3 weak), with one weak invalid:
+        // quorum is reached, but checked_shards stays at 3 after batch validation.
+        // Then send one more valid weak shard to meet reconstruction threshold.
+        let fixture: Fixture<C> = Fixture {
+            num_peers: 10,
+            ..Default::default()
+        };
+
+        fixture.start(
+            |config, context, oracle, mut peers, coding_config| async move {
+                let inner1 = B::new::<H>((), Sha256Digest::EMPTY, Height::new(1), 100);
+                let coded_block1 = CodedBlock::<B, C>::new(inner1, coding_config, &STRATEGY);
+                let commitment1 = coded_block1.commitment();
+
+                let inner2 = B::new::<H>((), Sha256Digest::EMPTY, Height::new(2), 200);
+                let coded_block2 = CodedBlock::<B, C>::new(inner2, coding_config, &STRATEGY);
+
+                let receiver_idx = 3usize;
+                let receiver_pk = peers[receiver_idx].public_key.clone();
+
+                // Prepare one invalid weak shard: shard data from block2, commitment from block1.
+                let peer1_index = peers[1].index.get() as u16;
+                let mut invalid_weak = coded_block2
+                    .shard::<H>(peer1_index)
+                    .expect("missing shard")
+                    .verify_into_weak()
+                    .expect("verify_into_weak failed");
+                invalid_weak.commitment = commitment1;
+
+                // Announce leader and deliver receiver's strong shard.
+                let leader = peers[0].public_key.clone();
+                peers[receiver_idx]
+                    .mailbox
+                    .discovered(commitment1, leader, Round::new(Epoch::zero(), View::new(1)))
+                    .await;
+                let receiver_strong = coded_block1
+                    .shard::<H>(peers[receiver_idx].index.get() as u16)
+                    .expect("missing shard")
+                    .encode();
+                peers[0]
+                    .sender
+                    .send(Recipients::One(receiver_pk.clone()), receiver_strong, true)
+                    .await
+                    .expect("send failed");
+
+                // Contribute exactly minimum_shards total:
+                // - invalid weak from peer1
+                // - valid weak from peer2
+                // - valid weak from peer4
+                peers[1]
+                    .sender
+                    .send(
+                        Recipients::One(receiver_pk.clone()),
+                        invalid_weak.encode(),
+                        true,
+                    )
+                    .await
+                    .expect("send failed");
+                for idx in [2usize, 4usize] {
+                    let weak = coded_block1
+                        .shard::<H>(peers[idx].index.get() as u16)
+                        .expect("missing shard")
+                        .verify_into_weak()
+                        .expect("verify_into_weak failed")
+                        .encode();
+                    peers[idx]
+                        .sender
+                        .send(Recipients::One(receiver_pk.clone()), weak, true)
+                        .await
+                        .expect("send failed");
+                }
+
+                context.sleep(config.link.latency * 2).await;
+
+                // Invalid weak shard should be blocked, and reconstruction should not happen yet.
+                assert_blocked(
+                    &oracle,
+                    &peers[receiver_idx].public_key,
+                    &peers[1].public_key,
+                )
+                .await;
+                assert!(
+                    peers[receiver_idx].mailbox.get(commitment1).await.is_none(),
+                    "block should not reconstruct with only 3 checked shards"
+                );
+
+                // Send one additional valid weak shard; this should now satisfy checked threshold.
+                let extra_valid = coded_block1
+                    .shard::<H>(peers[5].index.get() as u16)
+                    .expect("missing shard")
+                    .verify_into_weak()
+                    .expect("verify_into_weak failed")
+                    .encode();
+                peers[5]
+                    .sender
+                    .send(Recipients::One(receiver_pk), extra_valid, true)
+                    .await
+                    .expect("send failed");
+
+                context.sleep(config.link.latency * 2).await;
+
+                let reconstructed = peers[receiver_idx]
+                    .mailbox
+                    .get(commitment1)
+                    .await
+                    .expect("block should reconstruct after additional valid weak shard");
+                assert_eq!(reconstructed.commitment(), commitment1);
+            },
+        );
+    }
+
+    #[test_traced]
+    fn test_invalid_pending_weak_shard_blocked_on_drain() {
+        // Test that a weak shard buffered in pending_weak_shards (before checking data) is
+        // blocked when batch validation runs at quorum and C::check fails.
+        let fixture: Fixture<C> = Fixture {
+            num_peers: 10,
+            ..Default::default()
+        };
+
+        fixture.start(
+            |config, context, oracle, mut peers, coding_config| async move {
+                // Create two different blocks.
+                let inner1 = B::new::<H>((), Sha256Digest::EMPTY, Height::new(1), 100);
+                let coded_block1 = CodedBlock::<B, C>::new(inner1, coding_config, &STRATEGY);
+                let commitment1 = coded_block1.commitment();
+
+                let inner2 = B::new::<H>((), Sha256Digest::EMPTY, Height::new(2), 200);
+                let coded_block2 = CodedBlock::<B, C>::new(inner2, coding_config, &STRATEGY);
+
+                // Get peer 1's weak shard from block2, but wrap with block1's commitment.
+                let peer1_index = peers[1].index.get() as u16;
+                let mut wrong_weak_shard = coded_block2
+                    .shard::<H>(peer1_index)
+                    .expect("missing shard")
+                    .verify_into_weak()
+                    .expect("verify_into_weak failed");
+                wrong_weak_shard.commitment = commitment1;
+                let wrong_bytes = wrong_weak_shard.encode();
+
+                let peer3_pk = peers[3].public_key.clone();
+
+                // Send the invalid weak shard BEFORE the strong shard (no checking data yet,
+                // so it gets buffered in pending_weak_shards).
+                peers[1]
+                    .sender
+                    .send(Recipients::One(peer3_pk.clone()), wrong_bytes, true)
+                    .await
+                    .expect("send failed");
+                context.sleep(config.link.latency * 2).await;
+
+                // No one should be blocked yet (weak shard is buffered).
+                let blocked = oracle.blocked().await.unwrap();
+                assert!(blocked.is_empty(), "no peers should be blocked yet");
+
+                // Send valid weak shards from peers 2 and 4 so the pending count
+                // reaches quorum once the strong shard arrives
+                // (minimum_shards = 4: 1 strong + 3 pending weak).
+                for &idx in &[2, 4] {
+                    let peer_index = peers[idx].index.get() as u16;
+                    let weak = coded_block1
+                        .shard::<H>(peer_index)
+                        .expect("missing shard")
+                        .verify_into_weak()
+                        .expect("verify_into_weak failed");
+                    let bytes = weak.encode();
+                    peers[idx]
+                        .sender
+                        .send(Recipients::One(peer3_pk.clone()), bytes, true)
+                        .await
+                        .expect("send failed");
+                }
+                context.sleep(config.link.latency * 2).await;
+
+                // No one should be blocked yet (all shards are buffered pending leader).
+                let blocked = oracle.blocked().await.unwrap();
+                assert!(blocked.is_empty(), "no peers should be blocked yet");
+
+                // Now inform peer 3 of the leader and send the valid strong shard.
+                let leader = peers[0].public_key.clone();
+                peers[3]
+                    .mailbox
+                    .discovered(commitment1, leader, Round::new(Epoch::zero(), View::new(1)))
+                    .await;
+                let peer3_index = peers[3].index.get() as u16;
+                let peer3_strong_shard =
+                    coded_block1.shard::<H>(peer3_index).expect("missing shard");
+                let strong_bytes = peer3_strong_shard.encode();
+                peers[0]
+                    .sender
+                    .send(Recipients::One(peer3_pk), strong_bytes, true)
+                    .await
+                    .expect("send failed");
+                context.sleep(config.link.latency * 2).await;
+
+                // Peer 1 should be blocked after batch validation validates and
+                // rejects their invalid weak shard.
+                assert_blocked(&oracle, &peers[3].public_key, &peers[1].public_key).await;
+            },
+        );
+    }
+
+    #[test_traced]
+    fn test_cross_epoch_buffered_shard_not_blocked() {
+        let executor = deterministic::Runner::default();
+        executor.start(|context| async move {
+            let (network, oracle) = simulated::Network::<deterministic::Context, P>::new(
+                context.with_label("network"),
+                simulated::Config {
+                    max_size: MAX_SHARD_SIZE as u32,
+                    disconnect_on_block: true,
+                    tracked_peer_sets: None,
+                },
+            );
+            network.start();
+
+            // Epoch 0 participants: peers 0..4 (seeds 0..4).
+            // Epoch 1 participants: peers 0..3 + peer 4 (seed 4 replaces seed 3).
+            let mut epoch0_keys: Vec<PrivateKey> = (0..4).map(PrivateKey::from_seed).collect();
+            epoch0_keys.sort_by_key(|s| s.public_key());
+            let epoch0_pks: Vec<P> = epoch0_keys.iter().map(|c| c.public_key()).collect();
+            let epoch0_set: Set<P> = Set::from_iter_dedup(epoch0_pks.clone());
+
+            let future_peer_key = PrivateKey::from_seed(4);
+            let future_peer_pk = future_peer_key.public_key();
+            let mut epoch1_pks: Vec<P> = epoch0_pks[..3]
+                .iter()
+                .cloned()
+                .chain(std::iter::once(future_peer_pk.clone()))
+                .collect();
+            epoch1_pks.sort();
+            let epoch1_set: Set<P> = Set::from_iter_dedup(epoch1_pks);
+
+            let receiver_idx_in_epoch0 = epoch0_set
+                .index(&epoch0_pks[0])
+                .expect("receiver must be in epoch 0")
+                .get() as usize;
+            let receiver_key = epoch0_keys[receiver_idx_in_epoch0].clone();
+            let receiver_pk = receiver_key.public_key();
+
+            let receiver_control = oracle.control(receiver_pk.clone());
+            let (sender_handle, receiver_handle) = receiver_control
+                .register(0, TEST_QUOTA)
+                .await
+                .expect("registration should succeed");
+
+            let future_peer_control = oracle.control(future_peer_pk.clone());
+            let (mut future_peer_sender, _future_peer_receiver) = future_peer_control
+                .register(0, TEST_QUOTA)
+                .await
+                .expect("registration should succeed");
+            oracle
+                .add_link(future_peer_pk.clone(), receiver_pk.clone(), DEFAULT_LINK)
+                .await
+                .expect("link should be added");
+
+            // Set up the receiver's engine with a multi-epoch provider.
+            let scheme_epoch0 =
+                Scheme::signer(SCHEME_NAMESPACE, epoch0_set.clone(), receiver_key.clone())
+                    .expect("signer scheme should be created");
+            let scheme_epoch1 =
+                Scheme::signer(SCHEME_NAMESPACE, epoch1_set.clone(), receiver_key.clone())
+                    .expect("signer scheme should be created");
+            let scheme_provider =
+                MultiEpochProvider::single(scheme_epoch0).with_epoch(Epoch::new(1), scheme_epoch1);
+
+            let config: Config<_, _, _, C, _, _, _> = Config {
+                scheme_provider,
+                blocker: receiver_control.clone(),
+                shard_codec_cfg: CodecConfig {
+                    maximum_shard_size: MAX_SHARD_SIZE,
+                },
+                block_codec_cfg: (),
+                strategy: STRATEGY,
+                mailbox_size: 1024,
+                peer_buffer_size: NZUsize!(64),
+                background_channel_capacity: 1024,
+            };
+
+            let (engine, mailbox) = ShardEngine::new(context.with_label("receiver"), config);
+            engine.start((sender_handle, receiver_handle));
+
+            // Build a coded block using epoch 1's participant set.
+            let coding_config = coding_config_for_participants(epoch1_set.len() as u16);
+            let inner = B::new::<H>((), Sha256Digest::EMPTY, Height::new(1), 100);
+            let coded_block = CodedBlock::<B, C>::new(inner, coding_config, &STRATEGY);
+            let commitment = coded_block.commitment();
+
+            // The future peer creates a weak shard at their epoch 1 index.
+            let future_peer_index = epoch1_set
+                .index(&future_peer_pk)
+                .expect("future peer must be in epoch 1");
+            let strong_shard = coded_block
+                .shard::<H>(future_peer_index.get() as u16)
+                .expect("missing shard");
+            let weak_shard = strong_shard
+                .verify_into_weak()
+                .expect("verify_into_weak failed");
+            let weak_bytes = weak_shard.encode();
+
+            // Send the shard BEFORE external_proposed (goes to pre-leader buffer).
+            future_peer_sender
+                .send(Recipients::One(receiver_pk.clone()), weak_bytes, true)
+                .await
+                .expect("send failed");
+            context.sleep(DEFAULT_LINK.latency * 2).await;
+
+            // No one should be blocked yet (shard is buffered, leader unknown).
+            let blocked = oracle.blocked().await.unwrap();
+            assert!(
+                blocked.is_empty(),
+                "no peers should be blocked while shard is buffered"
+            );
+
+            // Announce the leader with an epoch 1 round.
+            let leader = epoch0_pks[1].clone();
+            mailbox
+                .discovered(commitment, leader, Round::new(Epoch::new(1), View::new(1)))
+                .await;
+            context.sleep(DEFAULT_LINK.latency * 2).await;
+
+            // The future peer is a valid participant in epoch 1, so they must NOT
+            // be blocked after their buffered shard is ingested.
+            let blocked = oracle.blocked().await.unwrap();
+            assert!(
+                blocked.is_empty(),
+                "future-epoch participant should not be blocked: {blocked:?}"
+            );
+        });
+    }
+
+    #[test_traced]
+    fn test_failed_reconstruction_digest_mismatch_then_recovery() {
+        // Byzantine scenario: all shards pass coding verification (correct root) but the
+        // decoded blob has a different digest than what the commitment claims. This triggers
+        // Error::DigestMismatch in try_reconstruct. Verify that:
+        //   1. The failed commitment's state is cleaned up
+        //   2. Subscriptions for the failed commitment never resolve
+        //   3. A subsequent valid commitment reconstructs successfully
+        let fixture: Fixture<C> = Fixture {
+            num_peers: 10,
+            ..Default::default()
+        };
+
+        fixture.start(
+            |config, context, _oracle, mut peers, coding_config| async move {
+                // Block 1: the "claimed" block (its digest goes in the fake commitment).
+                let inner1 = B::new::<H>((), Sha256Digest::EMPTY, Height::new(1), 100);
+                let coded_block1 = CodedBlock::<B, C>::new(inner1, coding_config, &STRATEGY);
+
+                // Block 2: the actual data behind the shards.
+                let inner2 = B::new::<H>((), Sha256Digest::EMPTY, Height::new(2), 200);
+                let coded_block2 = CodedBlock::<B, C>::new(inner2, coding_config, &STRATEGY);
+                let real_commitment2 = coded_block2.commitment();
+
+                // Build a fake commitment: block1's digest + block2's coding root/context/config.
+                // Shards from block2 will verify against block2's root (present in the fake
+                // commitment), but try_reconstruct will decode block2 and find its digest != D1.
+                let fake_commitment = Commitment::from((
+                    coded_block1.digest(),
+                    real_commitment2.root::<Sha256Digest>(),
+                    real_commitment2.context::<Sha256Digest>(),
+                    coding_config,
+                ));
+
+                let receiver_idx = 3usize;
+                let receiver_pk = peers[receiver_idx].public_key.clone();
+                let leader = peers[0].public_key.clone();
+                let round = Round::new(Epoch::zero(), View::new(1));
+
+                // Discover the fake commitment.
+                peers[receiver_idx]
+                    .mailbox
+                    .discovered(fake_commitment, leader.clone(), round)
+                    .await;
+
+                // Open a block subscription before sending shards.
+                let mut block_sub = peers[receiver_idx].mailbox.subscribe(fake_commitment).await;
+                let mut digest_sub = peers[receiver_idx]
+                    .mailbox
+                    .subscribe_by_digest(coded_block1.digest())
+                    .await;
+
+                // Send the receiver's strong shard (from block2, with fake commitment).
+                let receiver_shard_idx = peers[receiver_idx].index.get() as u16;
+                let mut strong_shard = coded_block2
+                    .shard::<H>(receiver_shard_idx)
+                    .expect("missing shard");
+                strong_shard.commitment = fake_commitment;
+                peers[0]
+                    .sender
+                    .send(
+                        Recipients::One(receiver_pk.clone()),
+                        strong_shard.encode(),
+                        true,
+                    )
+                    .await
+                    .expect("send failed");
+
+                // Send enough weak shards to reach minimum_shards (4 for 10 peers).
+                // Need 3 more weak shards after the strong shard.
+                for &idx in &[1usize, 2, 4] {
+                    let peer_shard_idx = peers[idx].index.get() as u16;
+                    let mut weak = coded_block2
+                        .shard::<H>(peer_shard_idx)
+                        .expect("missing shard")
+                        .verify_into_weak()
+                        .expect("verify_into_weak failed");
+                    weak.commitment = fake_commitment;
+                    peers[idx]
+                        .sender
+                        .send(Recipients::One(receiver_pk.clone()), weak.encode(), true)
+                        .await
+                        .expect("send failed");
+                }
+
+                context.sleep(config.link.latency * 2).await;
+
+                // Reconstruction should have failed with DigestMismatch.
+                // State for fake_commitment should be removed (engine.rs:792).
+                assert!(
+                    peers[receiver_idx]
+                        .mailbox
+                        .get(fake_commitment)
+                        .await
+                        .is_none(),
+                    "block should not be available after DigestMismatch"
+                );
+
+                // Block subscription should be closed after failed reconstruction cleanup.
+                assert!(
+                    matches!(block_sub.try_recv(), Err(TryRecvError::Closed)),
+                    "subscription should close for failed reconstruction"
+                );
+                assert!(
+                    matches!(digest_sub.try_recv(), Err(TryRecvError::Closed)),
+                    "digest subscription should close after failed reconstruction"
+                );
+
+                // Now verify the engine is not stuck: send valid shards for block1's real
+                // commitment and confirm reconstruction succeeds.
+                let real_commitment1 = coded_block1.commitment();
+                let round2 = Round::new(Epoch::zero(), View::new(2));
+                peers[receiver_idx]
+                    .mailbox
+                    .discovered(real_commitment1, leader.clone(), round2)
+                    .await;
+
+                let strong1 = coded_block1
+                    .shard::<H>(receiver_shard_idx)
+                    .expect("missing shard");
+                peers[0]
+                    .sender
+                    .send(Recipients::One(receiver_pk.clone()), strong1.encode(), true)
+                    .await
+                    .expect("send failed");
+
+                for &idx in &[1usize, 2, 4] {
+                    let peer_shard_idx = peers[idx].index.get() as u16;
+                    let weak = coded_block1
+                        .shard::<H>(peer_shard_idx)
+                        .expect("missing shard")
+                        .verify_into_weak()
+                        .expect("verify_into_weak failed");
+                    peers[idx]
+                        .sender
+                        .send(Recipients::One(receiver_pk.clone()), weak.encode(), true)
+                        .await
+                        .expect("send failed");
+                }
+
+                context.sleep(config.link.latency * 2).await;
+
+                let reconstructed = peers[receiver_idx]
+                    .mailbox
+                    .get(real_commitment1)
+                    .await
+                    .expect("valid block should reconstruct after prior failure");
+                assert_eq!(reconstructed.commitment(), real_commitment1);
+            },
+        );
+    }
+
+    #[test_traced]
+    fn test_failed_reconstruction_context_mismatch_then_recovery() {
+        // Byzantine scenario: shards decode to a block whose digest and coding root/config
+        // match the commitment, but the commitment carries a mismatched context hash.
+        // The engine must reject reconstruction and keep the commitment unresolved.
+        let fixture: Fixture<C> = Fixture {
+            num_peers: 10,
+            ..Default::default()
+        };
+
+        fixture.start(
+            |config, context, _oracle, mut peers, coding_config| async move {
+                let inner = B::new::<H>((), Sha256Digest::EMPTY, Height::new(1), 100);
+                let coded_block = CodedBlock::<B, C>::new(inner, coding_config, &STRATEGY);
+                let real_commitment = coded_block.commitment();
+
+                let wrong_context_hash = Sha256::hash(b"wrong_context");
+                assert_ne!(
+                    real_commitment.context::<Sha256Digest>(),
+                    wrong_context_hash,
+                    "test requires a distinct context hash"
+                );
+                let fake_commitment = Commitment::from((
+                    coded_block.digest(),
+                    real_commitment.root::<Sha256Digest>(),
+                    wrong_context_hash,
+                    coding_config,
+                ));
+
+                let receiver_idx = 3usize;
+                let receiver_pk = peers[receiver_idx].public_key.clone();
+                let leader = peers[0].public_key.clone();
+                let round = Round::new(Epoch::zero(), View::new(1));
+
+                peers[receiver_idx]
+                    .mailbox
+                    .discovered(fake_commitment, leader.clone(), round)
+                    .await;
+                let mut block_sub = peers[receiver_idx].mailbox.subscribe(fake_commitment).await;
+
+                let receiver_shard_idx = peers[receiver_idx].index.get() as u16;
+                let mut strong_shard = coded_block
+                    .shard::<H>(receiver_shard_idx)
+                    .expect("missing shard");
+                strong_shard.commitment = fake_commitment;
+                peers[0]
+                    .sender
+                    .send(
+                        Recipients::One(receiver_pk.clone()),
+                        strong_shard.encode(),
+                        true,
+                    )
+                    .await
+                    .expect("send failed");
+
+                for &idx in &[1usize, 2, 4] {
+                    let peer_shard_idx = peers[idx].index.get() as u16;
+                    let mut weak = coded_block
+                        .shard::<H>(peer_shard_idx)
+                        .expect("missing shard")
+                        .verify_into_weak()
+                        .expect("verify_into_weak failed");
+                    weak.commitment = fake_commitment;
+                    peers[idx]
+                        .sender
+                        .send(Recipients::One(receiver_pk.clone()), weak.encode(), true)
+                        .await
+                        .expect("send failed");
+                }
+
+                context.sleep(config.link.latency * 2).await;
+
+                assert!(
+                    peers[receiver_idx]
+                        .mailbox
+                        .get(fake_commitment)
+                        .await
+                        .is_none(),
+                    "block should not be available after ContextMismatch"
+                );
+                assert!(
+                    matches!(block_sub.try_recv(), Err(TryRecvError::Closed)),
+                    "subscription should close for context-mismatched commitment"
+                );
+
+                // Verify the receiver still reconstructs valid commitments afterward.
+                let round2 = Round::new(Epoch::zero(), View::new(2));
+                peers[receiver_idx]
+                    .mailbox
+                    .discovered(real_commitment, leader.clone(), round2)
+                    .await;
+
+                let strong_real = coded_block
+                    .shard::<H>(receiver_shard_idx)
+                    .expect("missing shard");
+                peers[0]
+                    .sender
+                    .send(
+                        Recipients::One(receiver_pk.clone()),
+                        strong_real.encode(),
+                        true,
+                    )
+                    .await
+                    .expect("send failed");
+
+                for &idx in &[1usize, 2, 4] {
+                    let peer_shard_idx = peers[idx].index.get() as u16;
+                    let weak = coded_block
+                        .shard::<H>(peer_shard_idx)
+                        .expect("missing shard")
+                        .verify_into_weak()
+                        .expect("verify_into_weak failed");
+                    peers[idx]
+                        .sender
+                        .send(Recipients::One(receiver_pk.clone()), weak.encode(), true)
+                        .await
+                        .expect("send failed");
+                }
+
+                context.sleep(config.link.latency * 2).await;
+
+                let reconstructed = peers[receiver_idx]
+                    .mailbox
+                    .get(real_commitment)
+                    .await
+                    .expect("valid block should reconstruct after prior context mismatch");
+                assert_eq!(reconstructed.commitment(), real_commitment);
+            },
+        );
+    }
+}
diff --git a/consensus/src/marshal/coding/shards/mailbox.rs b/consensus/src/marshal/coding/shards/mailbox.rs
new file mode 100644
index 000000000..25117f97a
--- /dev/null
+++ b/consensus/src/marshal/coding/shards/mailbox.rs
@@ -0,0 +1,189 @@
+//! Mailbox for the shard buffer engine.
+
+use crate::{
+    marshal::coding::types::CodedBlock,
+    types::{coding::Commitment, Round},
+    CertifiableBlock,
+};
+use commonware_coding::Scheme as CodingScheme;
+use commonware_cryptography::PublicKey;
+use commonware_utils::channel::{fallible::AsyncFallibleExt, mpsc, oneshot};
+use std::sync::Arc;
+
+/// A message that can be sent to the coding [`Engine`].
+///
+/// [`Engine`]: super::Engine
+pub enum Message<B, C, P>
+where
+    B: CertifiableBlock,
+    C: CodingScheme,
+    P: PublicKey,
+{
+    /// A request to broadcast a proposed [`CodedBlock`] to all peers.
+    Proposed {
+        /// The erasure coded block.
+        block: CodedBlock<B, C>,
+        /// The round in which the block was proposed.
+        round: Round,
+    },
+    /// A notification from consensus that a [`Commitment`] has been discovered.
+    Discovered {
+        /// The [`Commitment`] of the proposed block.
+        commitment: Commitment,
+        /// The leader's public key.
+        leader: P,
+        /// The round in which the commitment was proposed.
+        round: Round,
+    },
+    /// A request to get a reconstructed block, if available.
+    GetByCommitment {
+        /// The [`Commitment`] of the block to get.
+        commitment: Commitment,
+        /// The response channel.
+        response: oneshot::Sender<Option<Arc<CodedBlock<B, C>>>>,
+    },
+    /// A request to get a reconstructed block by its digest, if available.
+    GetByDigest {
+        /// The digest of the block to get.
+        digest: B::Digest,
+        /// The response channel.
+        response: oneshot::Sender<Option<Arc<CodedBlock<B, C>>>>,
+    },
+    /// A request to open a subscription for the receipt of our valid shard from
+    /// the leader.
+    SubscribeShard {
+        /// The block's commitment.
+        commitment: Commitment,
+        /// The response channel.
+        response: oneshot::Sender<()>,
+    },
+    /// A request to open a subscription for the reconstruction of a [`CodedBlock`]
+    /// by its [`Commitment`].
+    SubscribeByCommitment {
+        /// The block's digest.
+        commitment: Commitment,
+        /// The response channel.
+        response: oneshot::Sender<Arc<CodedBlock<B, C>>>,
+    },
+    /// A request to open a subscription for the reconstruction of a [`CodedBlock`]
+    /// by its digest.
+    SubscribeByDigest {
+        /// The block's digest.
+        digest: B::Digest,
+        /// The response channel.
+        response: oneshot::Sender<Arc<CodedBlock<B, C>>>,
+    },
+    /// A request to prune all caches at and below the given commitment.
+    Prune {
+        /// The prune target's [`Commitment`].
+        min: Commitment,
+    },
+}
+
+/// A mailbox for sending messages to the [`Engine`].
+///
+/// [`Engine`]: super::Engine
+#[derive(Clone)]
+pub struct Mailbox<B, C, P>
+where
+    B: CertifiableBlock,
+    C: CodingScheme,
+    P: PublicKey,
+{
+    pub(super) sender: mpsc::Sender<Message<B, C, P>>,
+}
+
+impl<B, C, P> Mailbox<B, C, P>
+where
+    B: CertifiableBlock,
+    C: CodingScheme,
+    P: PublicKey,
+{
+    /// Create a new [`Mailbox`] with the given sender.
+    pub const fn new(sender: mpsc::Sender<Message<B, C, P>>) -> Self {
+        Self { sender }
+    }
+
+    /// Broadcast a proposed erasure coded block's shards to the participants.
+    pub async fn proposed(&self, round: Round, block: CodedBlock<B, C>) {
+        let msg = Message::Proposed { block, round };
+        self.sender.send_lossy(msg).await;
+    }
+
+    /// Inform the engine of an externally proposed [`Commitment`].
+    pub async fn discovered(&self, commitment: Commitment, leader: P, round: Round) {
+        let msg = Message::Discovered {
+            commitment,
+            leader,
+            round,
+        };
+        self.sender.send_lossy(msg).await;
+    }
+
+    /// Request a reconstructed block by its [`Commitment`].
+    pub async fn get(&self, commitment: Commitment) -> Option<Arc<CodedBlock<B, C>>> {
+        self.sender
+            .request(|tx| Message::GetByCommitment {
+                commitment,
+                response: tx,
+            })
+            .await
+            .flatten()
+    }
+
+    /// Request a reconstructed block by its digest.
+    pub async fn get_by_digest(&self, digest: B::Digest) -> Option<Arc<CodedBlock<B, C>>> {
+        self.sender
+            .request(|tx| Message::GetByDigest {
+                digest,
+                response: tx,
+            })
+            .await
+            .flatten()
+    }
+
+    /// Subscribe to the receipt of our valid shard from the leader.
+    pub async fn subscribe_shard(&self, commitment: Commitment) -> oneshot::Receiver<()> {
+        let (responder, receiver) = oneshot::channel();
+        let msg = Message::SubscribeShard {
+            commitment,
+            response: responder,
+        };
+        self.sender.send_lossy(msg).await;
+        receiver
+    }
+
+    /// Subscribe to the reconstruction of a [`CodedBlock`] by its [`Commitment`].
+    pub async fn subscribe(
+        &self,
+        commitment: Commitment,
+    ) -> oneshot::Receiver<Arc<CodedBlock<B, C>>> {
+        let (responder, receiver) = oneshot::channel();
+        let msg = Message::SubscribeByCommitment {
+            commitment,
+            response: responder,
+        };
+        self.sender.send_lossy(msg).await;
+        receiver
+    }
+
+    /// Subscribe to the reconstruction of a [`CodedBlock`] by its digest.
+    pub async fn subscribe_by_digest(
+        &self,
+        digest: B::Digest,
+    ) -> oneshot::Receiver<Arc<CodedBlock<B, C>>> {
+        let (responder, receiver) = oneshot::channel();
+        let msg = Message::SubscribeByDigest {
+            digest,
+            response: responder,
+        };
+        self.sender.send_lossy(msg).await;
+        receiver
+    }
+
+    /// Request to prune all caches at and below the given commitment.
+    pub async fn prune(&self, min: Commitment) {
+        let msg = Message::Prune { min };
+        self.sender.send_lossy(msg).await;
+    }
+}
diff --git a/consensus/src/marshal/coding/shards/metrics.rs b/consensus/src/marshal/coding/shards/metrics.rs
new file mode 100644
index 000000000..57c2f7956
--- /dev/null
+++ b/consensus/src/marshal/coding/shards/metrics.rs
@@ -0,0 +1,89 @@
+//! Metrics for the shard engine.
+
+use commonware_runtime::{telemetry::metrics::histogram::Buckets, Metrics as MetricsTrait};
+use commonware_utils::Array;
+use prometheus_client::{
+    encoding::EncodeLabelSet,
+    metrics::{counter::Counter, family::Family, gauge::Gauge, histogram::Histogram},
+};
+
+/// Label for per-peer metrics.
+#[derive(Clone, Debug, Hash, PartialEq, Eq, EncodeLabelSet)]
+pub struct Peer {
+    pub peer: String,
+}
+
+impl Peer {
+    pub fn new(peer: &impl Array) -> Self {
+        Self {
+            peer: peer.to_string(),
+        }
+    }
+}
+
+/// Metrics for the shard engine.
+pub struct ShardMetrics {
+    /// Histogram of erasure decoding duration in seconds.
+    pub erasure_decode_duration: Histogram,
+    /// Number of blocks in the reconstructed blocks cache.
+    pub reconstructed_blocks_cache_count: Gauge,
+    /// Number of active reconstruction states.
+    pub reconstruction_states_count: Gauge,
+    /// Number of shards received per peer.
+    pub shards_received: Family<Peer, Counter>,
+    /// Total number of blocks successfully reconstructed.
+    pub blocks_reconstructed_total: Counter,
+    /// Total number of block reconstruction failures.
+    pub reconstruction_failures_total: Counter,
+}
+
+impl ShardMetrics {
+    /// Create and register metrics with the given context.
+    pub fn new(context: &impl MetricsTrait) -> Self {
+        let erasure_decode_duration = Histogram::new(Buckets::LOCAL);
+        let reconstructed_blocks_cache_count = Gauge::default();
+        let reconstruction_states_count = Gauge::default();
+        let shards_received = Family::<Peer, Counter>::default();
+        let blocks_reconstructed_total = Counter::default();
+        let reconstruction_failures_total = Counter::default();
+        context.register(
+            "erasure_decode_duration",
+            "Histogram of erasure decoding duration in seconds",
+            erasure_decode_duration.clone(),
+        );
+        context.register(
+            "reconstructed_blocks_cache_count",
+            "Number of blocks in the reconstructed blocks cache",
+            reconstructed_blocks_cache_count.clone(),
+        );
+        context.register(
+            "reconstruction_states_count",
+            "Number of active reconstruction states",
+            reconstruction_states_count.clone(),
+        );
+        context.register(
+            "shards_received",
+            "Number of shards received per peer",
+            shards_received.clone(),
+        );
+        context.register(
+            "blocks_reconstructed_total",
+            "Total number of blocks successfully reconstructed",
+            blocks_reconstructed_total.clone(),
+        );
+        context.register(
+            "reconstruction_failures_total",
+            "Total number of block reconstruction failures",
+            reconstruction_failures_total.clone(),
+        );
+
+        Self {
+            erasure_decode_duration,
+            reconstructed_blocks_cache_count,
+            reconstruction_states_count,
+            shards_received,
+            blocks_reconstructed_total,
+            reconstruction_failures_total,
+        }
+    }
+}
diff --git a/consensus/src/marshal/coding/shards/mod.rs b/consensus/src/marshal/coding/shards/mod.rs
new file mode 100644
index 000000000..6ec595d3b
--- /dev/null
+++ b/consensus/src/marshal/coding/shards/mod.rs
@@ -0,0 +1,25 @@
+//! Shard engine for erasure-coded block distribution and reconstruction.
+//!
+//! # Overview
+//!
+//! The shards subsystem distributes erasure-coded blocks, validates shard authenticity, and
+//! reconstructs blocks on demand. It ensures every validator contributes bandwidth proportional
+//! to a single shard while allowing any node to recover the entire [`super::types::CodedBlock`]
+//! once enough shards are available.
+//!
+//! # Responsibilities
+//!
+//! - [`Engine`] accepts commands over [`Mailbox`] to broadcast proposer shards, validate and
+//!   reshare received shards, and serve reconstruction requests.
+//! - Maintains an ephemeral cache of reconstructed blocks, evicted when marshal signals
+//!   durability.
+//! - Tracks subscriptions for shard arrival and block reconstruction, notifying waiters when
+//!   data becomes available.
+
+mod mailbox;
+pub use mailbox::{Mailbox, Message};
+
+mod metrics;
+
+mod engine;
+pub use engine::{Config, Engine, Error};
diff --git a/consensus/src/marshal/coding/types.rs b/consensus/src/marshal/coding/types.rs
new file mode 100644
index 000000000..0647756fb
--- /dev/null
+++ b/consensus/src/marshal/coding/types.rs
@@ -0,0 +1,825 @@
+//! Types for erasure coding.
+
+use crate::{
+    types::{coding::Commitment, Height},
+    Block, CertifiableBlock, Heightable,
+};
+use commonware_codec::{EncodeSize, Read, ReadExt, Write};
+use commonware_coding::{Config as CodingConfig, Scheme};
+use commonware_cryptography::{
+    sha256::Digest as Sha256Digest, Committable, Digestible, Hasher, Sha256,
+};
+use commonware_parallel::{Sequential, Strategy};
+use commonware_utils::{Faults, N3f1, NZU16};
+use std::{marker::PhantomData, ops::Deref};
+
+const STRONG_SHARD_TAG: u8 = 0;
+const WEAK_SHARD_TAG: u8 = 1;
+
+/// A shard of erasure coded data, either a strong shard (from the proposer) or a weak shard
+/// (from a non-proposer).
+///
+/// A weak shard cannot be checked for validity on its own.
+#[derive(Clone)]
+pub enum DistributionShard<C: Scheme> {
+    /// A shard that is broadcasted by the proposer, containing extra information for generating
+    /// checking data.
+    Strong(C::StrongShard),
+    /// A shard that is broadcasted by a non-proposer, containing only the shard data.
+    Weak(C::WeakShard),
+}
+
+impl<C: Scheme> Write for DistributionShard<C> {
+    fn write(&self, buf: &mut impl bytes::BufMut) {
+        match self {
+            Self::Strong(shard) => {
+                buf.put_u8(STRONG_SHARD_TAG);
+                shard.write(buf);
+            }
+            Self::Weak(weak_shard) => {
+                buf.put_u8(WEAK_SHARD_TAG);
+                weak_shard.write(buf);
+            }
+        }
+    }
+}
+
+impl<C: Scheme> EncodeSize for DistributionShard<C> {
+    fn encode_size(&self) -> usize {
+        1 + match self {
+            Self::Strong(shard) => shard.encode_size(),
+            Self::Weak(weak_shard) => weak_shard.encode_size(),
+        }
+    }
+}
+
+impl<C: Scheme> Read for DistributionShard<C> {
+    type Cfg = commonware_coding::CodecConfig;
+
+    fn read_cfg(
+        buf: &mut impl bytes::Buf,
+        shard_cfg: &Self::Cfg,
+    ) -> Result<Self, commonware_codec::Error> {
+        match u8::read(buf)? {
+            STRONG_SHARD_TAG => {
+                let shard = C::StrongShard::read_cfg(buf, shard_cfg)?;
+                Ok(Self::Strong(shard))
+            }
+            WEAK_SHARD_TAG => {
+                let weak_shard = C::WeakShard::read_cfg(buf, shard_cfg)?;
+                Ok(Self::Weak(weak_shard))
+            }
+            _ => Err(commonware_codec::Error::Invalid(
+                "DistributionShard",
+                "invalid tag",
+            )),
+        }
+    }
+}
+
+impl<C: Scheme> PartialEq for DistributionShard<C> {
+    fn eq(&self, other: &Self) -> bool {
+        match (self, other) {
+            (Self::Strong(a), Self::Strong(b)) => a == b,
+            (Self::Weak(a), Self::Weak(b)) => a == b,
+            _ => false,
+        }
+    }
+}
+
+impl<C: Scheme> Eq for DistributionShard<C> {}
+
+#[cfg(feature = "arbitrary")]
+impl<C: Scheme> arbitrary::Arbitrary<'_> for DistributionShard<C>
+where
+    C::StrongShard: for<'a> arbitrary::Arbitrary<'a>,
+    C::WeakShard: for<'a> arbitrary::Arbitrary<'a>,
+{
+    fn arbitrary(u: &mut arbitrary::Unstructured<'_>) -> arbitrary::Result<Self> {
+        if u.arbitrary::<bool>()? {
+            Ok(Self::Strong(u.arbitrary()?))
+        } else {
+            Ok(Self::Weak(u.arbitrary()?))
+        }
+    }
+}
+
+/// A broadcastable shard of erasure coded data, including the coding commitment and
+/// the configuration used to code the data.
+pub struct Shard<C: Scheme, H: Hasher> {
+    /// The coding commitment
+    pub(crate) commitment: Commitment,
+    /// The index of this shard within the commitment.
+    pub(crate) index: u16,
+    /// An individual shard within the commitment.
+    pub(crate) inner: DistributionShard<C>,
+    /// Phantom data for the hasher.
+    _hasher: PhantomData<H>,
+}
+
+impl<C: Scheme, H: Hasher> Shard<C, H> {
+    pub const fn new(commitment: Commitment, index: u16, inner: DistributionShard<C>) -> Self {
+        Self {
+            commitment,
+            index,
+            inner,
+            _hasher: PhantomData,
+        }
+    }
+
+    /// Returns the index of this shard within the commitment.
+    pub const fn index(&self) -> u16 {
+        self.index
+    }
+
+    /// Returns the [`Commitment`] for this shard.
+    pub const fn commitment(&self) -> Commitment {
+        self.commitment
+    }
+
+    /// Returns true if the inner shard is strong.
+    pub const fn is_strong(&self) -> bool {
+        matches!(self.inner, DistributionShard::Strong(_))
+    }
+
+    /// Returns true if the inner shard is weak.
+    pub const fn is_weak(&self) -> bool {
+        matches!(self.inner, DistributionShard::Weak(_))
+    }
+
+    /// Takes the inner [`DistributionShard`].
+    pub fn into_inner(self) -> DistributionShard<C> {
+        self.inner
+    }
+
+    /// Verifies the shard and returns the weak shard for broadcasting if valid.
+    ///
+    /// Returns `Some(weak_shard)` if the shard is valid and can be rebroadcast,
+    /// or `None` if the shard is invalid or already weak.
+    pub fn verify_into_weak(self) -> Option<Self> {
+        let DistributionShard::Strong(shard) = self.inner else {
+            return None;
+        };
+
+        let weak_shard = C::weaken(
+            &self.commitment.config(),
+            &self.commitment.root(),
+            self.index,
+            shard,
+        )
+        .ok()
+        .map(|(_, _, weak_shard)| weak_shard)?;
+
+        Some(Self::new(
+            self.commitment,
+            self.index,
+            DistributionShard::Weak(weak_shard),
+        ))
+    }
+}
+
+impl<C: Scheme, H: Hasher> Clone for Shard<C, H> {
+    fn clone(&self) -> Self {
+        Self {
+            commitment: self.commitment,
+            index: self.index,
+            inner: self.inner.clone(),
+            _hasher: PhantomData,
+        }
+    }
+}
+
+impl<C: Scheme, H: Hasher> Deref for Shard<C, H> {
+    type Target = DistributionShard<C>;
+
+    fn deref(&self) -> &Self::Target {
+        &self.inner
+    }
+}
+
+impl<C: Scheme, H: Hasher> Committable for Shard<C, H> {
+    type Commitment = Commitment;
+
+    fn commitment(&self) -> Self::Commitment {
+        self.commitment
+    }
+}
+
+impl<C: Scheme, H: Hasher> Write for Shard<C, H> {
+    fn write(&self, buf: &mut impl bytes::BufMut) {
+        self.commitment.write(buf);
+        self.index.write(buf);
+        self.inner.write(buf);
+    }
+}
+
+impl<C: Scheme, H: Hasher> EncodeSize for Shard<C, H> {
+    fn encode_size(&self) -> usize {
+        self.commitment.encode_size() + self.index.encode_size() + self.inner.encode_size()
+    }
+}
+
+impl<C: Scheme, H: Hasher> Read for Shard<C, H> {
+    type Cfg = commonware_coding::CodecConfig;
+
+    fn read_cfg(
+        buf: &mut impl bytes::Buf,
+        cfg: &Self::Cfg,
+    ) -> Result<Self, commonware_codec::Error> {
+        let commitment = Commitment::read(buf)?;
+        let index = u16::read(buf)?;
+        let inner = DistributionShard::read_cfg(buf, cfg)?;
+
+        Ok(Self {
+            commitment,
+            index,
+            inner,
+            _hasher: PhantomData,
+        })
+    }
+}
+
+impl<C: Scheme, H: Hasher> PartialEq for Shard<C, H> {
+    fn eq(&self, other: &Self) -> bool {
+        self.commitment == other.commitment
+            && self.index == other.index
+            && self.inner == other.inner
+    }
+}
+
+impl<C: Scheme, H: Hasher> Eq for Shard<C, H> {}
+
+#[cfg(feature = "arbitrary")]
+impl<C: Scheme, H: Hasher> arbitrary::Arbitrary<'_> for Shard<C, H>
+where
+    DistributionShard<C>: for<'a> arbitrary::Arbitrary<'a>,
+{
+    fn arbitrary(u: &mut arbitrary::Unstructured<'_>) -> arbitrary::Result<Self> {
+        Ok(Self {
+            commitment: u.arbitrary()?,
+            index: u.arbitrary()?,
+            inner: u.arbitrary()?,
+            _hasher: PhantomData,
+        })
+    }
+}
+
+/// An envelope type for an erasure coded [`Block`].
+#[derive(Debug)]
+pub struct CodedBlock<B: Block, C: Scheme> {
+    /// The inner block type.
+    inner: B,
+    /// The erasure coding configuration.
+    config: CodingConfig,
+    /// The erasure coding commitment.
+    commitment: C::Commitment,
+    /// The coded shards.
+    ///
+    /// These shards are optional to enable lazy construction.
+    shards: Option<Vec<C::StrongShard>>,
+}
+
+impl<B: Block, C: Scheme> CodedBlock<B, C> {
+    /// Erasure codes the block.
+    fn encode(
+        inner: &B,
+        config: CodingConfig,
+        strategy: &impl Strategy,
+    ) -> (C::Commitment, Vec<C::StrongShard>) {
+        let mut buf = Vec::with_capacity(config.encode_size() + inner.encode_size());
+        inner.write(&mut buf);
+        config.write(&mut buf);
+
+        C::encode(&config, buf.as_slice(), strategy).expect("must encode block successfully")
+    }
+
+    /// Create a new [`CodedBlock`] from a [`Block`] and a configuration.
+    pub fn new(inner: B, config: CodingConfig, strategy: &impl Strategy) -> Self {
+        let (commitment, shards) = Self::encode(&inner, config, strategy);
+        Self {
+            inner,
+            config,
+            commitment,
+            shards: Some(shards),
+        }
+    }
+
+    /// Create a new [`CodedBlock`] from a [`Block`] and trusted [`Commitment`].
+    pub fn new_trusted(inner: B, commitment: Commitment) -> Self {
+        Self {
+            inner,
+            config: commitment.config(),
+            commitment: commitment.root(),
+            shards: None,
+        }
+    }
+
+    /// Returns the coding configuration for the data committed.
+    pub const fn config(&self) -> CodingConfig {
+        self.config
+    }
+
+    /// Returns a reference to the shards in this coded block.
+    ///
+    /// If the shards have not yet been generated, they will be created via [`Scheme::encode`].
+    pub fn shards(&mut self, strategy: &impl Strategy) -> &[C::StrongShard] {
+        match self.shards {
+            Some(ref shards) => shards,
+            None => {
+                let (commitment, shards) = Self::encode(&self.inner, self.config, strategy);
+
+                assert_eq!(
+                    commitment, self.commitment,
+                    "coded block constructed with trusted commitment does not match commitment"
+                );
+
+                self.shards = Some(shards);
+                self.shards.as_ref().unwrap()
+            }
+        }
+    }
+
+    /// Returns a [`Shard`] at the given index, if the index is valid.
+    pub fn shard<H: Hasher>(&self, index: u16) -> Option<Shard<C, H>>
+    where
+        B: CertifiableBlock,
+    {
+        Some(Shard::new(
+            self.commitment(),
+            index,
+            DistributionShard::Strong(self.shards.as_ref()?.get(usize::from(index))?.clone()),
+        ))
+    }
+
+    /// Returns a reference to the inner [`Block`].
+    pub const fn inner(&self) -> &B {
+        &self.inner
+    }
+
+    /// Takes the inner [`Block`].
+    pub fn into_inner(self) -> B {
+        self.inner
+    }
+}
+
+impl<B: CertifiableBlock, C: Scheme> From<CodedBlock<B, C>> for StoredCodedBlock<B, C> {
+    fn from(block: CodedBlock<B, C>) -> Self {
+        Self::new(block)
+    }
+}
+
+impl<B: Block + Clone, C: Scheme> Clone for CodedBlock<B, C> {
+    fn clone(&self) -> Self {
+        Self {
+            inner: self.inner.clone(),
+            config: self.config,
+            commitment: self.commitment,
+            shards: self.shards.clone(),
+        }
+    }
+}
+
+impl<B: CertifiableBlock, C: Scheme> Committable for CodedBlock<B, C> {
+    type Commitment = Commitment;
+
+    fn commitment(&self) -> Self::Commitment {
+        Commitment::from((
+            self.digest(),
+            self.commitment,
+            hash_context(&self.inner.context()),
+            self.config,
+        ))
+    }
+}
+
+impl<B: Block, C: Scheme> Digestible for CodedBlock<B, C> {
+    type Digest = B::Digest;
+
+    fn digest(&self) -> Self::Digest {
+        self.inner.digest()
+    }
+}
+
+impl<B: Block, C: Scheme> Write for CodedBlock<B, C> {
+    fn write(&self, buf: &mut impl bytes::BufMut) {
+        self.inner.write(buf);
+        self.config.write(buf);
+    }
+}
+
+impl<B: Block, C: Scheme> EncodeSize for CodedBlock<B, C> {
+    fn encode_size(&self) -> usize {
+        self.inner.encode_size() + self.config.encode_size()
+    }
+}
+
+impl<B: Block, C: Scheme> Read for CodedBlock<B, C> {
+    type Cfg = <B as Read>::Cfg;
+
+    fn read_cfg(
+        buf: &mut impl bytes::Buf,
+        block_cfg: &Self::Cfg,
+    ) -> Result<Self, commonware_codec::Error> {
+        let inner = B::read_cfg(buf, block_cfg)?;
+        let config = CodingConfig::read(buf)?;
+
+        let mut buf = Vec::with_capacity(inner.encode_size() + config.encode_size());
+        inner.write(&mut buf);
+        config.write(&mut buf);
+        let (commitment, shards) =
+            C::encode(&config, buf.as_slice(), &Sequential).map_err(|_| {
+                commonware_codec::Error::Invalid("CodedBlock", "Failed to re-commit to block")
+            })?;
+
+        Ok(Self {
+            inner,
+            config,
+            commitment,
+            shards: Some(shards),
+        })
+    }
+}
+
+impl<B: CertifiableBlock, C: Scheme> Block for CodedBlock<B, C> {
+    fn parent(&self) -> Self::Digest {
+        self.inner.parent()
+    }
+}
+
+impl<B: Block, C: Scheme> Heightable for CodedBlock<B, C> {
+    fn height(&self) -> Height {
+        self.inner.height()
+    }
+}
+
+impl<B: CertifiableBlock, C: Scheme> CertifiableBlock for CodedBlock<B, C> {
+    type Context = B::Context;
+
+    fn context(&self) -> Self::Context {
+        self.inner.context()
+    }
+}
+
+/// Hashes a consensus context for inclusion in a [`Commitment`].
+pub fn hash_context<C: EncodeSize + Write>(context: &C) -> Sha256Digest {
+    let mut buf = Vec::with_capacity(context.encode_size());
+    context.write(&mut buf);
+    Sha256::hash(&buf)
+}
+
+impl<B: Block + PartialEq, C: Scheme> PartialEq for CodedBlock<B, C> {
+    fn eq(&self, other: &Self) -> bool {
+        self.inner == other.inner
+            && self.config == other.config
+            && self.commitment == other.commitment
+            && self.shards == other.shards
+    }
+}
+
+impl<B: Block + Eq, C: Scheme> Eq for CodedBlock<B, C> {}
+
+/// A [`CodedBlock`] paired with its [`Commitment`] for efficient storage and retrieval.
+///
+/// This type should be preferred for storing verified [`CodedBlock`]s on disk - it
+/// should never be sent over the network. Use [`CodedBlock`] for network transmission,
+/// as it re-encodes the block with [`Scheme::encode`] on deserialization to ensure integrity.
+///
+/// When reading from storage, we don't need to re-encode the block to compute
+/// the commitment - we stored it alongside the block when we first verified it.
+/// This avoids expensive erasure coding operations on the read path.
+///
+/// The [`Read`] implementation performs a light verification (block digest check)
+/// to detect storage corruption, but does not re-encode the block.
+pub struct StoredCodedBlock<B: Block, C: Scheme> {
+    inner: B,
+    commitment: Commitment,
+    _scheme: PhantomData<C>,
+}
+
+impl<B: CertifiableBlock, C: Scheme> StoredCodedBlock<B, C> {
+    /// Create a [`StoredCodedBlock`] from a verified [`CodedBlock`].
+    ///
+    /// The caller must ensure the [`CodedBlock`] has been properly verified
+    /// (i.e., its commitment was computed or validated against a trusted source).
+    pub fn new(block: CodedBlock<B, C>) -> Self {
+        Self {
+            commitment: block.commitment(),
+            inner: block.inner,
+            _scheme: PhantomData,
+        }
+    }
+
+    /// Convert back to a [`CodedBlock`] using the trusted commitment.
+    ///
+    /// The returned [`CodedBlock`] will have `shards: None`, meaning shards
+    /// will be lazily generated if needed via [`CodedBlock::shards`].
+    pub fn into_coded_block(self) -> CodedBlock<B, C> {
+        CodedBlock::new_trusted(self.inner, self.commitment)
+    }
+
+    /// Returns a reference to the inner block.
+    pub const fn inner(&self) -> &B {
+        &self.inner
+    }
+}
+
+/// Converts a [`StoredCodedBlock`] back to a [`CodedBlock`].
+impl<B: Block, C: Scheme> From<StoredCodedBlock<B, C>> for CodedBlock<B, C> {
+    fn from(stored: StoredCodedBlock<B, C>) -> Self {
+        Self::new_trusted(stored.inner, stored.commitment)
+    }
+}
+
+impl<B: Block + Clone, C: Scheme> Clone for StoredCodedBlock<B, C> {
+    fn clone(&self) -> Self {
+        Self {
+            commitment: self.commitment,
+            inner: self.inner.clone(),
+            _scheme: PhantomData,
+        }
+    }
+}
+
+impl<B: Block, C: Scheme> Committable for StoredCodedBlock<B, C> {
+    type Commitment = Commitment;
+
+    fn commitment(&self) -> Self::Commitment {
+        self.commitment
+    }
+}
+
+impl<B: Block, C: Scheme> Digestible for StoredCodedBlock<B, C> {
+    type Digest = B::Digest;
+
+    fn digest(&self) -> Self::Digest {
+        self.inner.digest()
+    }
+}
+
+impl<B: Block, C: Scheme> Write for StoredCodedBlock<B, C> {
+    fn write(&self, buf: &mut impl bytes::BufMut) {
+        self.inner.write(buf);
+        self.commitment.write(buf);
+    }
+}
+
+impl<B: Block, C: Scheme> EncodeSize for StoredCodedBlock<B, C> {
+    fn encode_size(&self) -> usize {
+        self.inner.encode_size() + self.commitment.encode_size()
+    }
+}
+
+impl<B: Block, C: Scheme> Read for StoredCodedBlock<B, C> {
+    // Note: No concurrency parameter needed since we don't re-encode!
+    type Cfg = B::Cfg;
+
+    fn read_cfg(
+        buf: &mut impl bytes::Buf,
+        block_cfg: &Self::Cfg,
+    ) -> Result<Self, commonware_codec::Error> {
+        let inner = B::read_cfg(buf, block_cfg)?;
+        let commitment = Commitment::read(buf)?;
+
+        // Light verification to detect storage corruption
+        if inner.digest() != commitment.block::<B::Digest>() {
+            return Err(commonware_codec::Error::Invalid(
+                "StoredCodedBlock",
+                "storage corruption: block digest mismatch",
+            ));
+        }
+
+        Ok(Self {
+            commitment,
+            inner,
+            _scheme: PhantomData,
+        })
+    }
+}
+
+impl<B: Block, C: Scheme> Block for StoredCodedBlock<B, C> {
+    fn parent(&self) -> Self::Digest {
+        self.inner.parent()
+    }
+}
+
+impl<B: CertifiableBlock, C: Scheme> CertifiableBlock for StoredCodedBlock<B, C> {
+    type Context = B::Context;
+
+    fn context(&self) -> Self::Context {
+        self.inner.context()
+    }
+}
+
+impl<B: Block, C: Scheme> Heightable for StoredCodedBlock<B, C> {
+    fn height(&self) -> Height {
+        self.inner.height()
+    }
+}
+
+impl<B: Block + PartialEq, C: Scheme> PartialEq for StoredCodedBlock<B, C> {
+    fn eq(&self, other: &Self) -> bool {
+        self.commitment == other.commitment && self.inner == other.inner
+    }
+}
+
+impl<B: Block + Eq, C: Scheme> Eq for StoredCodedBlock<B, C> {}
+
+/// Compute the [`CodingConfig`] for a given number of participants.
+///
+/// Panics if `n_participants < 4`.
+pub fn coding_config_for_participants(n_participants: u16) -> CodingConfig {
+    let max_faults = N3f1::max_faults(n_participants);
+    assert!(
+        max_faults >= 1,
+        "Need at least 4 participants to maintain fault tolerance"
+    );
+    let max_faults = u16::try_from(max_faults).expect("max_faults must fit in u16");
+    let minimum_shards = NZU16!(max_faults + 1);
+    CodingConfig {
+        minimum_shards,
+        extra_shards: NZU16!(n_participants - minimum_shards.get()),
+    }
+}
+
+#[cfg(test)]
+mod test {
+    use super::*;
+    use crate::{marshal::mocks::block::Block as MockBlock, Block as _};
+    use commonware_codec::{Decode, Encode};
+    use commonware_coding::{CodecConfig, ReedSolomon};
+    use commonware_cryptography::{sha256::Digest as Sha256Digest, Digest, Sha256};
+
+    const MAX_SHARD_SIZE: CodecConfig = CodecConfig {
+        maximum_shard_size: 1024 * 1024, // 1 MiB
+    };
+
+    type H = Sha256;
+    type RS = ReedSolomon<H>;
+    type RShard = Shard<RS, H>;
+    type Block = MockBlock<<H as Hasher>::Digest, ()>;
+
+    #[test]
+    fn test_distribution_shard_codec_roundtrip() {
+        const MOCK_BLOCK_DATA: &[u8] = b"commonware shape rotator club";
+        const CONFIG: CodingConfig = CodingConfig {
+            minimum_shards: NZU16!(1),
+            extra_shards: NZU16!(2),
+        };
+
+        let (_, shards) = RS::encode(&CONFIG, MOCK_BLOCK_DATA, &Sequential).unwrap();
+        let raw_shard = shards.first().cloned().unwrap();
+
+        let strong_shard = DistributionShard::<RS>::Strong(raw_shard.clone());
+        let encoded = strong_shard.encode();
+        let decoded =
+            DistributionShard::<RS>::decode_cfg(&mut encoded.as_ref(), &MAX_SHARD_SIZE).unwrap();
+        assert!(strong_shard == decoded);
+
+        let weak_shard = DistributionShard::<RS>::Weak(raw_shard);
+        let encoded = weak_shard.encode();
+        let decoded =
+            DistributionShard::<RS>::decode_cfg(&mut encoded.as_ref(), &MAX_SHARD_SIZE).unwrap();
+        assert!(weak_shard == decoded);
+    }
+
+    #[test]
+    fn test_distribution_shard_decode_truncated_returns_error() {
+        let decode = std::panic::catch_unwind(std::panic::AssertUnwindSafe(|| {
+            let mut buf = &[][..];
+            DistributionShard::<RS>::decode_cfg(&mut buf, &MAX_SHARD_SIZE)
+        }));
+        assert!(decode.is_ok(), "decode must not panic on truncated input");
+        assert!(decode.unwrap().is_err());
+    }
+
+    #[test]
+    fn test_coding_config_for_participants_valid_for_minimum_set() {
+        let config = coding_config_for_participants(4);
+        assert_eq!(config.minimum_shards.get(), 2);
+        assert_eq!(config.extra_shards.get(), 2);
+    }
+
+    #[test]
+    #[should_panic(expected = "Need at least 4 participants to maintain fault tolerance")]
+    fn test_coding_config_for_participants_panics_for_small_sets() {
+        let _ = coding_config_for_participants(3);
+    }
+
+    #[test]
+    fn test_shard_codec_roundtrip() {
+        const MOCK_BLOCK_DATA: &[u8] = b"deadc0de";
+        const CONFIG: CodingConfig = CodingConfig {
+            minimum_shards: NZU16!(1),
+            extra_shards: NZU16!(2),
+        };
+
+        let (commitment, shards) = RS::encode(&CONFIG, MOCK_BLOCK_DATA, &Sequential).unwrap();
+        let raw_shard = shards.first().cloned().unwrap();
+
+        let commitment =
+            Commitment::from((Sha256Digest::EMPTY, commitment, Sha256Digest::EMPTY, CONFIG));
+        let shard = RShard::new(commitment, 0, DistributionShard::Strong(raw_shard.clone()));
+        let encoded = shard.encode();
+        let decoded = RShard::decode_cfg(&mut encoded.as_ref(), &MAX_SHARD_SIZE).unwrap();
+        assert!(shard == decoded);
+
+        let shard = RShard::new(commitment, 0, DistributionShard::Weak(raw_shard));
+        let encoded = shard.encode();
+        let decoded = RShard::decode_cfg(&mut encoded.as_ref(), &MAX_SHARD_SIZE).unwrap();
+        assert!(shard == decoded);
+    }
+
+    #[test]
+    fn test_coded_block_codec_roundtrip() {
+        const CONFIG: CodingConfig = CodingConfig {
+            minimum_shards: NZU16!(1),
+            extra_shards: NZU16!(2),
+        };
+
+        let block = Block::new::<Sha256>((), Sha256::hash(b"parent"), Height::new(42), 1_234_567);
+        let coded_block = CodedBlock::<Block, RS>::new(block, CONFIG, &Sequential);
+
+        let encoded = coded_block.encode();
+        let decoded = CodedBlock::<Block, RS>::decode_cfg(encoded, &()).unwrap();
+
+        assert!(coded_block == decoded);
+    }
+
+    #[test]
+    fn test_stored_coded_block_codec_roundtrip() {
+        const CONFIG: CodingConfig = CodingConfig {
+            minimum_shards: NZU16!(1),
+            extra_shards: NZU16!(2),
+        };
+
+        let block = Block::new::<Sha256>((), Sha256::hash(b"parent"), Height::new(42), 1_234_567);
+        let coded_block = CodedBlock::<Block, RS>::new(block, CONFIG, &Sequential);
+        let stored = StoredCodedBlock::<Block, RS>::new(coded_block.clone());
+
+        assert_eq!(stored.commitment(), coded_block.commitment());
+        assert_eq!(stored.digest(), coded_block.digest());
+        assert_eq!(stored.height(), coded_block.height());
+        assert_eq!(stored.parent(), coded_block.parent());
+
+        let encoded = stored.encode();
+        let decoded = StoredCodedBlock::<Block, RS>::decode_cfg(encoded, &()).unwrap();
+
+        assert!(stored == decoded);
+        assert_eq!(decoded.commitment(), coded_block.commitment());
+        assert_eq!(decoded.digest(), coded_block.digest());
+    }
+
+    #[test]
+    fn test_stored_coded_block_into_coded_block() {
+        const CONFIG: CodingConfig = CodingConfig {
+            minimum_shards: NZU16!(1),
+            extra_shards: NZU16!(2),
+        };
+
+        let block = Block::new::<Sha256>((), Sha256::hash(b"parent"), Height::new(42), 1_234_567);
+        let coded_block = CodedBlock::<Block, RS>::new(block, CONFIG, &Sequential);
+        let original_commitment = coded_block.commitment();
+        let original_digest = coded_block.digest();
+
+        let stored = StoredCodedBlock::<Block, RS>::new(coded_block);
+        let encoded = stored.encode();
+        let decoded = StoredCodedBlock::<Block, RS>::decode_cfg(encoded, &()).unwrap();
+        let restored = decoded.into_coded_block();
+
+        assert_eq!(restored.commitment(), original_commitment);
+        assert_eq!(restored.digest(), original_digest);
+    }
+
+    #[test]
+    fn test_stored_coded_block_corruption_detection() {
+        const CONFIG: CodingConfig = CodingConfig {
+            minimum_shards: NZU16!(1),
+            extra_shards: NZU16!(2),
+        };
+
+        let block = Block::new::<Sha256>((), Sha256::hash(b"parent"), Height::new(42), 1_234_567);
+        let coded_block = CodedBlock::<Block, RS>::new(block, CONFIG, &Sequential);
+        let stored = StoredCodedBlock::<Block, RS>::new(coded_block);
+
+        let mut encoded = stored.encode().to_vec();
+
+        // Corrupt the commitment (located after the block bytes)
+        let block_size = stored.inner().encode_size();
+        encoded[block_size] ^= 0xFF;
+
+        // Decoding should fail due to digest mismatch
+        let result = StoredCodedBlock::<Block, RS>::decode_cfg(&mut encoded.as_slice(), &());
+        assert!(result.is_err());
+    }
+
+    #[cfg(feature = "arbitrary")]
+    mod conformance {
+        use super::*;
+        use commonware_codec::conformance::CodecConformance;
+
+        commonware_conformance::conformance_tests! {
+            CodecConformance<DistributionShard<ReedSolomon<Sha256>>>,
+            CodecConformance<Shard<ReedSolomon<Sha256>, Sha256>>,
+        }
+    }
+}
diff --git a/consensus/src/marshal/coding/variant.rs b/consensus/src/marshal/coding/variant.rs
new file mode 100644
index 000000000..e65e93ab3
--- /dev/null
+++ b/consensus/src/marshal/coding/variant.rs
@@ -0,0 +1,85 @@
+use crate::{
+    marshal::{
+        coding::{
+            shards,
+            types::{CodedBlock, StoredCodedBlock},
+        },
+        core::{Buffer, Variant},
+    },
+    types::{coding::Commitment, Round},
+    CertifiableBlock,
+};
+use commonware_coding::Scheme as CodingScheme;
+use commonware_cryptography::{Committable, Digestible, PublicKey};
+use commonware_utils::channel::oneshot;
+use std::sync::Arc;
+
+/// The coding variant of Marshal, which uses erasure coding for block dissemination.
+///
+/// This variant distributes blocks as erasure-coded shards, allowing reconstruction
+/// from a subset of shards. This reduces bandwidth requirements for block propagation.
+#[derive(Default, Clone, Copy)]
+pub struct Coding<B: CertifiableBlock, C: CodingScheme, P: PublicKey>(
+    std::marker::PhantomData<(B, C, P)>,
+);
+
+impl<B: CertifiableBlock, C: CodingScheme, P: PublicKey> Variant for Coding<B, C, P> {
+    type ApplicationBlock = B;
+    type Block = CodedBlock<B, C>;
+    type StoredBlock = StoredCodedBlock<B, C>;
+    type Commitment = Commitment;
+
+    fn commitment(block: &Self::Block) -> Self::Commitment {
+        block.commitment()
+    }
+
+    fn commitment_to_inner(commitment: Self::Commitment) -> <Self::Block as Digestible>::Digest {
+        commitment.block()
+    }
+
+    fn into_inner(block: Self::Block) -> Self::ApplicationBlock {
+        block.into_inner()
+    }
+}
+
+impl<B, C, P> Buffer<Coding<B, C, P>> for shards::Mailbox<B, C, P>
+where
+    B: CertifiableBlock,
+    C: CodingScheme,
+    P: PublicKey,
+{
+    type CachedBlock = Arc<CodedBlock<B, C>>;
+
+    async fn find_by_digest(
+        &self,
+        digest: <CodedBlock<B, C> as Digestible>::Digest,
+    ) -> Option<Self::CachedBlock> {
+        self.get_by_digest(digest).await
+    }
+
+    async fn find_by_commitment(&self, commitment: Commitment) -> Option<Self::CachedBlock> {
+        self.get(commitment).await
+    }
+
+    async fn subscribe_by_digest(
+        &self,
+        digest: <CodedBlock<B, C> as Digestible>::Digest,
+    ) -> oneshot::Receiver<Self::CachedBlock> {
+        self.subscribe_by_digest(digest).await
+    }
+
+    async fn subscribe_by_commitment(
+        &self,
+        commitment: Commitment,
+    ) -> oneshot::Receiver<Self::CachedBlock> {
+        self.subscribe(commitment).await
+    }
+
+    async fn finalized(&self, commitment: Commitment) {
+        self.prune(commitment).await;
+    }
+
+    async fn proposed(&self, round: Round, block: CodedBlock<B, C>) {
+        self.proposed(round, block).await;
+    }
+}
