<!DOCTYPE html>
<html lang="en">

<head>
    <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
    <meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
    <link rel="preload" href="/style.css" as="style">
    <link rel="preload" href="/shared.js" as="script">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">

    <title>commonware > Deliver Us in Pieces</title>
    <meta name="description" content="Validator clusters already have the bandwidth. We are just not using it. In the standard proposal path of consensus::simplex, one node pushes the whole block while everyone else waits, so throughput is bottlenecked. What if we distributed the load?">
    <meta name="author" content="Ben Clabby">
    <meta name="keywords" content="commonware, open source, common goods, software, internet, ownership, trust, blockchain, decentralization, crypto">

    <link rel="canonical" href="https://commonware.xyz/blogs/coding" />

    <meta property="og:url" content="https://commonware.xyz/blogs/coding" />
    <meta property="og:type" content="article" />
    <meta property="og:site_name" content="commonware" />
    <meta property="og:image" content="https://commonware.xyz/imgs/coding_chain.png" />
    <meta property="og:title" content="Deliver Us in Pieces" />
    <meta property="og:description" content="Validator clusters already have the bandwidth. We are just not using it. In the standard proposal path of consensus::simplex, one node pushes the whole block while everyone else waits, so throughput is bottlenecked. What if we distributed the load?" />
    <meta property="article:author" content="https://x.com/vex_0x" />
    <meta property="article:published_time" content="2026-02-20T00:00:00Z" />
    <meta property="article:modified_time" content="2026-02-20T00:00:00Z" />

    <meta name="twitter:card" content="summary_large_image" />
    <meta property="twitter:domain" content="commonware.xyz" />
    <meta property="twitter:url" content="https://commonware.xyz/blogs/coding" />
    <meta property="twitter:title" content="Deliver Us in Pieces" />
    <meta property="twitter:description" content="Validator clusters already have the bandwidth. We are just not using it. In the standard proposal path of consensus::simplex, one node pushes the whole block while everyone else waits, so throughput is bottlenecked. What if we distributed the load?" />
    <meta property="twitter:image" content="https://commonware.xyz/imgs/coding_chain.png" />
    <meta property="twitter:site" content="@commonwarexyz" />
    <meta property="twitter:creator" content="@vex_0x" />

    <link rel="stylesheet" type="text/css" href="/style.css">
</head>

<body>
    <div id="logo-placeholder">
        <div class="logo-line">
            <span class="edge-logo-symbol">+</span>
            <span class="horizontal-logo-symbol">~</span>
            <span class="horizontal-logo-symbol"> </span>
            <span class="horizontal-logo-symbol">-</span>
            <span class="horizontal-logo-symbol">+</span>
            <span class="horizontal-logo-symbol">-</span>
            <span class="horizontal-logo-symbol">+</span>
            <span class="horizontal-logo-symbol"> </span>
            <span class="horizontal-logo-symbol">-</span>
            <span class="horizontal-logo-symbol">+</span>
            <span class="horizontal-logo-symbol">-</span>
            <span class="horizontal-logo-symbol">~</span>
            <span class="horizontal-logo-symbol">~</span>
            <span class="edge-logo-symbol">*</span>
        </div>
        <div class="logo-line">
            <span class="vertical-logo-symbol">|</span>
            <span class="logo-text"> commonware </span>
            <span class="vertical-logo-symbol"> </span>
        </div>
        <div class="logo-line">
            <span class="edge-logo-symbol">*</span>
            <span class="horizontal-logo-symbol">~</span>
            <span class="horizontal-logo-symbol">+</span>
            <span class="horizontal-logo-symbol">+</span>
            <span class="horizontal-logo-symbol">-</span>
            <span class="horizontal-logo-symbol"> </span>
            <span class="horizontal-logo-symbol">~</span>
            <span class="horizontal-logo-symbol">-</span>
            <span class="horizontal-logo-symbol">+</span>
            <span class="horizontal-logo-symbol"> </span>
            <span class="horizontal-logo-symbol">-</span>
            <span class="horizontal-logo-symbol">*</span>
            <span class="horizontal-logo-symbol">-</span>
            <span class="edge-logo-symbol">+</span>
        </div>
    </div>
    <div class="content">
        <h1>Deliver Us in Pieces</h1>
        <div class="meta">
            <div class="author">By <a href="https://x.com/vex_0x">Ben Clabby</a></div>
            <div class="date">February 20, 2026</div>
        </div>

        <p>Validator clusters already have the bandwidth. We are just not using it. In the standard proposal path of <code><a href="https://docs.rs/commonware-consensus/latest/commonware_consensus/simplex/index.html">consensus::simplex</a></code>, one node pushes the whole block while everyone else waits, so throughput is bottlenecked. What if we distributed the load?</p>

        <p>Today, we are introducing a new path for <code><a href="https://docs.rs/commonware-consensus/latest/commonware_consensus/simplex/index.html">consensus::simplex</a></code>: erasure-coded broadcast integrated directly into marshal through <code><a href="https://github.com/commonwarexyz/monorepo/blob/main/consensus/src/marshal/coding/mod.rs">marshal::coding</a></code>. A leader commits to an erasure-encoded block, validators relay verified shards, and Simplex advances on the same commitment.</p>

        <h2>Certification: A Second Decision Point</h2>

        <p>The foundation of this integration is a new phase in a view's progression to finalization within simplex. "Certification" offers a local, deterministic method to nullify a view after voting on partial information. For a more formal treatment of this idea, refer to <a href="https://eprint.iacr.org/2023/1916.pdf"><i>Sing a song of Simplex</i></a> by Victor Shoup.</p>

        <p>A notarization proves that a quorum observed the same proposal. It does not force replicas to keep going down that path. After notarization forms, the network can still change course if new information shows up locally.</p>

        <p>If <code>certify</code> returns true, the validator advances to the next view and then votes to <code>finalize</code> the certified view. If <code>certify</code> returns false, the validator votes to <code>nullify</code> and refuses to build on that payload. In other words: notarization says “we saw it,” certification decides “we will build on it.”</p>

        <div class="image-container">
            <img src="/imgs/certify_sequence.png" alt="View Sequence" />
            <div class="image-caption">Figure 1: Simplex view lifecycle with certification.</div>
        </div>

        <h2>Why This Matters for Coding</h2>

        <p>In the coding path, this boundary can be used to improve view latency. The proposer first erasure-encodes their block and commits to all shards to form a consensus payload (the <b>commitment</b>). Then, they disperse both a shard as well as an inclusion proof to the validators (a method described in <a href="https://www.usenix.org/system/files/nsdi22-paper-yang_lei.pdf"><i>Dispersed Ledger</i></a> by Lei Yang, Seo Jin Park, Mohammad Alizadeh, Sreeram Kannan, and David Tse). Upon receipt, validators verify proposal invariants and shard validity against the erasure-coding commitment, then relay their shard and vote to notarize without waiting for full block reconstruction.</p>

        <p>This is where we differ from other three-round protocols that employ erasure-encoded broadcast such as <a href="https://arxiv.org/abs/2502.20692">MonadBFT</a> and <a href="https://drive.google.com/file/d/1Rlr3PdHsBmPahOInP6-Pl0bMzdayltdV/view">Alpenglow</a>: those designs wait for full block recovery before voting. We move that wait to certification, after notarization, resulting in a lower view latency with a hard safety gate before finalization.</p>

        <p>After notarization, <code>certify</code> is where we resolve new information: we reconstruct the block, check ancestry and epoch invariants, and run full application verification. If reconstruction fails or the reconstructed blob is invalid, certification fails and the view is nullified cleanly - no bad blocks end up in the finalized chain.</p>

        <div class="image-container">
            <img src="/imgs/coding_commitment_construction.png" alt="Erasure coding commitment construction" />
            <div class="image-caption">Figure 2: Coding Commitment Construction</div>
        </div>

        <div class="image-container">
            <img src="/imgs/coding_dissemination.png" alt="Erasure Coded Block dissemination" />
            <div class="image-caption">Figure 3: Block Dissemination Lifecycle.</div>
        </div>

        <div class="image-container">
            <img src="/imgs/coding_chain.png" alt="Erasure Coded Block dissemination and chain diagram" />
            <div class="image-caption">Figure 4: Erasure Coded Chain Structure.</div>
        </div>

        <h2>Deferred Verification, Even Without Coding</h2>

        <p>There is a second win: <code>certify</code> gives us deferred verification as a first-class pattern in the standard path. We can start verification early, hide it behind vote propagation latency, and require the result at certification time. This is already used in the standard marshal path (see <code><a href="https://github.com/commonwarexyz/monorepo/blob/main/consensus/src/marshal/standard/deferred.rs">standard::Deferred</a></code>), without erasure coding. In a global deployment of <code>alto</code> with a simulated 500ms verification duration, we saw view latency drop by 105ms on average with this feature enabled.</p>
        <p>Application developers can opt-in to this change by implementing the <code>CertifiableBlock</code> trait on their block type, which requires storing the consensus context within their blocks. The <code>inline</code> path is retained for applications that want to make no changes.</p>

        <h2>Out-of-the-Box Performance</h2>

        <p>Applications do not need to be rewritten to use this feature. If you already implement the consensus <code>Application</code>/<code>VerifyingApplication</code> interfaces, wrap the same application with coding marshal and get erasure-coded dissemination automatically. Build, verify, report: same contract.</p>

        <p>The tradeoff is deliberate and explicit: opting into coding is a protocol-level breaking change. On-wire payloads, commitments, and verification flow differ from the standard path, so networks must choose to upgrade into coding (or stay on standard) intentionally. The upside is that this choice is localized, reversible in architecture, and does not force application developers to redesign core logic.</p>

        <h2>Alto Benchmarks</h2>

        <p>For global <a href="https://alto.commonware.xyz">alto</a> benchmarks, we deploy 50 validators uniformly across <code>ap-northeast-1</code>, <code>ap-nor theast-2</code>, <code>ap-south-1</code>, <code>ap-southeast-2</code>, <code>eu- central-1</code>, <code>eu-north-1</code>, <code>eu-west-1</code>, <code>sa-east -1</code>, <code>us-east-1</code>, and <code>us-west-1</code>. Each validator runs on a <code>c8g.2xlarge</code> instance (8 vcpus, 4 dedicated to <code>tokio</code> and 4 dedicated to a <code>rayon</code> thread pool used for parallel hashing and signature verification).</p>

        <div class="image-container">
            <img src="/imgs/alto_coding_4.png" alt="Alto coding benchmarks (4 MiB blocks)" />
            <div class="image-caption">Figure 5: Global Alto cluster, using <code><a href="https://docs.rs/commonware-coding/latest/commonware_coding/struct.ReedSolomon.html">coding::reed_solomon</a></code> and <code><a href="https://docs.rs/commonware-cryptography/latest/commonware_cryptography/blake3/struct.Blake3.html">cryptography::blake3</a></code>, achieving ~14Mb/s throughput and ~300ms view latency with statically sized 4MiB blocks.</div>
        </div>

        <div class="image-container">
            <img src="/imgs/alto_coding_8.png" alt="Alto coding benchmarks (8 MiB blocks)" />
            <div class="image-caption">Figure 6: Global Alto cluster, using <code><a href="https://docs.rs/commonware-coding/latest/commonware_coding/struct.ReedSolomon.html">coding::reed_solomon</a></code> and <code><a href="https://docs.rs/commonware-cryptography/latest/commonware_cryptography/blake3/struct.Blake3.html">cryptography::blake3</a></code>, achieving ~17Mb/s throughput and &lt;500ms view latency with statically sized 8MiB blocks.</div>
        </div>

        <h2>What Comes Next</h2>

        <p>Delivering blocks in pieces is one part of a larger roadmap toward faster and more composable consensus deployments. <code><a href="https://github.com/commonwarexyz/monorepo/blob/main/consensus/src/marshal/coding/mod.rs">marshal::coding</a></code> is now <a href="/blogs/is-it-ready-yet.html">in ALPHA</a>, and will be included in the upcoming release.</p>

        <p><i>commonware-constantinople is coming soon.</i></p>
    </div>

    <div id="footer-placeholder"></div>
    <script src="/shared.js"></script>
</body>

</html>