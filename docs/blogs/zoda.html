<!DOCTYPE html>
<html lang="en">

<head>
    <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
    <meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
    <link rel="icon" href="/favicon.ico" type="image/x-icon">

    <title>commonware > Optimizing Block Dispersal with Coding</title>
    <meta name="description" content="In which we describe how we use
coding schemes, and ZODA to distribute blocks efficiently">
    <meta name="author" content="Lucas Meier">
    <meta name="keywords" content="commonware, open source, common goods, software, internet, ownership, trust, blockchain, decentralization, crypto">

        <meta property="og:type" content="article" />
    <meta property="og:site_name" content="commonware" />
        <meta property="og:title" content="Optimizing Block Dispersal
with Coding" />
    <meta property="og:description" content="In which we describe how we
use coding schemes, and ZODA to distribute blocks efficiently" />
    <meta property="article:author" content="Lucas Meier" />
    <meta property="article:published_time" content="2025-10-11T00:00:00Z" />
    <meta property="article:modified_time" content="2025-10-11T00:00:00Z" />

        <meta property="twitter:domain" content="commonware.xyz" />
    <meta property="twitter:url" content="" />
    <meta property="twitter:title" content="Optimizing Block Dispersal
with Coding" />
    <meta property="twitter:description" content="In which we describe
how we use coding schemes, and ZODA to distribute blocks efficiently" />
    <meta property="twitter:site" content="@commonwarexyz" />
    
    <link rel="stylesheet" type="text/css" href="/style.css">

         <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.css">
     <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.js"></script>
     <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/contrib/auto-render.min.js" 
             onload="renderMathInElement(document.body);"></script></head>
    <body>
    <div id="logo-placeholder">
        <div class="logo-line">
            <span class="edge-logo-symbol">+</span>
            <span class="horizontal-logo-symbol">~</span>
            <span class="horizontal-logo-symbol"> </span>
            <span class="horizontal-logo-symbol">-</span>
            <span class="horizontal-logo-symbol">+</span>
            <span class="horizontal-logo-symbol">-</span>
            <span class="horizontal-logo-symbol">+</span>
            <span class="horizontal-logo-symbol"> </span>
            <span class="horizontal-logo-symbol">-</span>
            <span class="horizontal-logo-symbol">+</span>
            <span class="horizontal-logo-symbol">-</span>
            <span class="horizontal-logo-symbol">~</span>
            <span class="horizontal-logo-symbol">~</span>
            <span class="edge-logo-symbol">*</span>
        </div>
        <div class="logo-line">
            <span class="vertical-logo-symbol">|</span>
            <span class="logo-text"> commonware </span>
            <span class="vertical-logo-symbol"> </span>
        </div>
        <div class="logo-line">
            <span class="edge-logo-symbol">*</span>
            <span class="horizontal-logo-symbol">~</span>
            <span class="horizontal-logo-symbol">+</span>
            <span class="horizontal-logo-symbol">+</span>
            <span class="horizontal-logo-symbol">-</span>
            <span class="horizontal-logo-symbol"> </span>
            <span class="horizontal-logo-symbol">~</span>
            <span class="horizontal-logo-symbol">-</span>
            <span class="horizontal-logo-symbol">+</span>
            <span class="horizontal-logo-symbol"> </span>
            <span class="horizontal-logo-symbol">-</span>
            <span class="horizontal-logo-symbol">*</span>
            <span class="horizontal-logo-symbol">-</span>
            <span class="edge-logo-symbol">+</span>
        </div>
    </div>
    <div class="content">
        <h1>Optimizing Block Dispersal with Coding</h1>
        <div class="meta">
            <div class="author">By <a href="https://x.com/vex_0x">Lucas
Meier</a></div>
            <div class="date">October 15th, 2025</div>
        </div>
        <p>A crucial part of blockchain consensus is distributing the
        block among participants. You can come to consensus over a mere
        fingerprint of the block—a hash for example— but doing anything
        interesting with the block, like processing transactions,
        requires the data.</p>
        <p>We’ve invested some effort in this part of the Commonware
        stack recently, and I’d like to share some fruits of that effort
        in this post. As an outline, we’ll cover: - data dissemination,
        naively, - how to increase efficiency with coding, - and,
        finally, how to get quicker guarantees about the data with <a
        href="https://eprint.iacr.org/2025/034">ZODA</a>.</p>
        <p>In a future post we could cover lower-level details of our
        implementation, like the field we use for Reed-Solomon coding,
        and the optimizations needed for fast fourier transforms, but
        this one will stick to an overview.</p>
        <h2 id="naive-dissemination">Naive Dissemination</h2>
        <p>We assume a <em>leader</em> has some data, <span
        class="math inline">D</span> bytes worth, to be disseminated.
        They want <span class="math inline">m</span> followers to
        receive it. The simplest approach is to have the leader send the
        data to every follower. The leader’s transmission cost is <span
        class="math inline">m \cdot D</span> bytes, and the followers’
        cost is <span class="math inline">0</span> bytes, since they
        send nothing.</p>
        <p>Networked protocols are often bottlenecked by sending data,
        since moving bits around the planet, a country, or a building is
        hopelessly slow compared to moving it within an integrated
        circuit. This protocol is bottlenecked more so, with all of its
        communication going through the single leader node. While the
        leader sends the entire data <span class="math inline">m</span>
        times, the followers sit idle, wasting their resources. We can
        do better.</p>
        <h2 id="towards-coding">Towards Coding</h2>
        <p>We want the followers to participate in sending the data as
        well. Imagine, after our naive protocol, that a follower
        crashes, losing their data. This is no big problem: the data is
        present among the other followers, and our lost node can
        communicate with them to recover it. In fact, every other node
        has all of the data, so you have more information than required
        on the network. If one node had one half of the data, and some
        other node the other half, you would still be able to recover
        it, by combining their halves.</p>
        <p>We could extend the logic further still: each of the <span
        class="math inline">m</span> participants could hold <span
        class="math inline">\frac{1}{m}</span> of the data. All
        together, the participants hold it all, distributed as thinly as
        possible.</p>
        <p>In this case, the leader’s transmission cost is now just
        <span class="math inline">m \cdot \frac{D}{m}</span> = D$, quite
        the improvement. If the participants want to recover the whole
        data, each of them will need to send their shard to the others,
        at a cost of <span class="math inline">(m - 1) \cdot
        \frac{D}{m}</span> bytes. The total amount of data sent by the
        leader, and then the followers, is <span class="math inline">D +
        m \cdot \frac{(m - 1) D}{m} = m \cdot D</span>. Compared to the
        naive approach, the total amount of data sent is the same.
        However, it is sent much more efficiently, spreading the load
        evenly across all the links in the network. Each node sending
        <span class="math inline">\frac{(m - 1)}{m} \cdot D</span> bytes
        worth of data to others can operate in parallel, whereas in the
        original case, the leader must send <span class="math inline">m
        \cdot D</span> bytes sequentially.</p>
        <h3 id="dealing-with-loss">Dealing with Loss</h3>
        <p>One flaw in our scheme, so far, is that the data is spread so
        thinly, that even one node missing out results in it being lost
        completely. This might happen by accident—a node crashing is not
        impossible, after all— but we also want to tolerate malicious
        nodes. One follower being able to block transmission is not
        acceptable.</p>
        <p>From here, we reach to using a <em>coding scheme</em>. This
        scheme takes in a message of <span class="math inline">n</span>
        <em>symbols</em>—we shall revisit the term, but think of it like
        a byte, or some other small piece of data—and produce <span
        class="math inline">m \geq n</span> symbols. A useful coding
        scheme has the property that given any <span
        class="math inline">n</span> of these <span
        class="math inline">m</span> symbols, we can recover the
        original message.</p>
        <p>As an example, a <em>Reed-Solomon</em> code consists of
        treating the data as a list of <span
        class="math inline">n</span> field elements (serving as the
        aforementioned symbols) which define the polynomial:</p>
        <p><span class="math display">
        d(X) \coloneqq a_0 + a_1 X + \cdots + a_{n - 1} X^{n - 1}
        </span></p>
        <p>We can then consider the evaluation of this polynomial at
        <span class="math inline">m</span> distinct points:</p>
        <p><span class="math display">
        d(\omega_0), d(\omega_1), \ldots, d(\omega_{m - 1})
        </span></p>
        <p>as forming our encoded message. With some algebra, any <span
        class="math inline">n</span> of these evaluations can be
        interpolated back into the original polynomial <span
        class="math inline">d(X)</span>, whose coefficients spell out
        our message.</p>
        <p>These details are not essential: what matters is that we take
        <span class="math inline">n</span> symbols, encode them into
        <span class="math inline">m</span>, such that any <span
        class="math inline">n</span> of the encoded symbols are good
        enough to recover the originals.</p>
        <h3 id="dissemination-with-coding">Dissemination with
        Coding</h3>
        <p>This naturally suggests a scheme in which followers receive
        encoded symbols, allowing recovery with partial information. To
        flesh this out further, we want to accommodate data which may
        not consist of precisely <span class="math inline">n</span>
        symbols. Instead, we assume a matrix of <span
        class="math inline">n \times c</span> symbols (which may be
        padded). This matrix can be encoded columnwise, producing a
        result of size <span class="math inline">m \times c</span>. Each
        shard can be a row of this matrix. Given <span
        class="math inline">n</span> shards, the original matrix can be
        recovered, proceeding columnwise once more.</p>
        <p>The cost of this scheme is now: - <span class="math inline">m
        \cdot \frac{D}{n}</span> for the leader, - <span
        class="math inline">(m - 1) \cdot \frac{D}{n}</span> for each
        follower, - <span class="math inline">\frac{m^2}{n} \cdot
        D</span> in total.</p>
        <p>As the redundancy decreases, with <span class="math inline">m
        \to n</span>, we get the same cost as before. We want some
        redundancy though, with <span class="math inline">m \gg
        n</span>, so the total cost will be <em>higher</em> than before.
        Nevertheless, it is distributed far more fairly than the naive
        case, so we should expect it to perform better.</p>
        <h2 id="integrity">Integrity</h2>
        <p>We’ve described coding schemes as being able to tolerate
        erasure: missing pieces of data. This fits naturally in the
        model of crash faults: if a node crashes, their piece is lost,
        but we can tolerate this. What do we do in the case of malicious
        faults, where data is intentionally changed, rather than merely
        omitted?</p>
        <p>Some coding schemes can tolerate random errors. For example,
        bit flips, or adding a random field element. Unfortunately, this
        comes at the cost of at least doubling the amount of redundancy
        in order to correct the same number of errors. There’s also a
        significant jump in algorithmic complexity, mathematically, and
        cognitively, to the point where implementations often don’t
        contain procedures for decoding with errors at all.</p>
        <p>To avoid the need to correct errors, we can use a trick:
        instead of decoding with bad shards, we could detect that
        they’ve been corrupted, and treat them as missing instead.</p>
        <p>If the followers received a hash of each shard, then they
        could tell whether some data is actually the shard it claims to
        be, by hashing it. This comes at a penalty of transmitting <span
        class="math inline">m \cdot 2^\lambda</span> bits of data
        (guaranteeing no collisions up to a probability of <span
        class="math inline">2^-\lambda</span> requires <span
        class="math inline">2 \lambda</span> bit hashes). We can improve
        this a bit by having the leader use a vector commitment over the
        <span class="math inline">m</span> hashes. Each shard would then
        come with an opening, demonstrating that the <span
        class="math inline">i</span>th hash in the vector is that of the
        shard. A binary Merkle Tree is an example of such a scheme (but
        others might work better, e.g. playing with arity, or using a
        Polynomial Commitment Scheme).</p>
        <p>As a side-effect, our scheme now produces a fingerprint,
        attesting uniquely to the encoded data. This could be used for
        consensus, like the hash of the data itself often is.</p>
        <h3 id="bad-leaders">Bad Leaders</h3>
        <p>So far, our leader encodes the data into shards, distributes
        them, and given a large enough subset of them, we can recover
        the data. We also know that malicious follower cannot tamper
        with the data, because they must prove that their shard is what
        the leader committed to.</p>
        <p>But, what if the leader is malicious? What if instead of
        encoding data into shards, they simply made the shards up
        themselves?</p>
        <p>In that case, honest followers might successfully reconstruct
        something, but each of them sees a different result, based on
        the particular shards they chose to use. It’s also easy to get
        different honest followers to pick different shards, by
        selectively withholding them. Proceeding with different data is
        very bad, so we want to avoid this.</p>
        <p>Something we can do is to check that re-encoding the data
        produces what the leader claimed. If encoding is: -
        <em>deterministic</em>, producing, always, the same result, -
        <em>injective</em>, with different data producing different
        results, then this works out. A malicious leader shares one
        commitment, and there can be at most one original piece of data
        that commits to that value.</p>
        <p>One drawback is that now we can only know that the data
        exists <em>after</em> we’ve reconstructed it. If we’re tying
        this process to consensus, it would be nice to avoid coming to
        agreement on a piece of data which will turn out to never have
        existed, producing an empty block. There’s also, more plainly, a
        cost to re-encoding, which it might be nice to avoid.</p>
        <h2 id="zoda">ZODA</h2>
        <p>At a high level, <a
        href="https://eprint.iacr.org/2025/034">ZODA</a> allows us to
        avoid this issue. We can be convinced that our shard comes from
        a valid encoding of some unique piece of data, as soon as we
        receive our shard.</p>
        <p>(For ZODA afficionados, what we describe subsequently is the
        application of the “Hadamard” variant from section D of the
        paper).</p>
        <p>This involves sending, along with the shard, some additional
        data, of use not in recovering it, but in providing assurance
        that our shard results from an encoding of it.</p>
        <h3 id="some-details-and-intuition">Some Details and
        Intuition</h3>
        <p>The inner workings of the protocol are not necessary to
        understand its utility nor application, but are simple enough to
        be understood at a high level of operation.</p>
        <p>We continue in modelling our data, <span
        class="math inline">X</span>, as a matrix of dimension <span
        class="math inline">n \times c</span>, with elements in some
        field <span class="math inline">F</span>. We can encode it,
        using a matrix <span class="math inline">G</span> of dimension
        <span class="math inline">m \times n</span>, producing <span
        class="math inline">Y \coloneqq G X</span>, of dimension <span
        class="math inline">m \times c</span>. The rows of <span
        class="math inline">Y</span> are committed to, and this
        commitment can serve as a source of randomness in what follows,
        according to the <em>Fiat-Shamir</em> paradigm.</p>
        <p>Whereas in the plain coding scheme, we received one
        particular row of <span class="math inline">Y</span>, here we
        receive <span class="math inline">S</span> rows, sampled at
        random. (We may modify <span class="math inline">m</span> and
        <span class="math inline">n</span> to accomodate this fact). We
        also receive proofs of inclusion for each row.</p>
        <p>In order to convince us that our rows <span
        class="math inline">Y_S</span> came from <span
        class="math inline">G X</span>, a random matrix <span
        class="math inline">H</span> of dimension <span
        class="math inline">c \times S&#39;</span> is sampled from a
        (potentially) larger field <span class="math inline">F&#39;
        \supseteq F</span>. Then, we are given <span
        class="math inline">Z \coloneqq X H</span>, of dimension $n
        S’.</p>
        <p>Because encoding is linear, we can check that:</p>
        <p><span class="math display">
        Y_S H \overset{?}{=} (G Z)_S
        </span></p>
        <p>which should hold for an honest encoder, since:</p>
        <p><span class="math display">
        G (X H) = (G X) H
        </span></p>
        <p>for any matrices <span class="math inline">G</span>, <span
        class="math inline">X</span>, <span
        class="math inline">H</span>.</p>
        <h3 id="some-intuition">Some Intuition</h3>
        <p>You can show, as the paper does, that given enough samples
        <span class="math inline">S</span>, <span
        class="math inline">S&#39;</span>, and a large enough <span
        class="math inline">F&#39;</span>, any desirable level of
        security can be achieved. We can, however, reason intuitively
        about why this might work.</p>
        <p>For a given row <span class="math inline">Y_i</span>,
        checking:</p>
        <p><span class="math display">
        (Y_i H)_j \overset{?}{=} (G Z)_{i j}
        </span></p>
        <p>is the same as checking that a random linear combination of
        (alleged) encoded symbols is equal to <span
        class="math inline">G x</span>, for some symbol <span
        class="math inline">x</span>. In other words, that this
        combination is an encoded symbol. This is true if <span
        class="math inline">Y_i</span> is correct, and likely to be
        false if not. By sampling <span
        class="math inline">S&#39;</span> check columns, we perform this
        check many times, with different randomness, making it more
        likely to be false for a fake encoding. Furthermore, by sampling
        <span class="math inline">S</span> rows at random, rather than
        having a row assigned to use by the leader, we make it very
        difficult to find some clever data which will slip through our
        checks, since the cheater will not know where they need to fake
        the outcome.</p>
        <h3 id="completing-the-protocol">Completing the Protocol</h3>
        <p>To complete the sketch of the protocol let’s look at how we
        handle the shards, collectively. Rather than have each follower
        sample <span class="math inline">S</span> rows at random, we
        instead shuffle the rows, and partition it into chunks of size
        <span class="math inline">S</span>. This guarantees no overlap
        between shards, while still giving us the randomness to convince
        us of a valid encoding. When receiving shards, we check
        inclusion, and that:</p>
        <p><span class="math display">
        Y_S H \overset{?}{=} (G Z)_S
        </span></p>
        <p>as for our own shard.</p>
        <h2 id="summary">Summary</h2>
        <p>A leader wants to send some data to followers.</p>
        <p>In the naive case, the leader simply sends all of the data to
        everyone.</p>
        <p>To optimize distribution, we encode the data into shards,
        with each follower receiving one shard. The data can be
        recovered from a subset of shards. The leader commits to the
        shards, so that we can easily check if purported shards actually
        belong. Unfortunately, we can’t know if the data is uniquely
        recoverable until re-assembling it, and re-encoding it to see if
        it matches our commitment.</p>
        <p><a href="https://eprint.iacr.org/2025/034">ZODA</a>
        alleviates this by guaranteeing that a shard originates from a
        valid encoding, by adding additional check data to each
        shard.</p>
        <p>Our work-in-progress implementation of this scheme can be
        found here: <a
        href="https://github.com/commonwarexyz/monorepo/blob/cronokirby/ZODA/coding/src/zoda.rs"></a>.</p>
    <div id="footer-placeholder"></div>
    <script src="/shared.js"></script>
</body>
</html>
